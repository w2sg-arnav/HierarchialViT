2025-05-08 16:03:19,681 - root - INFO - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/logs/phase5_high_acc.log
2025-05-08 16:03:19,681 - __main__ - INFO - --------- Starting New Training Session ---------
2025-05-08 16:03:19,681 - __main__ - INFO - Using device: cuda
2025-05-08 16:03:19,681 - __main__ - INFO - Random seed: 42
2025-05-08 16:03:19,681 - __main__ - INFO - Effective Configuration:
2025-05-08 16:03:19,681 - __main__ - INFO -   seed: 42
2025-05-08 16:03:19,681 - __main__ - INFO -   device: cuda
2025-05-08 16:03:19,682 - __main__ - INFO -   log_dir: logs
2025-05-08 16:03:19,682 - __main__ - INFO -   log_file_finetune: phase5_high_acc.log
2025-05-08 16:03:19,682 - __main__ - INFO -   checkpoint_dir: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints
2025-05-08 16:03:19,682 - __main__ - INFO -   best_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth
2025-05-08 16:03:19,682 - __main__ - INFO -   final_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_final_90percent.pth
2025-05-08 16:03:19,682 - __main__ - INFO -   data_root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection
2025-05-08 16:03:19,682 - __main__ - INFO -   train_split_ratio: 0.85
2025-05-08 16:03:19,682 - __main__ - INFO -   num_classes: 7
2025-05-08 16:03:19,682 - __main__ - INFO -   num_workers: 12
2025-05-08 16:03:19,683 - __main__ - INFO -   normalize_data: True
2025-05-08 16:03:19,683 - __main__ - INFO -   model_name: DiseaseAwareHVT_XL
2025-05-08 16:03:19,683 - __main__ - INFO -   pretrained_checkpoint_path: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth
2025-05-08 16:03:19,683 - __main__ - INFO -   load_pretrained: True
2025-05-08 16:03:19,683 - __main__ - INFO -   hvt_patch_size: 14
2025-05-08 16:03:19,683 - __main__ - INFO -   hvt_embed_dim_rgb: 128
2025-05-08 16:03:19,683 - __main__ - INFO -   hvt_embed_dim_spectral: 128
2025-05-08 16:03:19,683 - __main__ - INFO -   hvt_spectral_channels: 3
2025-05-08 16:03:19,683 - __main__ - INFO -   hvt_depths: [3, 6, 18, 3]
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_num_heads: [4, 8, 16, 32]
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_mlp_ratio: 4.0
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_qkv_bias: True
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_model_drop_rate: 0.2
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_attn_drop_rate: 0.1
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_drop_path_rate: 0.3
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_use_dfca: True
2025-05-08 16:03:19,684 - __main__ - INFO -   hvt_dfca_heads: 16
2025-05-08 16:03:19,684 - __main__ - INFO -   img_size: (512, 512)
2025-05-08 16:03:19,684 - __main__ - INFO -   epochs: 200
2025-05-08 16:03:19,685 - __main__ - INFO -   batch_size: 64
2025-05-08 16:03:19,685 - __main__ - INFO -   accumulation_steps: 2
2025-05-08 16:03:19,685 - __main__ - INFO -   amp_enabled: True
2025-05-08 16:03:19,685 - __main__ - INFO -   clip_grad_norm: 3.0
2025-05-08 16:03:19,685 - __main__ - INFO -   log_interval: 50
2025-05-08 16:03:19,685 - __main__ - INFO -   optimizer: LAMB
2025-05-08 16:03:19,685 - __main__ - INFO -   learning_rate: 0.0003
2025-05-08 16:03:19,685 - __main__ - INFO -   weight_decay: 0.02
2025-05-08 16:03:19,685 - __main__ - INFO -   optimizer_params: {'betas': (0.9, 0.999)}
2025-05-08 16:03:19,685 - __main__ - INFO -   layer_decay: 0.75
2025-05-08 16:03:19,686 - __main__ - INFO -   freeze_backbone_epochs: 10
2025-05-08 16:03:19,686 - __main__ - INFO -   head_lr_factor: 10.0
2025-05-08 16:03:19,686 - __main__ - INFO -   use_llrd: True
2025-05-08 16:03:19,686 - __main__ - INFO -   llrd_rate: 0.85
2025-05-08 16:03:19,686 - __main__ - INFO -   loss_type: focal
2025-05-08 16:03:19,686 - __main__ - INFO -   focal_alpha: None
2025-05-08 16:03:19,686 - __main__ - INFO -   focal_gamma: 2.0
2025-05-08 16:03:19,686 - __main__ - INFO -   label_smoothing: 0.15
2025-05-08 16:03:19,686 - __main__ - INFO -   use_weighted_sampler: False
2025-05-08 16:03:19,686 - __main__ - INFO -   use_weighted_loss: True
2025-05-08 16:03:19,687 - __main__ - INFO -   augmentations_enabled: True
2025-05-08 16:03:19,687 - __main__ - INFO -   rand_augment_num_ops: 3
2025-05-08 16:03:19,687 - __main__ - INFO -   rand_augment_magnitude: 12
2025-05-08 16:03:19,687 - __main__ - INFO -   color_jitter_params: {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}
2025-05-08 16:03:19,687 - __main__ - INFO -   random_erase_prob: 0.3
2025-05-08 16:03:19,687 - __main__ - INFO -   mixup_alpha: 0.4
2025-05-08 16:03:19,687 - __main__ - INFO -   cutmix_alpha: 0.4
2025-05-08 16:03:19,687 - __main__ - INFO -   mixup_cutmix_prob: 0.7
2025-05-08 16:03:19,687 - __main__ - INFO -   auto_augment_policy: None
2025-05-08 16:03:19,687 - __main__ - INFO -   ema_decay: 0.999
2025-05-08 16:03:19,688 - __main__ - INFO -   scheduler: CosineAnnealingLR
2025-05-08 16:03:19,688 - __main__ - INFO -   warmup_epochs: 15
2025-05-08 16:03:19,688 - __main__ - INFO -   warmup_lr_init_factor: 0.01
2025-05-08 16:03:19,688 - __main__ - INFO -   min_lr: 1e-06
2025-05-08 16:03:19,688 - __main__ - INFO -   cosine_t_0: 10
2025-05-08 16:03:19,688 - __main__ - INFO -   cosine_t_mult: 2
2025-05-08 16:03:19,688 - __main__ - INFO -   reducelr_factor: 0.2
2025-05-08 16:03:19,688 - __main__ - INFO -   reducelr_patience: 10
2025-05-08 16:03:19,688 - __main__ - INFO -   evaluate_every_n_epochs: 1
2025-05-08 16:03:19,688 - __main__ - INFO -   early_stopping_patience: 25
2025-05-08 16:03:19,689 - __main__ - INFO -   metric_to_monitor: accuracy
2025-05-08 16:03:19,689 - __main__ - INFO -   tta_enabled: True
2025-05-08 16:03:19,689 - __main__ - INFO -   tta_augmentations: ['hflip', 'vflip', 'rotate']
2025-05-08 16:03:19,689 - __main__ - INFO -   hpo_enabled: False
2025-05-08 16:03:19,689 - __main__ - INFO -   hpo_n_trials: 150
2025-05-08 16:03:19,689 - __main__ - INFO -   hpo_study_name: disease_hvt_xl_phase5_hpo
2025-05-08 16:03:19,689 - __main__ - INFO -   hpo_storage_db: sqlite:///hpo_phase5_study.db
2025-05-08 16:03:19,689 - __main__ - INFO -   hpo_params_ranges: {'learning_rate': (1e-05, 0.001, 'log'), 'weight_decay': (0.001, 0.1, 'log'), 'llrd_rate': (0.7, 0.95, 'uniform'), 'mixup_alpha': (0.1, 0.8, 'uniform'), 'label_smoothing': (0.0, 0.2, 'uniform'), 'hvt_drop_path_rate': (0.1, 0.5, 'uniform'), 'focal_gamma': (1.0, 3.0, 'uniform')}
2025-05-08 16:03:19,691 - __main__ - ERROR - A critical error occurred during the training session: name 'random' is not defined
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 930, in <module>
    run_training_session(config)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 522, in run_training_session
    set_seed(config["seed"])
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 163, in set_seed
    random.seed(seed) # For python's random module
NameError: name 'random' is not defined
2025-05-08 16:04:18,057 - root - INFO - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/logs/phase5_high_acc.log
2025-05-08 16:04:18,057 - __main__ - INFO - --------- Starting New Training Session ---------
2025-05-08 16:04:18,058 - __main__ - INFO - Using device: cuda
2025-05-08 16:04:18,058 - __main__ - INFO - Random seed: 42
2025-05-08 16:04:18,058 - __main__ - INFO - Effective Configuration:
2025-05-08 16:04:18,058 - __main__ - INFO -   seed: 42
2025-05-08 16:04:18,058 - __main__ - INFO -   device: cuda
2025-05-08 16:04:18,058 - __main__ - INFO -   log_dir: logs
2025-05-08 16:04:18,058 - __main__ - INFO -   log_file_finetune: phase5_high_acc.log
2025-05-08 16:04:18,058 - __main__ - INFO -   checkpoint_dir: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints
2025-05-08 16:04:18,058 - __main__ - INFO -   best_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth
2025-05-08 16:04:18,059 - __main__ - INFO -   final_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_final_90percent.pth
2025-05-08 16:04:18,059 - __main__ - INFO -   data_root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection
2025-05-08 16:04:18,059 - __main__ - INFO -   train_split_ratio: 0.85
2025-05-08 16:04:18,059 - __main__ - INFO -   num_classes: 7
2025-05-08 16:04:18,059 - __main__ - INFO -   num_workers: 12
2025-05-08 16:04:18,059 - __main__ - INFO -   normalize_data: True
2025-05-08 16:04:18,059 - __main__ - INFO -   model_name: DiseaseAwareHVT_XL
2025-05-08 16:04:18,059 - __main__ - INFO -   pretrained_checkpoint_path: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth
2025-05-08 16:04:18,059 - __main__ - INFO -   load_pretrained: True
2025-05-08 16:04:18,059 - __main__ - INFO -   hvt_patch_size: 14
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_embed_dim_rgb: 128
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_embed_dim_spectral: 128
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_spectral_channels: 3
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_depths: [3, 6, 18, 3]
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_num_heads: [4, 8, 16, 32]
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_mlp_ratio: 4.0
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_qkv_bias: True
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_model_drop_rate: 0.2
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_attn_drop_rate: 0.1
2025-05-08 16:04:18,060 - __main__ - INFO -   hvt_drop_path_rate: 0.3
2025-05-08 16:04:18,061 - __main__ - INFO -   hvt_use_dfca: True
2025-05-08 16:04:18,061 - __main__ - INFO -   hvt_dfca_heads: 16
2025-05-08 16:04:18,061 - __main__ - INFO -   img_size: (512, 512)
2025-05-08 16:04:18,061 - __main__ - INFO -   epochs: 200
2025-05-08 16:04:18,061 - __main__ - INFO -   batch_size: 64
2025-05-08 16:04:18,061 - __main__ - INFO -   accumulation_steps: 2
2025-05-08 16:04:18,061 - __main__ - INFO -   amp_enabled: True
2025-05-08 16:04:18,061 - __main__ - INFO -   clip_grad_norm: 3.0
2025-05-08 16:04:18,061 - __main__ - INFO -   log_interval: 50
2025-05-08 16:04:18,061 - __main__ - INFO -   optimizer: LAMB
2025-05-08 16:04:18,062 - __main__ - INFO -   learning_rate: 0.0003
2025-05-08 16:04:18,062 - __main__ - INFO -   weight_decay: 0.02
2025-05-08 16:04:18,062 - __main__ - INFO -   optimizer_params: {'betas': (0.9, 0.999)}
2025-05-08 16:04:18,062 - __main__ - INFO -   layer_decay: 0.75
2025-05-08 16:04:18,062 - __main__ - INFO -   freeze_backbone_epochs: 10
2025-05-08 16:04:18,062 - __main__ - INFO -   head_lr_factor: 10.0
2025-05-08 16:04:18,062 - __main__ - INFO -   use_llrd: True
2025-05-08 16:04:18,062 - __main__ - INFO -   llrd_rate: 0.85
2025-05-08 16:04:18,062 - __main__ - INFO -   loss_type: focal
2025-05-08 16:04:18,062 - __main__ - INFO -   focal_alpha: None
2025-05-08 16:04:18,063 - __main__ - INFO -   focal_gamma: 2.0
2025-05-08 16:04:18,063 - __main__ - INFO -   label_smoothing: 0.15
2025-05-08 16:04:18,063 - __main__ - INFO -   use_weighted_sampler: False
2025-05-08 16:04:18,063 - __main__ - INFO -   use_weighted_loss: True
2025-05-08 16:04:18,063 - __main__ - INFO -   augmentations_enabled: True
2025-05-08 16:04:18,063 - __main__ - INFO -   rand_augment_num_ops: 3
2025-05-08 16:04:18,063 - __main__ - INFO -   rand_augment_magnitude: 12
2025-05-08 16:04:18,063 - __main__ - INFO -   color_jitter_params: {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}
2025-05-08 16:04:18,063 - __main__ - INFO -   random_erase_prob: 0.3
2025-05-08 16:04:18,063 - __main__ - INFO -   mixup_alpha: 0.4
2025-05-08 16:04:18,063 - __main__ - INFO -   cutmix_alpha: 0.4
2025-05-08 16:04:18,064 - __main__ - INFO -   mixup_cutmix_prob: 0.7
2025-05-08 16:04:18,064 - __main__ - INFO -   auto_augment_policy: None
2025-05-08 16:04:18,064 - __main__ - INFO -   ema_decay: 0.999
2025-05-08 16:04:18,064 - __main__ - INFO -   scheduler: CosineAnnealingLR
2025-05-08 16:04:18,064 - __main__ - INFO -   warmup_epochs: 15
2025-05-08 16:04:18,064 - __main__ - INFO -   warmup_lr_init_factor: 0.01
2025-05-08 16:04:18,064 - __main__ - INFO -   min_lr: 1e-06
2025-05-08 16:04:18,064 - __main__ - INFO -   cosine_t_0: 10
2025-05-08 16:04:18,064 - __main__ - INFO -   cosine_t_mult: 2
2025-05-08 16:04:18,065 - __main__ - INFO -   reducelr_factor: 0.2
2025-05-08 16:04:18,065 - __main__ - INFO -   reducelr_patience: 10
2025-05-08 16:04:18,065 - __main__ - INFO -   evaluate_every_n_epochs: 1
2025-05-08 16:04:18,065 - __main__ - INFO -   early_stopping_patience: 25
2025-05-08 16:04:18,065 - __main__ - INFO -   metric_to_monitor: accuracy
2025-05-08 16:04:18,065 - __main__ - INFO -   tta_enabled: True
2025-05-08 16:04:18,065 - __main__ - INFO -   tta_augmentations: ['hflip', 'vflip', 'rotate']
2025-05-08 16:04:18,065 - __main__ - INFO -   hpo_enabled: False
2025-05-08 16:04:18,065 - __main__ - INFO -   hpo_n_trials: 150
2025-05-08 16:04:18,066 - __main__ - INFO -   hpo_study_name: disease_hvt_xl_phase5_hpo
2025-05-08 16:04:18,066 - __main__ - INFO -   hpo_storage_db: sqlite:///hpo_phase5_study.db
2025-05-08 16:04:18,066 - __main__ - INFO -   hpo_params_ranges: {'learning_rate': (1e-05, 0.001, 'log'), 'weight_decay': (0.001, 0.1, 'log'), 'llrd_rate': (0.7, 0.95, 'uniform'), 'mixup_alpha': (0.1, 0.8, 'uniform'), 'label_smoothing': (0.0, 0.2, 'uniform'), 'hvt_drop_path_rate': (0.1, 0.5, 'uniform'), 'focal_gamma': (1.0, 3.0, 'uniform')}
2025-05-08 16:04:18,068 - __main__ - INFO - Setting up datasets...
2025-05-08 16:04:18,068 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: train
2025-05-08 16:04:18,069 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 16:04:18,714 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 16:04:19,699 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 16:04:19,701 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'train' size: 7766 samples.
2025-05-08 16:04:19,702 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: val
2025-05-08 16:04:19,702 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 16:04:20,352 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 16:04:21,290 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 16:04:21,293 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'val' size: 1371 samples.
2025-05-08 16:04:21,297 - phase5_multimodal_hpo.dataset - INFO - Computed class weights for split 'train': [1.03 0.9  1.06 1.02 1.06 0.83 1.16]
2025-05-08 16:04:21,297 - __main__ - INFO - Class weights will be used in the loss function.
2025-05-08 16:04:21,298 - __main__ - INFO - Loaders created. Train batches: 121, Val batches: 22. Num workers: 12
2025-05-08 16:04:21,298 - __main__ - INFO - Initializing model: DiseaseAwareHVT_XL
2025-05-08 16:04:21,607 - __main__ - WARNING - Pretrained checkpoint not found: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth. Training from scratch or as initialized.
2025-05-08 16:04:22,003 - __main__ - INFO - Freezing backbone layers for initial 10 epochs.
2025-05-08 16:04:22,006 - __main__ - INFO - Frozen phase: Setting head LR with factor 10.0.
2025-05-08 16:04:22,010 - __main__ - INFO - Using LAMB optimizer.
2025-05-08 16:04:22,010 - __main__ - INFO - Warmup scheduler: LinearLR for 15 epochs, start_factor 0.01.
2025-05-08 16:04:22,010 - __main__ - INFO - Main scheduler: CosineAnnealingLR, T_max=185, eta_min=1e-06.
2025-05-08 16:04:22,011 - __main__ - INFO - Using SequentialLR combining warmup and main scheduler.
2025-05-08 16:04:22,019 - phase5_multimodal_hpo.finetune.trainer - INFO - EMA enabled with decay: 0.999
2025-05-08 16:04:22,019 - phase5_multimodal_hpo.finetune.trainer - INFO - Using Focal Loss with gamma=2.0, label_smoothing=0.15
2025-05-08 16:04:22,019 - phase5_multimodal_hpo.finetune.trainer - INFO - Augmentations enabled for training.
2025-05-08 16:04:22,020 - phase5_multimodal_hpo.finetune.trainer - INFO - Using RandAugment with num_ops=3, magnitude=12
2025-05-08 16:04:22,023 - phase5_multimodal_hpo.finetune.trainer - INFO - Random Erasing enabled with p=0.3
2025-05-08 16:04:22,024 - phase5_multimodal_hpo.finetune.trainer - INFO - Mixup/Cutmix enabled: p=0.7, mixup_alpha=0.4, cutmix_alpha=0.4
2025-05-08 16:04:22,024 - phase5_multimodal_hpo.finetune.trainer - INFO - TTA enabled with 4 views: ['hflip', 'vflip', 'rotate']
2025-05-08 16:04:22,024 - phase5_multimodal_hpo.finetune.trainer - INFO - Finetuner initialized. Device=cuda, AccumSteps=2
2025-05-08 16:04:22,024 - __main__ - INFO - Starting training from epoch 1 for 200 total epochs... Monitoring: accuracy
2025-05-08 16:04:36,358 - __main__ - ERROR - A critical error occurred during the training session: labels tensor should be of shape (batch_size,) but got shape torch.Size([64, 7]) instead.
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 931, in <module>
    run_training_session(config)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 828, in run_training_session
    avg_train_loss = trainer.train_one_epoch(train_loader, epoch, config["epochs"])
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/finetune/trainer.py", line 416, in train_one_epoch
    rgb_images, spectral_images, labels = self._apply_augmentations(rgb_images, spectral_images, labels)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/finetune/trainer.py", line 359, in _apply_augmentations
    rgb_batch_mixed, labels_one_hot_mixed = self.mixup_cutmix_transform(rgb_batch_aug, labels_one_hot)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py", line 150, in forward
    return transform(*inputs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/transforms/v2/_augment.py", line 166, in forward
    raise ValueError(
ValueError: labels tensor should be of shape (batch_size,) but got shape torch.Size([64, 7]) instead.
2025-05-08 16:07:07,540 - root - INFO - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/logs/phase5_high_acc.log
2025-05-08 16:07:07,541 - __main__ - INFO - --------- Starting New Training Session ---------
2025-05-08 16:07:07,542 - __main__ - INFO - Using device: cuda
2025-05-08 16:07:07,542 - __main__ - INFO - Random seed: 42
2025-05-08 16:07:07,542 - __main__ - INFO - Effective Configuration:
2025-05-08 16:07:07,542 - __main__ - INFO -   seed: 42
2025-05-08 16:07:07,542 - __main__ - INFO -   device: cuda
2025-05-08 16:07:07,542 - __main__ - INFO -   log_dir: logs
2025-05-08 16:07:07,542 - __main__ - INFO -   log_file_finetune: phase5_high_acc.log
2025-05-08 16:07:07,542 - __main__ - INFO -   checkpoint_dir: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints
2025-05-08 16:07:07,542 - __main__ - INFO -   best_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth
2025-05-08 16:07:07,543 - __main__ - INFO -   final_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_final_90percent.pth
2025-05-08 16:07:07,543 - __main__ - INFO -   data_root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection
2025-05-08 16:07:07,543 - __main__ - INFO -   train_split_ratio: 0.85
2025-05-08 16:07:07,543 - __main__ - INFO -   num_classes: 7
2025-05-08 16:07:07,543 - __main__ - INFO -   num_workers: 12
2025-05-08 16:07:07,543 - __main__ - INFO -   normalize_data: True
2025-05-08 16:07:07,543 - __main__ - INFO -   model_name: DiseaseAwareHVT_XL
2025-05-08 16:07:07,543 - __main__ - INFO -   pretrained_checkpoint_path: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth
2025-05-08 16:07:07,543 - __main__ - INFO -   load_pretrained: True
2025-05-08 16:07:07,543 - __main__ - INFO -   hvt_patch_size: 14
2025-05-08 16:07:07,543 - __main__ - INFO -   hvt_embed_dim_rgb: 128
2025-05-08 16:07:07,543 - __main__ - INFO -   hvt_embed_dim_spectral: 128
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_spectral_channels: 3
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_depths: [3, 6, 18, 3]
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_num_heads: [4, 8, 16, 32]
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_mlp_ratio: 4.0
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_qkv_bias: True
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_model_drop_rate: 0.2
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_attn_drop_rate: 0.1
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_drop_path_rate: 0.3
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_use_dfca: True
2025-05-08 16:07:07,544 - __main__ - INFO -   hvt_dfca_heads: 16
2025-05-08 16:07:07,544 - __main__ - INFO -   img_size: (512, 512)
2025-05-08 16:07:07,544 - __main__ - INFO -   epochs: 200
2025-05-08 16:07:07,545 - __main__ - INFO -   batch_size: 64
2025-05-08 16:07:07,545 - __main__ - INFO -   accumulation_steps: 2
2025-05-08 16:07:07,545 - __main__ - INFO -   amp_enabled: True
2025-05-08 16:07:07,545 - __main__ - INFO -   clip_grad_norm: 3.0
2025-05-08 16:07:07,545 - __main__ - INFO -   log_interval: 50
2025-05-08 16:07:07,545 - __main__ - INFO -   optimizer: LAMB
2025-05-08 16:07:07,545 - __main__ - INFO -   learning_rate: 0.0003
2025-05-08 16:07:07,545 - __main__ - INFO -   weight_decay: 0.02
2025-05-08 16:07:07,545 - __main__ - INFO -   optimizer_params: {'betas': (0.9, 0.999)}
2025-05-08 16:07:07,545 - __main__ - INFO -   layer_decay: 0.75
2025-05-08 16:07:07,545 - __main__ - INFO -   freeze_backbone_epochs: 10
2025-05-08 16:07:07,546 - __main__ - INFO -   head_lr_factor: 10.0
2025-05-08 16:07:07,546 - __main__ - INFO -   use_llrd: True
2025-05-08 16:07:07,546 - __main__ - INFO -   llrd_rate: 0.85
2025-05-08 16:07:07,546 - __main__ - INFO -   loss_type: focal
2025-05-08 16:07:07,546 - __main__ - INFO -   focal_alpha: None
2025-05-08 16:07:07,546 - __main__ - INFO -   focal_gamma: 2.0
2025-05-08 16:07:07,546 - __main__ - INFO -   label_smoothing: 0.15
2025-05-08 16:07:07,546 - __main__ - INFO -   use_weighted_sampler: False
2025-05-08 16:07:07,546 - __main__ - INFO -   use_weighted_loss: True
2025-05-08 16:07:07,546 - __main__ - INFO -   augmentations_enabled: True
2025-05-08 16:07:07,547 - __main__ - INFO -   rand_augment_num_ops: 3
2025-05-08 16:07:07,547 - __main__ - INFO -   rand_augment_magnitude: 12
2025-05-08 16:07:07,547 - __main__ - INFO -   color_jitter_params: {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}
2025-05-08 16:07:07,547 - __main__ - INFO -   random_erase_prob: 0.3
2025-05-08 16:07:07,547 - __main__ - INFO -   mixup_alpha: 0.4
2025-05-08 16:07:07,547 - __main__ - INFO -   cutmix_alpha: 0.4
2025-05-08 16:07:07,547 - __main__ - INFO -   mixup_cutmix_prob: 0.7
2025-05-08 16:07:07,547 - __main__ - INFO -   auto_augment_policy: None
2025-05-08 16:07:07,547 - __main__ - INFO -   ema_decay: 0.999
2025-05-08 16:07:07,547 - __main__ - INFO -   scheduler: CosineAnnealingLR
2025-05-08 16:07:07,548 - __main__ - INFO -   warmup_epochs: 15
2025-05-08 16:07:07,548 - __main__ - INFO -   warmup_lr_init_factor: 0.01
2025-05-08 16:07:07,548 - __main__ - INFO -   min_lr: 1e-06
2025-05-08 16:07:07,548 - __main__ - INFO -   cosine_t_0: 10
2025-05-08 16:07:07,548 - __main__ - INFO -   cosine_t_mult: 2
2025-05-08 16:07:07,548 - __main__ - INFO -   reducelr_factor: 0.2
2025-05-08 16:07:07,548 - __main__ - INFO -   reducelr_patience: 10
2025-05-08 16:07:07,548 - __main__ - INFO -   evaluate_every_n_epochs: 1
2025-05-08 16:07:07,548 - __main__ - INFO -   early_stopping_patience: 25
2025-05-08 16:07:07,548 - __main__ - INFO -   metric_to_monitor: accuracy
2025-05-08 16:07:07,548 - __main__ - INFO -   tta_enabled: True
2025-05-08 16:07:07,549 - __main__ - INFO -   tta_augmentations: ['hflip', 'vflip', 'rotate']
2025-05-08 16:07:07,549 - __main__ - INFO -   hpo_enabled: False
2025-05-08 16:07:07,549 - __main__ - INFO -   hpo_n_trials: 150
2025-05-08 16:07:07,549 - __main__ - INFO -   hpo_study_name: disease_hvt_xl_phase5_hpo
2025-05-08 16:07:07,549 - __main__ - INFO -   hpo_storage_db: sqlite:///hpo_phase5_study.db
2025-05-08 16:07:07,549 - __main__ - INFO -   hpo_params_ranges: {'learning_rate': (1e-05, 0.001, 'log'), 'weight_decay': (0.001, 0.1, 'log'), 'llrd_rate': (0.7, 0.95, 'uniform'), 'mixup_alpha': (0.1, 0.8, 'uniform'), 'label_smoothing': (0.0, 0.2, 'uniform'), 'hvt_drop_path_rate': (0.1, 0.5, 'uniform'), 'focal_gamma': (1.0, 3.0, 'uniform')}
2025-05-08 16:07:07,550 - __main__ - INFO - Setting up datasets...
2025-05-08 16:07:07,550 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: train
2025-05-08 16:07:07,551 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 16:07:08,160 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 16:07:09,340 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 16:07:09,342 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'train' size: 7766 samples.
2025-05-08 16:07:09,342 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: val
2025-05-08 16:07:09,343 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 16:07:09,905 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 16:07:10,829 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 16:07:10,831 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'val' size: 1371 samples.
2025-05-08 16:07:10,835 - phase5_multimodal_hpo.dataset - INFO - Computed class weights for split 'train': [1.03 0.9  1.06 1.02 1.06 0.83 1.16]
2025-05-08 16:07:10,835 - __main__ - INFO - Class weights will be used in the loss function.
2025-05-08 16:07:10,837 - __main__ - INFO - Loaders created. Train batches: 121, Val batches: 22. Num workers: 12
2025-05-08 16:07:10,837 - __main__ - INFO - Initializing model: DiseaseAwareHVT_XL
2025-05-08 16:07:11,164 - __main__ - WARNING - Pretrained checkpoint not found: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth. Training from scratch or as initialized.
2025-05-08 16:07:11,579 - __main__ - INFO - Freezing backbone layers for initial 10 epochs.
2025-05-08 16:07:11,583 - __main__ - INFO - Frozen phase: Setting head LR with factor 10.0.
2025-05-08 16:07:11,586 - __main__ - INFO - Using LAMB optimizer.
2025-05-08 16:07:11,586 - __main__ - INFO - Warmup scheduler: LinearLR for 15 epochs, start_factor 0.01.
2025-05-08 16:07:11,586 - __main__ - INFO - Main scheduler: CosineAnnealingLR, T_max=185, eta_min=1e-06.
2025-05-08 16:07:11,587 - __main__ - INFO - Using SequentialLR combining warmup and main scheduler.
2025-05-08 16:07:11,596 - phase5_multimodal_hpo.finetune.trainer - INFO - EMA enabled with decay: 0.999
2025-05-08 16:07:11,596 - phase5_multimodal_hpo.finetune.trainer - INFO - Using Focal Loss with gamma=2.0, label_smoothing=0.15
2025-05-08 16:07:11,596 - phase5_multimodal_hpo.finetune.trainer - INFO - Augmentations enabled for training.
2025-05-08 16:07:11,597 - phase5_multimodal_hpo.finetune.trainer - INFO - Using RandAugment with num_ops=3, magnitude=12
2025-05-08 16:07:11,597 - phase5_multimodal_hpo.finetune.trainer - INFO - Random Erasing enabled with p=0.3
2025-05-08 16:07:11,598 - phase5_multimodal_hpo.finetune.trainer - INFO - Mixup/Cutmix enabled: p=0.7, mixup_alpha=0.4, cutmix_alpha=0.4
2025-05-08 16:07:11,599 - phase5_multimodal_hpo.finetune.trainer - INFO - TTA enabled with 4 views: ['hflip', 'vflip', 'rotate']
2025-05-08 16:07:11,599 - phase5_multimodal_hpo.finetune.trainer - INFO - Finetuner initialized. Device=cuda, AccumSteps=2
2025-05-08 16:07:11,599 - __main__ - INFO - Starting training from epoch 1 for 200 total epochs... Monitoring: accuracy
2025-05-08 16:07:27,477 - __main__ - ERROR - A critical error occurred during the training session: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 14.58 GiB of which 3.69 GiB is free. Process 315877 has 10.88 GiB memory in use. Of the allocated memory 8.93 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 931, in <module>
    run_training_session(config)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 828, in run_training_session
    avg_train_loss = trainer.train_one_epoch(train_loader, epoch, config["epochs"])
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/finetune/trainer.py", line 439, in train_one_epoch
    outputs = self.model(rgb_images, spectral_images)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/models/hvt_xl.py", line 315, in forward
    fused_features = self.forward_features(rgb, spectral)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/models/hvt_xl.py", line 294, in forward_features
    x_rgb, x_spec = self.dfca_modules[i](x_rgb, x_spec)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/models/hvt_xl.py", line 116, in forward
    rgb_enhanced, _ = self.rgb_to_spectral_attn(rgb_norm, spectral_norm, spectral_norm)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py", line 5444, in multi_head_attention_forward
    attn_output_weights = dropout(attn_output_weights, p=dropout_p)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py", line 1268, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 14.58 GiB of which 3.69 GiB is free. Process 315877 has 10.88 GiB memory in use. Of the allocated memory 8.93 GiB is allocated by PyTorch, and 1.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-08 16:10:49,129 - root - INFO - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/logs/phase5_high_acc.log
2025-05-08 16:10:49,129 - __main__ - INFO - --------- Starting New Training Session ---------
2025-05-08 16:10:49,129 - __main__ - INFO - Using device: cuda
2025-05-08 16:10:49,129 - __main__ - INFO - Random seed: 42
2025-05-08 16:10:49,129 - __main__ - INFO - Effective Configuration:
2025-05-08 16:10:49,129 - __main__ - INFO -   seed: 42
2025-05-08 16:10:49,130 - __main__ - INFO -   device: cuda
2025-05-08 16:10:49,130 - __main__ - INFO -   log_dir: logs
2025-05-08 16:10:49,130 - __main__ - INFO -   log_file_finetune: phase5_high_acc.log
2025-05-08 16:10:49,130 - __main__ - INFO -   checkpoint_dir: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints
2025-05-08 16:10:49,130 - __main__ - INFO -   best_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth
2025-05-08 16:10:49,130 - __main__ - INFO -   final_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_final_90percent.pth
2025-05-08 16:10:49,130 - __main__ - INFO -   data_root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection
2025-05-08 16:10:49,130 - __main__ - INFO -   train_split_ratio: 0.85
2025-05-08 16:10:49,130 - __main__ - INFO -   num_classes: 7
2025-05-08 16:10:49,130 - __main__ - INFO -   num_workers: 12
2025-05-08 16:10:49,130 - __main__ - INFO -   normalize_data: True
2025-05-08 16:10:49,130 - __main__ - INFO -   model_name: DiseaseAwareHVT_XL
2025-05-08 16:10:49,130 - __main__ - INFO -   pretrained_checkpoint_path: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth
2025-05-08 16:10:49,130 - __main__ - INFO -   load_pretrained: True
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_patch_size: 14
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_embed_dim_rgb: 128
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_embed_dim_spectral: 128
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_spectral_channels: 3
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_depths: [3, 6, 18, 3]
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_num_heads: [4, 8, 16, 32]
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_mlp_ratio: 4.0
2025-05-08 16:10:49,130 - __main__ - INFO -   hvt_qkv_bias: True
2025-05-08 16:10:49,131 - __main__ - INFO -   hvt_model_drop_rate: 0.2
2025-05-08 16:10:49,131 - __main__ - INFO -   hvt_attn_drop_rate: 0.1
2025-05-08 16:10:49,131 - __main__ - INFO -   hvt_drop_path_rate: 0.3
2025-05-08 16:10:49,131 - __main__ - INFO -   hvt_use_dfca: True
2025-05-08 16:10:49,131 - __main__ - INFO -   hvt_dfca_heads: 16
2025-05-08 16:10:49,131 - __main__ - INFO -   img_size: (512, 512)
2025-05-08 16:10:49,131 - __main__ - INFO -   epochs: 200
2025-05-08 16:10:49,131 - __main__ - INFO -   batch_size: 64
2025-05-08 16:10:49,131 - __main__ - INFO -   accumulation_steps: 2
2025-05-08 16:10:49,131 - __main__ - INFO -   amp_enabled: True
2025-05-08 16:10:49,131 - __main__ - INFO -   clip_grad_norm: 3.0
2025-05-08 16:10:49,131 - __main__ - INFO -   log_interval: 50
2025-05-08 16:10:49,131 - __main__ - INFO -   optimizer: LAMB
2025-05-08 16:10:49,131 - __main__ - INFO -   learning_rate: 0.0003
2025-05-08 16:10:49,131 - __main__ - INFO -   weight_decay: 0.02
2025-05-08 16:10:49,131 - __main__ - INFO -   optimizer_params: {'betas': (0.9, 0.999)}
2025-05-08 16:10:49,131 - __main__ - INFO -   layer_decay: 0.75
2025-05-08 16:10:49,131 - __main__ - INFO -   freeze_backbone_epochs: 10
2025-05-08 16:10:49,131 - __main__ - INFO -   head_lr_factor: 10.0
2025-05-08 16:10:49,131 - __main__ - INFO -   use_llrd: True
2025-05-08 16:10:49,131 - __main__ - INFO -   llrd_rate: 0.85
2025-05-08 16:10:49,131 - __main__ - INFO -   loss_type: focal
2025-05-08 16:10:49,131 - __main__ - INFO -   focal_alpha: None
2025-05-08 16:10:49,132 - __main__ - INFO -   focal_gamma: 2.0
2025-05-08 16:10:49,132 - __main__ - INFO -   label_smoothing: 0.15
2025-05-08 16:10:49,132 - __main__ - INFO -   use_weighted_sampler: False
2025-05-08 16:10:49,132 - __main__ - INFO -   use_weighted_loss: True
2025-05-08 16:10:49,132 - __main__ - INFO -   augmentations_enabled: True
2025-05-08 16:10:49,132 - __main__ - INFO -   rand_augment_num_ops: 3
2025-05-08 16:10:49,132 - __main__ - INFO -   rand_augment_magnitude: 12
2025-05-08 16:10:49,132 - __main__ - INFO -   color_jitter_params: {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}
2025-05-08 16:10:49,132 - __main__ - INFO -   random_erase_prob: 0.3
2025-05-08 16:10:49,132 - __main__ - INFO -   mixup_alpha: 0.4
2025-05-08 16:10:49,132 - __main__ - INFO -   cutmix_alpha: 0.4
2025-05-08 16:10:49,132 - __main__ - INFO -   mixup_cutmix_prob: 0.7
2025-05-08 16:10:49,132 - __main__ - INFO -   auto_augment_policy: None
2025-05-08 16:10:49,132 - __main__ - INFO -   ema_decay: 0.999
2025-05-08 16:10:49,132 - __main__ - INFO -   scheduler: CosineAnnealingLR
2025-05-08 16:10:49,132 - __main__ - INFO -   warmup_epochs: 15
2025-05-08 16:10:49,132 - __main__ - INFO -   warmup_lr_init_factor: 0.01
2025-05-08 16:10:49,132 - __main__ - INFO -   min_lr: 1e-06
2025-05-08 16:10:49,132 - __main__ - INFO -   cosine_t_0: 10
2025-05-08 16:10:49,132 - __main__ - INFO -   cosine_t_mult: 2
2025-05-08 16:10:49,132 - __main__ - INFO -   reducelr_factor: 0.2
2025-05-08 16:10:49,132 - __main__ - INFO -   reducelr_patience: 10
2025-05-08 16:10:49,132 - __main__ - INFO -   evaluate_every_n_epochs: 1
2025-05-08 16:10:49,132 - __main__ - INFO -   early_stopping_patience: 25
2025-05-08 16:10:49,133 - __main__ - INFO -   metric_to_monitor: accuracy
2025-05-08 16:10:49,133 - __main__ - INFO -   tta_enabled: True
2025-05-08 16:10:49,133 - __main__ - INFO -   tta_augmentations: ['hflip', 'vflip', 'rotate']
2025-05-08 16:10:49,133 - __main__ - INFO -   hpo_enabled: False
2025-05-08 16:10:49,133 - __main__ - INFO -   hpo_n_trials: 150
2025-05-08 16:10:49,133 - __main__ - INFO -   hpo_study_name: disease_hvt_xl_phase5_hpo
2025-05-08 16:10:49,133 - __main__ - INFO -   hpo_storage_db: sqlite:///hpo_phase5_study.db
2025-05-08 16:10:49,133 - __main__ - INFO -   hpo_params_ranges: {'learning_rate': (1e-05, 0.001, 'log'), 'weight_decay': (0.001, 0.1, 'log'), 'llrd_rate': (0.7, 0.95, 'uniform'), 'mixup_alpha': (0.1, 0.8, 'uniform'), 'label_smoothing': (0.0, 0.2, 'uniform'), 'hvt_drop_path_rate': (0.1, 0.5, 'uniform'), 'focal_gamma': (1.0, 3.0, 'uniform')}
2025-05-08 16:10:49,134 - __main__ - INFO - Setting up datasets...
2025-05-08 16:10:49,134 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: train
2025-05-08 16:10:49,134 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 16:12:50,456 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 16:13:36,799 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 16:13:36,800 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'train' size: 7766 samples.
2025-05-08 16:13:36,800 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: val
2025-05-08 16:13:36,800 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 16:13:37,144 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 16:13:37,677 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 16:13:37,678 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'val' size: 1371 samples.
2025-05-08 16:13:37,691 - phase5_multimodal_hpo.dataset - INFO - Computed class weights for split 'train': [1.03 0.9  1.06 1.02 1.06 0.83 1.16]
2025-05-08 16:13:37,691 - __main__ - INFO - Class weights will be used in the loss function.
2025-05-08 16:13:37,692 - __main__ - INFO - Loaders created. Train batches: 121, Val batches: 22. Num workers: 12
2025-05-08 16:13:37,692 - __main__ - INFO - Initializing model: DiseaseAwareHVT_XL
2025-05-08 16:13:37,894 - __main__ - WARNING - Pretrained checkpoint not found: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth. Training from scratch or as initialized.
2025-05-08 16:13:38,136 - __main__ - INFO - Freezing backbone layers for initial 10 epochs.
2025-05-08 16:13:38,139 - __main__ - INFO - Frozen phase: Setting head LR with factor 10.0.
2025-05-08 16:13:38,141 - __main__ - INFO - Using LAMB optimizer.
2025-05-08 16:13:38,141 - __main__ - INFO - Warmup scheduler: LinearLR for 15 epochs, start_factor 0.01.
2025-05-08 16:13:38,141 - __main__ - INFO - Main scheduler: CosineAnnealingLR, T_max=185, eta_min=1e-06.
2025-05-08 16:13:38,141 - __main__ - INFO - Using SequentialLR combining warmup and main scheduler.
2025-05-08 16:13:38,149 - phase5_multimodal_hpo.finetune.trainer - INFO - EMA enabled with decay: 0.999
2025-05-08 16:13:38,149 - phase5_multimodal_hpo.finetune.trainer - INFO - Using Focal Loss with gamma=2.0, label_smoothing=0.15
2025-05-08 16:13:38,149 - phase5_multimodal_hpo.finetune.trainer - INFO - Augmentations enabled for training.
2025-05-08 16:13:38,149 - phase5_multimodal_hpo.finetune.trainer - INFO - Using RandAugment with num_ops=3, magnitude=12
2025-05-08 16:13:38,151 - phase5_multimodal_hpo.finetune.trainer - INFO - Random Erasing enabled with p=0.3
2025-05-08 16:13:38,155 - phase5_multimodal_hpo.finetune.trainer - INFO - Mixup/Cutmix enabled: p=0.7, mixup_alpha=0.4, cutmix_alpha=0.4
2025-05-08 16:13:38,155 - phase5_multimodal_hpo.finetune.trainer - INFO - TTA enabled with 4 views: ['hflip', 'vflip', 'rotate']
2025-05-08 16:13:38,155 - phase5_multimodal_hpo.finetune.trainer - INFO - Finetuner initialized. Device=cuda, AccumSteps=2
2025-05-08 16:13:38,155 - __main__ - INFO - Starting training from epoch 1 for 200 total epochs... Monitoring: accuracy
2025-05-08 16:16:51,026 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 1 training finished. Average Loss: 1.4682, Current LR: 3.00e-05
2025-05-08 16:18:30,195 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4377, accuracy: 0.1568, f1_macro: 0.1204, f1_weighted: 0.1224, precision_macro: 0.1189, precision_weighted: 0.1197, recall_macro: 0.1504, recall_weighted: 0.1568, f1_Bacterial_Blight: 0.0700, f1_Curl_Virus: 0.0931, f1_Healthy_Leaf: 0.0320, f1_Herbicide_Growth_Damage: 0.1743, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2463, f1_Leaf_Variegation: 0.2273 (TTA: 4 views)
2025-05-08 16:18:30,222 - __main__ - INFO - Epoch 1/200 Summary | Train Loss: 1.4682 | Val Loss: 1.4377 | Val Acc: 0.1568 | Val F1w: 0.1224 | Monitor (accuracy): 0.1568 | LR: 4.26e-04 | Train Time: 192.92s | Val Time: 99.15s
2025-05-08 16:18:30,312 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 1, Best Metric: 0.1568)
2025-05-08 16:18:30,313 - __main__ - INFO - Epoch 1: New best validation accuracy: 0.1568. Checkpoint saved.
2025-05-08 16:21:36,938 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 2 training finished. Average Loss: 1.4569, Current LR: 4.26e-04
2025-05-08 16:23:15,490 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4358, accuracy: 0.1627, f1_macro: 0.1249, f1_weighted: 0.1272, precision_macro: 0.1241, precision_weighted: 0.1251, recall_macro: 0.1557, recall_weighted: 0.1627, f1_Bacterial_Blight: 0.0711, f1_Curl_Virus: 0.1007, f1_Healthy_Leaf: 0.0323, f1_Herbicide_Growth_Damage: 0.1918, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2540, f1_Leaf_Variegation: 0.2245 (TTA: 4 views)
2025-05-08 16:23:15,524 - __main__ - INFO - Epoch 2/200 Summary | Train Loss: 1.4569 | Val Loss: 1.4358 | Val Acc: 0.1627 | Val F1w: 0.1272 | Monitor (accuracy): 0.1627 | LR: 8.22e-04 | Train Time: 186.66s | Val Time: 98.55s
2025-05-08 16:23:15,684 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 2, Best Metric: 0.1627)
2025-05-08 16:23:15,685 - __main__ - INFO - Epoch 2: New best validation accuracy: 0.1627. Checkpoint saved.
2025-05-08 16:26:23,045 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 3 training finished. Average Loss: 1.4371, Current LR: 8.22e-04
2025-05-08 16:28:02,338 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4329, accuracy: 0.1634, f1_macro: 0.1239, f1_weighted: 0.1273, precision_macro: 0.1268, precision_weighted: 0.1285, recall_macro: 0.1540, recall_weighted: 0.1634, f1_Bacterial_Blight: 0.0711, f1_Curl_Virus: 0.0955, f1_Healthy_Leaf: 0.0403, f1_Herbicide_Growth_Damage: 0.1818, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2723, f1_Leaf_Variegation: 0.2061 (TTA: 4 views)
2025-05-08 16:28:02,373 - __main__ - INFO - Epoch 3/200 Summary | Train Loss: 1.4371 | Val Loss: 1.4329 | Val Acc: 0.1634 | Val F1w: 0.1273 | Monitor (accuracy): 0.1634 | LR: 1.22e-03 | Train Time: 187.36s | Val Time: 99.33s
2025-05-08 16:28:02,531 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 3, Best Metric: 0.1634)
2025-05-08 16:28:02,532 - __main__ - INFO - Epoch 3: New best validation accuracy: 0.1634. Checkpoint saved.
2025-05-08 16:31:09,073 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 4 training finished. Average Loss: 1.4343, Current LR: 1.22e-03
2025-05-08 16:32:47,621 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4271, accuracy: 0.1721, f1_macro: 0.1308, f1_weighted: 0.1355, precision_macro: 0.1336, precision_weighted: 0.1363, recall_macro: 0.1609, recall_weighted: 0.1721, f1_Bacterial_Blight: 0.0682, f1_Curl_Virus: 0.1134, f1_Healthy_Leaf: 0.0480, f1_Herbicide_Growth_Damage: 0.1972, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2963, f1_Leaf_Variegation: 0.1922 (TTA: 4 views)
2025-05-08 16:32:47,625 - __main__ - INFO - Epoch 4/200 Summary | Train Loss: 1.4343 | Val Loss: 1.4271 | Val Acc: 0.1721 | Val F1w: 0.1355 | Monitor (accuracy): 0.1721 | LR: 1.61e-03 | Train Time: 186.54s | Val Time: 98.55s
2025-05-08 16:32:47,789 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 4, Best Metric: 0.1721)
2025-05-08 16:32:47,790 - __main__ - INFO - Epoch 4: New best validation accuracy: 0.1721. Checkpoint saved.
2025-05-08 16:35:54,873 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 5 training finished. Average Loss: 1.4284, Current LR: 1.61e-03
2025-05-08 16:37:33,163 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4193, accuracy: 0.1926, f1_macro: 0.1494, f1_weighted: 0.1551, precision_macro: 0.1515, precision_weighted: 0.1548, recall_macro: 0.1799, recall_weighted: 0.1926, f1_Bacterial_Blight: 0.0993, f1_Curl_Virus: 0.1223, f1_Healthy_Leaf: 0.0551, f1_Herbicide_Growth_Damage: 0.2470, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.3355, f1_Leaf_Variegation: 0.1863 (TTA: 4 views)
2025-05-08 16:37:33,172 - __main__ - INFO - Epoch 5/200 Summary | Train Loss: 1.4284 | Val Loss: 1.4193 | Val Acc: 0.1926 | Val F1w: 0.1551 | Monitor (accuracy): 0.1926 | LR: 2.01e-03 | Train Time: 187.13s | Val Time: 98.25s
2025-05-08 16:37:33,323 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 5, Best Metric: 0.1926)
2025-05-08 16:37:33,324 - __main__ - INFO - Epoch 5: New best validation accuracy: 0.1926. Checkpoint saved.
2025-05-08 16:40:40,358 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 6 training finished. Average Loss: 1.4166, Current LR: 2.01e-03
2025-05-08 16:42:19,652 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4096, accuracy: 0.2064, f1_macro: 0.1638, f1_weighted: 0.1701, precision_macro: 0.1563, precision_weighted: 0.1593, recall_macro: 0.1932, recall_weighted: 0.2064, f1_Bacterial_Blight: 0.1438, f1_Curl_Virus: 0.1323, f1_Healthy_Leaf: 0.0427, f1_Herbicide_Growth_Damage: 0.2569, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.3798, f1_Leaf_Variegation: 0.1911 (TTA: 4 views)
2025-05-08 16:42:19,655 - __main__ - INFO - Epoch 6/200 Summary | Train Loss: 1.4166 | Val Loss: 1.4096 | Val Acc: 0.2064 | Val F1w: 0.1701 | Monitor (accuracy): 0.2064 | LR: 2.41e-03 | Train Time: 187.05s | Val Time: 99.28s
2025-05-08 16:42:19,807 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 6, Best Metric: 0.2064)
2025-05-08 16:42:19,808 - __main__ - INFO - Epoch 6: New best validation accuracy: 0.2064. Checkpoint saved.
2025-05-08 16:45:27,771 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 7 training finished. Average Loss: 1.4115, Current LR: 2.41e-03
2025-05-08 16:47:05,846 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3989, accuracy: 0.2203, f1_macro: 0.1842, f1_weighted: 0.1914, precision_macro: 0.1711, precision_weighted: 0.1758, recall_macro: 0.2086, recall_weighted: 0.2203, f1_Bacterial_Blight: 0.1694, f1_Curl_Virus: 0.1453, f1_Healthy_Leaf: 0.0492, f1_Herbicide_Growth_Damage: 0.3016, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.4245, f1_Leaf_Variegation: 0.1994 (TTA: 4 views)
2025-05-08 16:47:05,850 - __main__ - INFO - Epoch 7/200 Summary | Train Loss: 1.4115 | Val Loss: 1.3989 | Val Acc: 0.2203 | Val F1w: 0.1914 | Monitor (accuracy): 0.2203 | LR: 2.80e-03 | Train Time: 187.96s | Val Time: 98.08s
2025-05-08 16:47:05,991 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 7, Best Metric: 0.2203)
2025-05-08 16:47:05,992 - __main__ - INFO - Epoch 7: New best validation accuracy: 0.2203. Checkpoint saved.
2025-05-08 16:50:13,403 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 8 training finished. Average Loss: 1.4091, Current LR: 2.80e-03
2025-05-08 16:51:51,762 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3869, accuracy: 0.2312, f1_macro: 0.2028, f1_weighted: 0.2115, precision_macro: 0.1907, precision_weighted: 0.1981, recall_macro: 0.2206, recall_weighted: 0.2312, f1_Bacterial_Blight: 0.2182, f1_Curl_Virus: 0.1426, f1_Healthy_Leaf: 0.0812, f1_Herbicide_Growth_Damage: 0.2969, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.4811, f1_Leaf_Variegation: 0.1994 (TTA: 4 views)
2025-05-08 16:51:51,774 - __main__ - INFO - Epoch 8/200 Summary | Train Loss: 1.4091 | Val Loss: 1.3869 | Val Acc: 0.2312 | Val F1w: 0.2115 | Monitor (accuracy): 0.2312 | LR: 3.00e-03 | Train Time: 187.41s | Val Time: 98.37s
2025-05-08 16:51:51,938 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 8, Best Metric: 0.2312)
2025-05-08 16:51:51,939 - __main__ - INFO - Epoch 8: New best validation accuracy: 0.2312. Checkpoint saved.
2025-05-08 16:54:58,821 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 9 training finished. Average Loss: 1.4007, Current LR: 3.00e-03
2025-05-08 16:56:37,202 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3746, accuracy: 0.2422, f1_macro: 0.2216, f1_weighted: 0.2299, precision_macro: 0.2175, precision_weighted: 0.2265, recall_macro: 0.2354, recall_weighted: 0.2422, f1_Bacterial_Blight: 0.2670, f1_Curl_Virus: 0.1236, f1_Healthy_Leaf: 0.0911, f1_Herbicide_Growth_Damage: 0.2776, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.5325, f1_Leaf_Variegation: 0.2593 (TTA: 4 views)
2025-05-08 16:56:37,205 - __main__ - INFO - Epoch 9/200 Summary | Train Loss: 1.4007 | Val Loss: 1.3746 | Val Acc: 0.2422 | Val F1w: 0.2299 | Monitor (accuracy): 0.2422 | LR: 3.00e-03 | Train Time: 186.94s | Val Time: 98.33s
2025-05-08 16:56:37,363 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 9, Best Metric: 0.2422)
2025-05-08 16:56:37,363 - __main__ - INFO - Epoch 9: New best validation accuracy: 0.2422. Checkpoint saved.
2025-05-08 16:56:37,365 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 10: Multi-scale training. Resizing to (602, 602) (factor 1.20)
2025-05-08 17:03:54,776 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 10 training finished. Average Loss: 1.3994, Current LR: 3.00e-03
2025-05-08 17:05:33,634 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3628, accuracy: 0.2516, f1_macro: 0.2329, f1_weighted: 0.2415, precision_macro: 0.2357, precision_weighted: 0.2474, recall_macro: 0.2476, recall_weighted: 0.2516, f1_Bacterial_Blight: 0.3077, f1_Curl_Virus: 0.1005, f1_Healthy_Leaf: 0.1174, f1_Herbicide_Growth_Damage: 0.2671, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.5631, f1_Leaf_Variegation: 0.2747 (TTA: 4 views)
2025-05-08 17:05:33,637 - __main__ - INFO - Epoch 10/200 Summary | Train Loss: 1.3994 | Val Loss: 1.3628 | Val Acc: 0.2516 | Val F1w: 0.2415 | Monitor (accuracy): 0.2516 | LR: 2.99e-03 | Train Time: 437.41s | Val Time: 98.86s
2025-05-08 17:05:33,801 - phase5_multimodal_hpo.finetune.trainer - INFO - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 10, Best Metric: 0.2516)
2025-05-08 17:05:33,802 - __main__ - INFO - Epoch 10: New best validation accuracy: 0.2516. Checkpoint saved.
2025-05-08 17:05:33,802 - __main__ - INFO - Epoch 11: *** Unfreezing backbone ***
2025-05-08 17:05:33,804 - __main__ - INFO - Applying LLRD with decay rate: 0.85
2025-05-08 17:05:33,809 - __main__ - INFO - LLRD: Assigning base_lr to unassigned param: norm_rgb_final.weight
2025-05-08 17:05:33,809 - __main__ - INFO - LLRD: Assigning base_lr to unassigned param: norm_rgb_final.bias
2025-05-08 17:05:33,810 - __main__ - INFO - LLRD: Assigning base_lr to unassigned param: norm_spectral_final.weight
2025-05-08 17:05:33,810 - __main__ - INFO - LLRD: Assigning base_lr to unassigned param: norm_spectral_final.bias
2025-05-08 17:05:33,820 - __main__ - INFO - Optimizer re-initialized for full model fine-tuning with base LR: 0.0003.
2025-05-08 17:05:33,820 - __main__ - INFO - Scheduler re-initialized for unfreeze phase: CosineAnnealingLR
2025-05-08 17:05:36,146 - __main__ - ERROR - A critical error occurred during the training session: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.05 GiB is free. Process 5461 has 78.03 GiB memory in use. Of the allocated memory 75.46 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 931, in <module>
    run_training_session(config)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/main.py", line 828, in run_training_session
    avg_train_loss = trainer.train_one_epoch(train_loader, epoch, config["epochs"])
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/finetune/trainer.py", line 439, in train_one_epoch
    outputs = self.model(rgb_images, spectral_images)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/models/hvt_xl.py", line 315, in forward
    fused_features = self.forward_features(rgb, spectral)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/models/hvt_xl.py", line 289, in forward_features
    x_rgb = blk_rgb(x_rgb)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/models/hvt_xl.py", line 74, in forward
    attn_output, _ = self.attn(self.norm1(x), self.norm1(x), self.norm1(x))
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py", line 5442, in multi_head_attention_forward
    attn_output_weights = softmax(attn_output_weights, dim=-1)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py", line 1858, in softmax
    ret = input.softmax(dim)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.05 GiB is free. Process 5461 has 78.03 GiB memory in use. Of the allocated memory 75.46 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-08 17:21:37,017 - root - INFO - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/logs/phase5_high_acc.log
2025-05-08 17:21:37,023 - __main__ - INFO - --------- Starting New Training Session ---------
2025-05-08 17:21:37,023 - __main__ - INFO - Using device: cuda
2025-05-08 17:21:37,023 - __main__ - INFO - Random seed: 42
2025-05-08 17:21:37,023 - __main__ - INFO - Effective Configuration:
2025-05-08 17:21:37,023 - __main__ - INFO -   seed: 42
2025-05-08 17:21:37,023 - __main__ - INFO -   device: cuda
2025-05-08 17:21:37,023 - __main__ - INFO -   log_dir: logs
2025-05-08 17:21:37,023 - __main__ - INFO -   log_file_finetune: phase5_high_acc.log
2025-05-08 17:21:37,023 - __main__ - INFO -   checkpoint_dir: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints
2025-05-08 17:21:37,023 - __main__ - INFO -   best_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth
2025-05-08 17:21:37,023 - __main__ - INFO -   final_model_path: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_final_90percent.pth
2025-05-08 17:21:37,023 - __main__ - INFO -   resume_from_best: False
2025-05-08 17:21:37,023 - __main__ - INFO -   resume_checkpoint_path: None
2025-05-08 17:21:37,023 - __main__ - INFO -   data_root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection
2025-05-08 17:21:37,023 - __main__ - INFO -   train_split_ratio: 0.85
2025-05-08 17:21:37,023 - __main__ - INFO -   num_classes: 7
2025-05-08 17:21:37,023 - __main__ - INFO -   num_workers: 8
2025-05-08 17:21:37,024 - __main__ - INFO -   normalize_data: True
2025-05-08 17:21:37,024 - __main__ - INFO -   model_name: DiseaseAwareHVT_XL
2025-05-08 17:21:37,024 - __main__ - INFO -   pretrained_checkpoint_path: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth
2025-05-08 17:21:37,024 - __main__ - INFO -   load_pretrained: True
2025-05-08 17:21:37,024 - __main__ - INFO -   use_gradient_checkpointing: True
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_patch_size: 14
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_embed_dim_rgb: 128
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_embed_dim_spectral: 128
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_spectral_channels: 3
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_depths: [3, 6, 18, 3]
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_num_heads: [4, 8, 16, 32]
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_mlp_ratio: 4.0
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_qkv_bias: True
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_model_drop_rate: 0.2
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_attn_drop_rate: 0.1
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_drop_path_rate: 0.3
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_use_dfca: True
2025-05-08 17:21:37,024 - __main__ - INFO -   hvt_dfca_heads: 16
2025-05-08 17:21:37,024 - __main__ - INFO -   img_size: (448, 448)
2025-05-08 17:21:37,024 - __main__ - INFO -   epochs: 200
2025-05-08 17:21:37,024 - __main__ - INFO -   batch_size: 32
2025-05-08 17:21:37,024 - __main__ - INFO -   accumulation_steps: 4
2025-05-08 17:21:37,024 - __main__ - INFO -   amp_enabled: True
2025-05-08 17:21:37,025 - __main__ - INFO -   clip_grad_norm: 3.0
2025-05-08 17:21:37,025 - __main__ - INFO -   log_interval: 50
2025-05-08 17:21:37,025 - __main__ - INFO -   optimizer: LAMB
2025-05-08 17:21:37,025 - __main__ - INFO -   learning_rate: 0.0003
2025-05-08 17:21:37,025 - __main__ - INFO -   weight_decay: 0.02
2025-05-08 17:21:37,025 - __main__ - INFO -   optimizer_params: {'betas': (0.9, 0.999)}
2025-05-08 17:21:37,025 - __main__ - INFO -   layer_decay: 0.75
2025-05-08 17:21:37,025 - __main__ - INFO -   freeze_backbone_epochs: 10
2025-05-08 17:21:37,025 - __main__ - INFO -   head_lr_factor: 10.0
2025-05-08 17:21:37,025 - __main__ - INFO -   use_llrd: True
2025-05-08 17:21:37,025 - __main__ - INFO -   llrd_rate: 0.85
2025-05-08 17:21:37,025 - __main__ - INFO -   loss_type: focal
2025-05-08 17:21:37,025 - __main__ - INFO -   focal_alpha: None
2025-05-08 17:21:37,025 - __main__ - INFO -   focal_gamma: 2.0
2025-05-08 17:21:37,025 - __main__ - INFO -   label_smoothing: 0.15
2025-05-08 17:21:37,025 - __main__ - INFO -   use_weighted_sampler: False
2025-05-08 17:21:37,025 - __main__ - INFO -   use_weighted_loss: True
2025-05-08 17:21:37,025 - __main__ - INFO -   augmentations_enabled: True
2025-05-08 17:21:37,025 - __main__ - INFO -   rand_augment_num_ops: 3
2025-05-08 17:21:37,025 - __main__ - INFO -   rand_augment_magnitude: 12
2025-05-08 17:21:37,026 - __main__ - INFO -   color_jitter_params: {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}
2025-05-08 17:21:37,026 - __main__ - INFO -   random_erase_prob: 0.3
2025-05-08 17:21:37,026 - __main__ - INFO -   mixup_alpha: 0.4
2025-05-08 17:21:37,026 - __main__ - INFO -   cutmix_alpha: 0.4
2025-05-08 17:21:37,026 - __main__ - INFO -   mixup_cutmix_prob: 0.7
2025-05-08 17:21:37,026 - __main__ - INFO -   auto_augment_policy: None
2025-05-08 17:21:37,026 - __main__ - INFO -   multi_scale_training_epoch_interval: 10
2025-05-08 17:21:37,026 - __main__ - INFO -   multi_scale_training_factors: [0.8, 1.0, 1.1]
2025-05-08 17:21:37,026 - __main__ - INFO -   multi_scale_max_factor_after_unfreeze: 1.0
2025-05-08 17:21:37,026 - __main__ - INFO -   ema_decay: 0.999
2025-05-08 17:21:37,026 - __main__ - INFO -   scheduler: CosineAnnealingLR
2025-05-08 17:21:37,026 - __main__ - INFO -   warmup_epochs: 15
2025-05-08 17:21:37,026 - __main__ - INFO -   warmup_lr_init_factor: 0.01
2025-05-08 17:21:37,026 - __main__ - INFO -   min_lr: 1e-06
2025-05-08 17:21:37,026 - __main__ - INFO -   cosine_t_0: 10
2025-05-08 17:21:37,026 - __main__ - INFO -   cosine_t_mult: 2
2025-05-08 17:21:37,026 - __main__ - INFO -   reducelr_factor: 0.2
2025-05-08 17:21:37,026 - __main__ - INFO -   reducelr_patience: 10
2025-05-08 17:21:37,026 - __main__ - INFO -   evaluate_every_n_epochs: 1
2025-05-08 17:21:37,026 - __main__ - INFO -   early_stopping_patience: 25
2025-05-08 17:21:37,027 - __main__ - INFO -   metric_to_monitor: accuracy
2025-05-08 17:21:37,027 - __main__ - INFO -   tta_enabled: True
2025-05-08 17:21:37,027 - __main__ - INFO -   tta_augmentations: ['hflip', 'vflip', 'rotate']
2025-05-08 17:21:37,027 - __main__ - INFO -   hpo_enabled: False
2025-05-08 17:21:37,027 - __main__ - INFO -   hpo_n_trials: 150
2025-05-08 17:21:37,027 - __main__ - INFO -   hpo_study_name: disease_hvt_xl_phase5_hpo
2025-05-08 17:21:37,027 - __main__ - INFO -   hpo_storage_db: sqlite:///hpo_phase5_study.db
2025-05-08 17:21:37,027 - __main__ - INFO -   hpo_params_ranges: {'learning_rate': (1e-05, 0.001, 'log'), 'weight_decay': (0.001, 0.1, 'log'), 'llrd_rate': (0.7, 0.95, 'uniform'), 'mixup_alpha': (0.1, 0.8, 'uniform'), 'label_smoothing': (0.0, 0.2, 'uniform'), 'hvt_drop_path_rate': (0.1, 0.5, 'uniform'), 'focal_gamma': (1.0, 3.0, 'uniform')}
2025-05-08 17:21:37,028 - __main__.run_session - INFO - Setting up datasets...
2025-05-08 17:21:37,028 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: train
2025-05-08 17:21:37,028 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 17:21:37,343 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 17:21:37,850 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 17:21:37,851 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'train' size: 7766 samples.
2025-05-08 17:21:37,852 - phase5_multimodal_hpo.dataset - INFO - Initializing SARCLD2024Dataset from: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection for split: val
2025-05-08 17:21:37,852 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Original Dataset
2025-05-08 17:21:38,152 - phase5_multimodal_hpo.dataset - INFO - Scanning dataset type: Augmented Dataset
2025-05-08 17:21:38,639 - phase5_multimodal_hpo.dataset - INFO - Total valid image tuples found: 9137
2025-05-08 17:21:38,640 - phase5_multimodal_hpo.dataset - INFO - Dataset split 'val' size: 1371 samples.
2025-05-08 17:21:38,642 - phase5_multimodal_hpo.dataset - INFO - Computed class weights for split 'train': [1.03 0.9  1.06 1.02 1.06 0.83 1.16]
2025-05-08 17:21:38,642 - __main__.run_session - INFO - Class weights will be used in loss.
2025-05-08 17:21:38,642 - __main__.run_session - INFO - Loaders: Train 242 batches, Val 43 batches. Workers: 8
2025-05-08 17:21:38,643 - __main__.run_session - INFO - Initializing model: DiseaseAwareHVT_XL
2025-05-08 17:21:38,802 - __main__.run_session - INFO - Gradient checkpointing enabled for model.
2025-05-08 17:21:38,802 - __main__.load_weights - WARNING - Pretrained ckpt not found: /teamspace/studios/this_studio/cvpr25/pretrain_checkpoints/hvt_xl_pretrain.pth. Training from scratch/as init.
2025-05-08 17:21:39,009 - __main__.run_session - INFO - Freezing backbone for initial 10 epochs.
2025-05-08 17:21:39,011 - __main__.param_groups - INFO - Frozen phase: Head LR factor 10.0.
2025-05-08 17:21:39,012 - __main__.run_session - INFO - Using LAMB optimizer.
2025-05-08 17:21:39,012 - __main__.run_session - INFO - Warmup: LinearLR for 15 epochs, factor 0.01.
2025-05-08 17:21:39,012 - __main__.run_session - INFO - Main Sched: CosineAnnealingLR.
2025-05-08 17:21:39,012 - __main__.run_session - INFO - Using SequentialLR (Warmup + Main).
2025-05-08 17:21:39,017 - phase5_multimodal_hpo.finetune.trainer - INFO - EMA enabled with decay: 0.999
2025-05-08 17:21:39,017 - phase5_multimodal_hpo.finetune.trainer - INFO - Using Focal Loss with gamma=2.0, label_smoothing=0.15
2025-05-08 17:21:39,017 - phase5_multimodal_hpo.finetune.trainer - INFO - Augmentations enabled for training.
2025-05-08 17:21:39,018 - phase5_multimodal_hpo.finetune.trainer - INFO - Using RandAugment: ops=3, mag=12
2025-05-08 17:21:39,018 - phase5_multimodal_hpo.finetune.trainer - INFO - Random Erasing: p=0.3
2025-05-08 17:21:39,018 - phase5_multimodal_hpo.finetune.trainer - INFO - Mixup/Cutmix: p=0.7, mix_a=0.4, cut_a=0.4
2025-05-08 17:21:39,018 - phase5_multimodal_hpo.finetune.trainer - INFO - TTA enabled with 4 views: ['hflip', 'vflip', 'rotate']
2025-05-08 17:21:39,018 - phase5_multimodal_hpo.finetune.trainer - INFO - Finetuner initialized. Device=cuda, AccumSteps=4, BaseImgSize=(448, 448)
2025-05-08 17:21:39,019 - __main__.run_session - INFO - Starting training from E1 for 200 total epochs... Monitor: accuracy
2025-05-08 17:23:32,623 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 1 training finished. Avg Loss: 1.4818, Current LR: 3.00e-05
2025-05-08 17:24:29,132 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4816, accuracy: 0.0919, f1_macro: 0.0424, f1_weighted: 0.0369, precision_macro: 0.0495, precision_weighted: 0.0513, recall_macro: 0.1072, recall_weighted: 0.0919, f1_Bacterial_Blight: 0.1123, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0081, f1_Leaf_Variegation: 0.1763 (TTA: 4 views)
2025-05-08 17:24:29,135 - __main__.run_session - INFO - E1/200 Sum | TrL:1.4818 | VlL:1.4816 | VAcc:0.0919 | VF1w:0.0369 | Mon(accuracy):0.0919 | LR:4.26e-04 | TrT:113.7s | VlT:56.5s
2025-05-08 17:24:29,317 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 1, Best 0.0919)
2025-05-08 17:24:29,318 - __main__.run_session - INFO - E1: New best val accuracy: 0.0919. Ckpt saved.
2025-05-08 17:26:20,616 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 2 training finished. Avg Loss: 1.4624, Current LR: 4.26e-04
2025-05-08 17:27:16,978 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4789, accuracy: 0.0897, f1_macro: 0.0428, f1_weighted: 0.0380, precision_macro: 0.0635, precision_weighted: 0.0689, recall_macro: 0.1043, recall_weighted: 0.0897, f1_Bacterial_Blight: 0.1054, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0239, f1_Leaf_Variegation: 0.1703 (TTA: 4 views)
2025-05-08 17:27:16,982 - __main__.run_session - INFO - E2/200 Sum | TrL:1.4624 | VlL:1.4789 | VAcc:0.0897 | VF1w:0.0380 | Mon(accuracy):0.0897 | LR:8.22e-04 | TrT:111.3s | VlT:56.4s
2025-05-08 17:27:16,982 - __main__.run_session - INFO - E2: Val accuracy (0.0897) !improve from best (0.0919). Patience: 1/25
2025-05-08 17:29:08,383 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 3 training finished. Avg Loss: 1.4410, Current LR: 8.22e-04
2025-05-08 17:30:04,740 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4706, accuracy: 0.0985, f1_macro: 0.0509, f1_weighted: 0.0474, precision_macro: 0.0621, precision_weighted: 0.0669, recall_macro: 0.1131, recall_weighted: 0.0985, f1_Bacterial_Blight: 0.1054, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0717, f1_Leaf_Variegation: 0.1789 (TTA: 4 views)
2025-05-08 17:30:04,743 - __main__.run_session - INFO - E3/200 Sum | TrL:1.4410 | VlL:1.4706 | VAcc:0.0985 | VF1w:0.0474 | Mon(accuracy):0.0985 | LR:1.22e-03 | TrT:111.4s | VlT:56.3s
2025-05-08 17:30:04,906 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 3, Best 0.0985)
2025-05-08 17:30:04,906 - __main__.run_session - INFO - E3: New best val accuracy: 0.0985. Ckpt saved.
2025-05-08 17:31:56,390 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 4 training finished. Avg Loss: 1.4322, Current LR: 1.22e-03
2025-05-08 17:32:52,800 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4609, accuracy: 0.1116, f1_macro: 0.0615, f1_weighted: 0.0599, precision_macro: 0.0660, precision_weighted: 0.0711, recall_macro: 0.1260, recall_weighted: 0.1116, f1_Bacterial_Blight: 0.0991, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.1375, f1_Leaf_Variegation: 0.1942 (TTA: 4 views)
2025-05-08 17:32:52,802 - __main__.run_session - INFO - E4/200 Sum | TrL:1.4322 | VlL:1.4609 | VAcc:0.1116 | VF1w:0.0599 | Mon(accuracy):0.1116 | LR:1.61e-03 | TrT:111.5s | VlT:56.4s
2025-05-08 17:32:52,958 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 4, Best 0.1116)
2025-05-08 17:32:52,959 - __main__.run_session - INFO - E4: New best val accuracy: 0.1116. Ckpt saved.
2025-05-08 17:34:44,332 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 5 training finished. Avg Loss: 1.4198, Current LR: 1.61e-03
2025-05-08 17:35:40,673 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4488, accuracy: 0.1422, f1_macro: 0.0878, f1_weighted: 0.0909, precision_macro: 0.0888, precision_weighted: 0.0980, recall_macro: 0.1534, recall_weighted: 0.1422, f1_Bacterial_Blight: 0.1113, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2979, f1_Leaf_Variegation: 0.2053 (TTA: 4 views)
2025-05-08 17:35:40,682 - __main__.run_session - INFO - E5/200 Sum | TrL:1.4198 | VlL:1.4488 | VAcc:0.1422 | VF1w:0.0909 | Mon(accuracy):0.1422 | LR:2.01e-03 | TrT:111.4s | VlT:56.3s
2025-05-08 17:35:40,840 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 5, Best 0.1422)
2025-05-08 17:35:40,841 - __main__.run_session - INFO - E5: New best val accuracy: 0.1422. Ckpt saved.
2025-05-08 17:37:32,159 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 6 training finished. Avg Loss: 1.4042, Current LR: 2.01e-03
2025-05-08 17:38:28,480 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4351, accuracy: 0.1648, f1_macro: 0.1087, f1_weighted: 0.1155, precision_macro: 0.1273, precision_weighted: 0.1426, recall_macro: 0.1743, recall_weighted: 0.1648, f1_Bacterial_Blight: 0.1129, f1_Curl_Virus: 0.0091, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.4205, f1_Leaf_Variegation: 0.2183 (TTA: 4 views)
2025-05-08 17:38:28,486 - __main__.run_session - INFO - E6/200 Sum | TrL:1.4042 | VlL:1.4351 | VAcc:0.1648 | VF1w:0.1155 | Mon(accuracy):0.1648 | LR:2.41e-03 | TrT:111.3s | VlT:56.3s
2025-05-08 17:38:28,645 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 6, Best 0.1648)
2025-05-08 17:38:28,646 - __main__.run_session - INFO - E6: New best val accuracy: 0.1648. Ckpt saved.
2025-05-08 17:40:19,910 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 7 training finished. Avg Loss: 1.4004, Current LR: 2.41e-03
2025-05-08 17:41:16,306 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4225, accuracy: 0.1904, f1_macro: 0.1355, f1_weighted: 0.1480, precision_macro: 0.1850, precision_weighted: 0.2086, recall_macro: 0.1962, recall_weighted: 0.1904, f1_Bacterial_Blight: 0.0549, f1_Curl_Virus: 0.0178, f1_Healthy_Leaf: 0.0989, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.5464, f1_Leaf_Variegation: 0.2302 (TTA: 4 views)
2025-05-08 17:41:16,309 - __main__.run_session - INFO - E7/200 Sum | TrL:1.4004 | VlL:1.4225 | VAcc:0.1904 | VF1w:0.1480 | Mon(accuracy):0.1904 | LR:2.80e-03 | TrT:111.3s | VlT:56.4s
2025-05-08 17:41:16,438 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 7, Best 0.1904)
2025-05-08 17:41:16,439 - __main__.run_session - INFO - E7: New best val accuracy: 0.1904. Ckpt saved.
2025-05-08 17:43:07,806 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 8 training finished. Avg Loss: 1.3982, Current LR: 2.80e-03
2025-05-08 17:44:04,370 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4108, accuracy: 0.1947, f1_macro: 0.1510, f1_weighted: 0.1641, precision_macro: 0.2181, precision_weighted: 0.2446, recall_macro: 0.2006, recall_weighted: 0.1947, f1_Bacterial_Blight: 0.0271, f1_Curl_Virus: 0.0902, f1_Healthy_Leaf: 0.1404, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0258, f1_Leaf_Redding: 0.5352, f1_Leaf_Variegation: 0.2386 (TTA: 4 views)
2025-05-08 17:44:04,372 - __main__.run_session - INFO - E8/200 Sum | TrL:1.3982 | VlL:1.4108 | VAcc:0.1947 | VF1w:0.1641 | Mon(accuracy):0.1947 | LR:3.00e-03 | TrT:111.4s | VlT:56.5s
2025-05-08 17:44:04,526 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 8, Best 0.1947)
2025-05-08 17:44:04,526 - __main__.run_session - INFO - E8: New best val accuracy: 0.1947. Ckpt saved.
2025-05-08 17:45:55,959 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 9 training finished. Avg Loss: 1.3968, Current LR: 3.00e-03
2025-05-08 17:46:52,339 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4011, accuracy: 0.2086, f1_macro: 0.1797, f1_weighted: 0.1905, precision_macro: 0.2790, precision_weighted: 0.3039, recall_macro: 0.2119, recall_weighted: 0.2086, f1_Bacterial_Blight: 0.0427, f1_Curl_Virus: 0.0634, f1_Healthy_Leaf: 0.1219, f1_Herbicide_Growth_Damage: 0.0202, f1_Leaf_Hopper_Jassids: 0.2371, f1_Leaf_Redding: 0.5418, f1_Leaf_Variegation: 0.2309 (TTA: 4 views)
2025-05-08 17:46:52,341 - __main__.run_session - INFO - E9/200 Sum | TrL:1.3968 | VlL:1.4011 | VAcc:0.2086 | VF1w:0.1905 | Mon(accuracy):0.2086 | LR:3.00e-03 | TrT:111.4s | VlT:56.4s
2025-05-08 17:46:52,495 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 9, Best 0.2086)
2025-05-08 17:46:52,495 - __main__.run_session - INFO - E9: New best val accuracy: 0.2086. Ckpt saved.
2025-05-08 17:46:52,498 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 10: Multi-scale training. Resizing to (490, 490) (factor 1.10)
2025-05-08 17:50:25,791 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 10 training finished. Avg Loss: 1.3894, Current LR: 3.00e-03
2025-05-08 17:51:22,129 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3935, accuracy: 0.2181, f1_macro: 0.1811, f1_weighted: 0.1893, precision_macro: 0.2574, precision_weighted: 0.2815, recall_macro: 0.2214, recall_weighted: 0.2181, f1_Bacterial_Blight: 0.1226, f1_Curl_Virus: 0.0502, f1_Healthy_Leaf: 0.0611, f1_Herbicide_Growth_Damage: 0.0195, f1_Leaf_Hopper_Jassids: 0.2975, f1_Leaf_Redding: 0.5150, f1_Leaf_Variegation: 0.2020 (TTA: 4 views)
2025-05-08 17:51:22,174 - __main__.run_session - INFO - E10/200 Sum | TrL:1.3894 | VlL:1.3935 | VAcc:0.2181 | VF1w:0.1893 | Mon(accuracy):0.2181 | LR:2.99e-03 | TrT:213.3s | VlT:56.4s
2025-05-08 17:51:22,339 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 10, Best 0.2181)
2025-05-08 17:51:22,340 - __main__.run_session - INFO - E10: New best val accuracy: 0.2181. Ckpt saved.
2025-05-08 17:51:22,340 - __main__.run_session - INFO - Epoch 11: *** Unfreezing backbone ***
2025-05-08 17:51:22,342 - __main__.param_groups - INFO - Applying LLRD with decay rate: 0.85
2025-05-08 17:51:22,351 - __main__.param_groups - INFO - LLRD: Assigning base LR (3.00e-04) to unassigned param: norm_rgb_final.weight
2025-05-08 17:51:22,351 - __main__.param_groups - INFO - LLRD: Assigning base LR (3.00e-04) to unassigned param: norm_rgb_final.bias
2025-05-08 17:51:22,351 - __main__.param_groups - INFO - LLRD: Assigning base LR (3.00e-04) to unassigned param: norm_spectral_final.weight
2025-05-08 17:51:22,351 - __main__.param_groups - INFO - LLRD: Assigning base LR (3.00e-04) to unassigned param: norm_spectral_final.bias
2025-05-08 17:51:22,441 - __main__.run_session - INFO - Optimizer re-init for full model with base LR: 0.0003.
2025-05-08 17:51:22,441 - __main__.run_session - INFO - Scheduler re-init for unfreeze: CosineAnnealingLR
2025-05-08 17:57:43,033 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 11 training finished. Avg Loss: 1.3795, Current LR: 3.00e-04
2025-05-08 17:58:39,499 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3888, accuracy: 0.2195, f1_macro: 0.1576, f1_weighted: 0.1629, precision_macro: 0.2414, precision_weighted: 0.2625, recall_macro: 0.2262, recall_weighted: 0.2195, f1_Bacterial_Blight: 0.2675, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0924, f1_Leaf_Hopper_Jassids: 0.2971, f1_Leaf_Redding: 0.4039, f1_Leaf_Variegation: 0.0426 (TTA: 4 views)
2025-05-08 17:58:39,504 - __main__.run_session - INFO - E11/200 Sum | TrL:1.3795 | VlL:1.3888 | VAcc:0.2195 | VF1w:0.1629 | Mon(accuracy):0.2195 | LR:3.00e-04 | TrT:380.6s | VlT:56.5s
2025-05-08 17:58:40,067 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 11, Best 0.2195)
2025-05-08 17:58:40,068 - __main__.run_session - INFO - E11: New best val accuracy: 0.2195. Ckpt saved.
2025-05-08 18:05:00,525 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 12 training finished. Avg Loss: 1.3730, Current LR: 3.00e-04
2025-05-08 18:05:56,922 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4137, accuracy: 0.2312, f1_macro: 0.1736, f1_weighted: 0.1783, precision_macro: 0.2903, precision_weighted: 0.3132, recall_macro: 0.2372, recall_weighted: 0.2312, f1_Bacterial_Blight: 0.3012, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0351, f1_Herbicide_Growth_Damage: 0.0279, f1_Leaf_Hopper_Jassids: 0.2909, f1_Leaf_Redding: 0.4401, f1_Leaf_Variegation: 0.1198 (TTA: 4 views)
2025-05-08 18:05:56,926 - __main__.run_session - INFO - E12/200 Sum | TrL:1.3730 | VlL:1.4137 | VAcc:0.2312 | VF1w:0.1783 | Mon(accuracy):0.2312 | LR:3.00e-04 | TrT:380.5s | VlT:56.4s
2025-05-08 18:05:57,419 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 12, Best 0.2312)
2025-05-08 18:05:57,420 - __main__.run_session - INFO - E12: New best val accuracy: 0.2312. Ckpt saved.
2025-05-08 18:12:17,545 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 13 training finished. Avg Loss: 1.3730, Current LR: 3.00e-04
2025-05-08 18:13:13,927 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3691, accuracy: 0.2319, f1_macro: 0.2064, f1_weighted: 0.2120, precision_macro: 0.2690, precision_weighted: 0.2891, recall_macro: 0.2377, recall_weighted: 0.2319, f1_Bacterial_Blight: 0.3073, f1_Curl_Virus: 0.0582, f1_Healthy_Leaf: 0.0092, f1_Herbicide_Growth_Damage: 0.0750, f1_Leaf_Hopper_Jassids: 0.2006, f1_Leaf_Redding: 0.5424, f1_Leaf_Variegation: 0.2523 (TTA: 4 views)
2025-05-08 18:13:13,936 - __main__.run_session - INFO - E13/200 Sum | TrL:1.3730 | VlL:1.3691 | VAcc:0.2319 | VF1w:0.2120 | Mon(accuracy):0.2319 | LR:2.99e-04 | TrT:380.1s | VlT:56.4s
2025-05-08 18:13:14,436 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 13, Best 0.2319)
2025-05-08 18:13:14,437 - __main__.run_session - INFO - E13: New best val accuracy: 0.2319. Ckpt saved.
2025-05-08 18:19:34,852 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 14 training finished. Avg Loss: 1.3586, Current LR: 2.99e-04
2025-05-08 18:20:31,259 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4215, accuracy: 0.2312, f1_macro: 0.2062, f1_weighted: 0.2111, precision_macro: 0.3113, precision_weighted: 0.3371, recall_macro: 0.2388, recall_weighted: 0.2312, f1_Bacterial_Blight: 0.2952, f1_Curl_Virus: 0.1173, f1_Healthy_Leaf: 0.0270, f1_Herbicide_Growth_Damage: 0.0195, f1_Leaf_Hopper_Jassids: 0.2313, f1_Leaf_Redding: 0.5015, f1_Leaf_Variegation: 0.2513 (TTA: 4 views)
2025-05-08 18:20:31,277 - __main__.run_session - INFO - E14/200 Sum | TrL:1.3586 | VlL:1.4215 | VAcc:0.2312 | VF1w:0.2111 | Mon(accuracy):0.2312 | LR:2.99e-04 | TrT:380.4s | VlT:56.4s
2025-05-08 18:20:31,277 - __main__.run_session - INFO - E14: Val accuracy (0.2312) !improve from best (0.2319). Patience: 1/25
2025-05-08 18:26:51,494 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 15 training finished. Avg Loss: 1.3409, Current LR: 2.99e-04
2025-05-08 18:27:47,986 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.4205, accuracy: 0.2327, f1_macro: 0.1937, f1_weighted: 0.2007, precision_macro: 0.2441, precision_weighted: 0.2628, recall_macro: 0.2421, recall_weighted: 0.2327, f1_Bacterial_Blight: 0.3229, f1_Curl_Virus: 0.0171, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0459, f1_Leaf_Hopper_Jassids: 0.1429, f1_Leaf_Redding: 0.5801, f1_Leaf_Variegation: 0.2471 (TTA: 4 views)
2025-05-08 18:27:47,993 - __main__.run_session - INFO - E15/200 Sum | TrL:1.3409 | VlL:1.4205 | VAcc:0.2327 | VF1w:0.2007 | Mon(accuracy):0.2327 | LR:2.98e-04 | TrT:380.2s | VlT:56.5s
2025-05-08 18:27:48,503 - phase5_multimodal_hpo.finetune.trainer - INFO - Checkpoint saved: /teamspace/studios/this_studio/cvpr25/phase5_multimodal_hpo/phase5_checkpoints/phase5_best_90percent.pth (Epoch 15, Best 0.2327)
2025-05-08 18:27:48,504 - __main__.run_session - INFO - E15: New best val accuracy: 0.2327. Ckpt saved.
2025-05-08 18:34:08,790 - phase5_multimodal_hpo.finetune.trainer - INFO - Epoch 16 training finished. Avg Loss: 1.3606, Current LR: 2.98e-04
2025-05-08 18:35:05,119 - phase5_multimodal_hpo.finetune.trainer - INFO - Validation Summary -- Avg Loss: 1.3997, accuracy: 0.2312, f1_macro: 0.1889, f1_weighted: 0.1917, precision_macro: 0.2571, precision_weighted: 0.2808, recall_macro: 0.2426, recall_weighted: 0.2312, f1_Bacterial_Blight: 0.3405, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0237, f1_Herbicide_Growth_Damage: 0.0450, f1_Leaf_Hopper_Jassids: 0.2089, f1_Leaf_Redding: 0.4665, f1_Leaf_Variegation: 0.2377 (TTA: 4 views)
2025-05-08 18:35:05,127 - __main__.run_session - INFO - E16/200 Sum | TrL:1.3606 | VlL:1.3997 | VAcc:0.2312 | VF1w:0.1917 | Mon(accuracy):0.2312 | LR:2.97e-04 | TrT:380.3s | VlT:56.3s
2025-05-08 18:35:05,127 - __main__.run_session - INFO - E16: Val accuracy (0.2312) !improve from best (0.2327). Patience: 1/25
