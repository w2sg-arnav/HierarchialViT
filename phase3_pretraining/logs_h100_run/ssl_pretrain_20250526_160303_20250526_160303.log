2025-05-26 16:03:03 - root - INFO - [setup_logging:57] - Logging configured. File: /teamspace/studios/this_studio/cvpr25/phase3_pretraining/logs_h100_run/ssl_pretrain_20250526_160303_20250526_160303.log (Level: DEBUG), Console Level: INFO
2025-05-26 16:03:04 - phase2_model.models - INFO - [<module>:17] - Models (InceptionV3Baseline, DFCA, DiseaseAwareHVT, factory) imported successfully into phase2_model.models package.
2025-05-26 16:03:04 - phase2_model - INFO - [<module>:25] - Models re-exported successfully by phase2_model/__init__.py.
2025-05-26 16:03:04 - __main__ - INFO - [main_pretrain_script:60] - ======== Starting Phase 3: HVT Self-Supervised Pre-training (Run ID: 20250526_160303) ========
2025-05-26 16:03:04 - __main__ - INFO - [main_pretrain_script:61] - Full run configuration snapshot: {'seed': 42, 'device': 'cuda', 'PROJECT_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25', 'PACKAGE_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25/phase3_pretraining', 'log_dir_name': 'logs_h100_run', 'log_file_pretrain': 'ssl_pretrain.log', 'checkpoint_dir_name': 'checkpoints_hvt_xl_h100_run', 'enable_torch_compile': False, 'torch_compile_mode': 'reduce-overhead', 'matmul_precision': 'high', 'cudnn_benchmark': True, 'resume_checkpoint_path': '/teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_epoch_20.pth', 'data_root': '/teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection', 'original_dataset_name': 'Original Dataset', 'augmented_dataset_name': 'Augmented Dataset', 'train_split_ratio': 0.95, 'num_classes': 7, 'num_workers': 8, 'prefetch_factor': 2, 'hvt_params_for_backbone': {'patch_size': 14, 'embed_dim_rgb': 192, 'embed_dim_spectral': 192, 'spectral_channels': 0, 'depths': [3, 6, 24, 3], 'num_heads': [6, 12, 24, 48], 'mlp_ratio': 4.0, 'qkv_bias': True, 'model_drop_rate': 0.0, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.2, 'norm_layer_name': 'LayerNorm', 'use_dfca': False, 'dfca_embed_dim_match_rgb': True, 'dfca_num_heads': 32, 'dfca_drop_rate': 0.1, 'dfca_use_disease_mask': True, 'use_gradient_checkpointing': True, 'ssl_enable_mae': False, 'ssl_enable_contrastive': False, 'enable_consistency_loss_heads': False, 'ssl_mae_mask_ratio': 0.75, 'ssl_mae_decoder_dim': 64, 'ssl_mae_norm_pix_loss': True, 'ssl_contrastive_projector_dim': 128, 'ssl_contrastive_projector_depth': 2}, 'pretrain_img_size': (448, 448), 'pretrain_epochs': 80, 'pretrain_batch_size': 32, 'accumulation_steps': 2, 'pretrain_lr': 0.0005, 'pretrain_optimizer': 'AdamW', 'pretrain_scheduler': 'WarmupCosine', 'warmup_epochs': 10, 'eta_min_lr': 1e-06, 'pretrain_weight_decay': 0.05, 'pretrain_momentum': 0.9, 'temperature': 0.1, 'projection_dim': 256, 'projection_hidden_dim': 4096, 'simclr_s': 1.0, 'simclr_p_grayscale': 0.2, 'simclr_p_gaussian_blur': 0.5, 'simclr_rrc_scale_min': 0.08, 'evaluate_every_n_epochs': 10, 'linear_probe_epochs': 10, 'linear_probe_lr': 0.1, 'probe_optimizer': 'SGD', 'probe_momentum': 0.9, 'probe_weight_decay': 0.0, 'probe_batch_size': 64, 'save_every_n_epochs': 10, 'model_arch_name_for_ckpt': 'hvt_xl_simclr_h100_run', 'clip_grad_norm': 1.0}
2025-05-26 16:03:04 - __main__ - INFO - [apply_pytorch_optimizations:51] - torch.backends.cudnn.benchmark = True
2025-05-26 16:03:04 - __main__ - INFO - [apply_pytorch_optimizations:54] - torch.set_float32_matmul_precision('high')
2025-05-26 16:03:04 - __main__ - INFO - [main_pretrain_script:66] - Global random seed: 42. Device: cuda.
2025-05-26 16:03:04 - __main__ - INFO - [main_pretrain_script:67] - CUDA Device: Tesla T4
2025-05-26 16:03:04 - __main__ - INFO - [main_pretrain_script:70] - Target image size for pre-training: (448, 448)
2025-05-26 16:03:04 - phase3_pretraining.dataset - INFO - [__init__:52] - Initializing SARCLD2024Dataset: split='train', img_size=(448, 448), use_spectral=False
2025-05-26 16:03:04 - phase3_pretraining.dataset - DEBUG - [__init__:62] - Scanning sub-dataset: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-26 16:03:04 - phase3_pretraining.dataset - DEBUG - [__init__:62] - Scanning sub-dataset: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-26 16:03:04 - phase3_pretraining.dataset - INFO - [__init__:77] - Found 9137 total image entries.
2025-05-26 16:03:04 - phase3_pretraining.dataset - INFO - [__init__:90] - Dataset split 'train' size: 8680 samples.
2025-05-26 16:03:04 - phase3_pretraining.dataset - INFO - [__init__:52] - Initializing SARCLD2024Dataset: split='train', img_size=(448, 448), use_spectral=False
2025-05-26 16:03:04 - phase3_pretraining.dataset - DEBUG - [__init__:62] - Scanning sub-dataset: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-26 16:03:04 - phase3_pretraining.dataset - DEBUG - [__init__:62] - Scanning sub-dataset: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-26 16:03:05 - phase3_pretraining.dataset - INFO - [__init__:77] - Found 9137 total image entries.
2025-05-26 16:03:05 - phase3_pretraining.dataset - INFO - [__init__:90] - Dataset split 'train' size: 8680 samples.
2025-05-26 16:03:05 - phase3_pretraining.dataset - INFO - [__init__:52] - Initializing SARCLD2024Dataset: split='val', img_size=(448, 448), use_spectral=False
2025-05-26 16:03:05 - phase3_pretraining.dataset - DEBUG - [__init__:62] - Scanning sub-dataset: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-26 16:03:05 - phase3_pretraining.dataset - DEBUG - [__init__:62] - Scanning sub-dataset: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-26 16:03:05 - phase3_pretraining.dataset - INFO - [__init__:77] - Found 9137 total image entries.
2025-05-26 16:03:05 - phase3_pretraining.dataset - INFO - [__init__:90] - Dataset split 'val' size: 457 samples.
2025-05-26 16:03:05 - __main__ - INFO - [main_pretrain_script:85] - Dataset sizes: Pretrain=8680, ProbeTrain=8680, ProbeVal=457
2025-05-26 16:03:05 - __main__ - INFO - [main_pretrain_script:96] - Pretrain DataLoader: 271 batches, BS=32, Workers=8
2025-05-26 16:03:05 - __main__ - INFO - [main_pretrain_script:98] - Initializing HVTForPretraining model wrapper...
2025-05-26 16:03:05 - phase3_pretraining.models.hvt_wrapper - INFO - [__init__:36] - Initializing HVTForPretraining wrapper for img_size: (448, 448)
2025-05-26 16:03:05 - phase3_pretraining.models.hvt_wrapper - INFO - [__init__:44] - Instantiating HVTBackbone using parameters defined in Phase 3 config (hvt_params_for_backbone).
2025-05-26 16:03:05 - phase2_model.models.hvt - INFO - [create_disease_aware_hvt:602] - Factory: Creating DiseaseAwareHVT for img_size: (448, 448), num_classes: 7
2025-05-26 16:03:08 - phase2_model.models.hvt - INFO - [__init__:325] - HVT: Running RGB stream only. No fusion.
2025-05-26 16:03:11 - phase2_model.models.hvt - INFO - [__init__:359] - DiseaseAwareHVT initialized for image size (448, 448) and 7 classes.
2025-05-26 16:03:11 - phase3_pretraining.models.hvt_wrapper - INFO - [__init__:70] - Projection head input dimension set to: 1536
2025-05-26 16:03:11 - phase3_pretraining.models.projection_head - INFO - [__init__:29] - ProjectionHead initialized: In=1536, Hidden=4096, Out=256, BatchNorm=True
2025-05-26 16:03:11 - phase3_pretraining.models.hvt_wrapper - INFO - [__init__:79] - HVTForPretraining wrapper initialized successfully.
2025-05-26 16:03:11 - phase3_pretraining.utils.augmentations - INFO - [__init__:27] - SimCLRAugmentation: img_size=(448, 448), s=1.0, p_gray=0.2, p_blur=0.5, rrc_min_scale=0.08
2025-05-26 16:03:11 - phase3_pretraining.utils.losses - INFO - [__init__:13] - InfoNCELoss initialized with temperature: 0.1
2025-05-26 16:03:12 - phase3_pretraining.pretrain.trainer - INFO - [__init__:41] - Initializing Pretrainer...
2025-05-26 16:03:12 - phase3_pretraining.pretrain.trainer - INFO - [__init__:58] - Optimizer: AdamW, BaseLR: 0.0005, WD: 0.05
2025-05-26 16:03:12 - phase3_pretraining.pretrain.trainer - INFO - [__init__:69] - Pretrainer init complete. AMP: True, Accum: 2, ClipGrad: 1.0
2025-05-26 16:03:12 - __main__ - INFO - [main_pretrain_script:114] - Attempting to resume training from checkpoint: /teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_epoch_20.pth
2025-05-26 16:03:16 - __main__ - INFO - [main_pretrain_script:122] - Loaded backbone and projection head state dicts from checkpoint.
2025-05-26 16:03:16 - __main__ - INFO - [main_pretrain_script:130] - Optimizer state loaded.
2025-05-26 16:03:16 - __main__ - INFO - [main_pretrain_script:140] - GradScaler state loaded.
2025-05-26 16:03:16 - __main__ - INFO - [main_pretrain_script:148] - Resuming training from epoch 21. Best probe accuracy so far: 25.16%
2025-05-26 16:03:16 - __main__ - INFO - [main_pretrain_script:155] - Deferring scheduler state load: Pretrainer will initialize it with correct last_epoch.
2025-05-26 16:03:16 - __main__ - INFO - [main_pretrain_script:178] - Starting/Resuming SimCLR pre-training from epoch 21 up to 80 epochs.
2025-05-26 16:03:16 - phase3_pretraining.pretrain.trainer - INFO - [_initialize_scheduler_if_needed:86] - Resuming: Scheduler will be initialized with last_step/epoch around: 5419
2025-05-26 16:03:16 - phase3_pretraining.pretrain.trainer - INFO - [_initialize_scheduler_if_needed:106] - Scheduler: WarmupCosine (WarmupSteps=2710, TotalTrainSteps=21680). Last epoch for init: 5420
2025-05-26 16:10:32 - phase3_pretraining.pretrain.trainer - WARNING - [train_one_epoch:168] - E21: Applying leftover gradients from accumulation (1 steps).
2025-05-26 16:10:32 - phase3_pretraining.pretrain.trainer - INFO - [train_one_epoch:188] - Epoch 21 Training Summary: AvgLoss=2.2436, OptSteps=136, FinalLR=4.73e-04
2025-05-26 16:10:32 - __main__ - INFO - [main_pretrain_script:196] - SSL Epoch 21/80 | Duration: 436.78s | Samples/sec: 19.85 | Avg Loss: 2.2436 | LR: 4.73e-04
2025-05-26 16:10:33 - __main__ - DEBUG - [main_pretrain_script:212] - CUDA Mem E21: Alloc 4325.1MB, MaxAlloc 9433.7MB
2025-05-26 16:17:57 - phase3_pretraining.pretrain.trainer - WARNING - [train_one_epoch:168] - E22: Applying leftover gradients from accumulation (1 steps).
2025-05-26 16:17:58 - phase3_pretraining.pretrain.trainer - INFO - [train_one_epoch:188] - Epoch 22 Training Summary: AvgLoss=2.0935, OptSteps=136, FinalLR=4.70e-04
2025-05-26 16:17:58 - __main__ - INFO - [main_pretrain_script:196] - SSL Epoch 22/80 | Duration: 445.04s | Samples/sec: 19.49 | Avg Loss: 2.0935 | LR: 4.70e-04
2025-05-26 16:17:58 - __main__ - DEBUG - [main_pretrain_script:212] - CUDA Mem E22: Alloc 4325.1MB, MaxAlloc 9435.2MB
2025-05-26 16:25:19 - phase3_pretraining.pretrain.trainer - WARNING - [train_one_epoch:168] - E23: Applying leftover gradients from accumulation (1 steps).
2025-05-26 16:25:20 - phase3_pretraining.pretrain.trainer - INFO - [train_one_epoch:188] - Epoch 23 Training Summary: AvgLoss=2.1128, OptSteps=136, FinalLR=4.67e-04
2025-05-26 16:25:20 - __main__ - INFO - [main_pretrain_script:196] - SSL Epoch 23/80 | Duration: 442.22s | Samples/sec: 19.61 | Avg Loss: 2.1128 | LR: 4.67e-04
2025-05-26 16:25:20 - __main__ - DEBUG - [main_pretrain_script:212] - CUDA Mem E23: Alloc 4325.1MB, MaxAlloc 9435.2MB
