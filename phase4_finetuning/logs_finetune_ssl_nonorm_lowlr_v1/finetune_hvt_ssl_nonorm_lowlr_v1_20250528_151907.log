2025-05-28 15:19:07 - root - INFO - [setup_logging:75] - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/finetune_hvt_ssl_nonorm_lowlr_v1_20250528_151907.log. Logger 'root' Effective Level: DEBUG
2025-05-28 15:19:07 - __main__ - INFO - [main_execution_logic:191] - ======== Starting Phase 4: HVT Fine-tuning (Run ID: 20250528_151907) ========
2025-05-28 15:19:07 - __main__ - INFO - [main_execution_logic:192] - Full run configuration: {'seed': 42, 'device': 'cuda', 'PACKAGE_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25/phase4_finetuning', 'PROJECT_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25', 'log_dir': 'logs_finetune_ssl_nonorm_lowlr_v1', 'log_file_finetune': 'finetune_hvt_ssl_nonorm_lowlr_v1.log', 'best_model_filename': 'best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth', 'final_model_filename': 'final_finetuned_hvt_ssl_nonorm_lowlr_v1.pth', 'checkpoint_save_dir_name': 'checkpoints_ssl_nonorm_lowlr_v1', 'data_root': '/teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection', 'original_dataset_name': 'Original Dataset', 'augmented_dataset_name': 'Augmented Dataset', 'img_size': (448, 448), 'num_classes': 7, 'train_split_ratio': 0.8, 'normalize_data': False, 'use_weighted_sampler': True, 'weighted_sampler_mode': 'inv_freq', 'use_weighted_loss': True, 'num_workers': 4, 'prefetch_factor': 2, 'model_architecture_name': 'DiseaseAwareHVT_SSL_NoNorm_LowLR_Finetune_v1', 'pretrained_checkpoint_path': '/teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth', 'load_pretrained_backbone': True, 'hvt_params_for_model_init': {'patch_size': 14, 'embed_dim_rgb': 192, 'embed_dim_spectral': 192, 'spectral_channels': 0, 'depths': [3, 6, 24, 3], 'num_heads': [6, 12, 24, 48], 'mlp_ratio': 4.0, 'qkv_bias': True, 'model_drop_rate': 0.1, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.1, 'norm_layer_name': 'LayerNorm', 'use_dfca': False, 'use_gradient_checkpointing': True, 'ssl_enable_mae': False, 'ssl_enable_contrastive': False, 'enable_consistency_loss_heads': False, 'dfca_embed_dim_match_rgb': True, 'dfca_num_heads': 32, 'dfca_drop_rate': 0.1, 'dfca_use_disease_mask': True, 'ssl_mae_mask_ratio': 0.75, 'ssl_mae_decoder_dim': 64, 'ssl_mae_norm_pix_loss': True, 'ssl_contrastive_projector_dim': 128, 'ssl_contrastive_projector_depth': 2}, 'enable_torch_compile': False, 'torch_compile_mode': 'reduce-overhead', 'matmul_precision': 'high', 'cudnn_benchmark': True, 'freeze_backbone_epochs': 10, 'epochs': 60, 'batch_size': 16, 'accumulation_steps': 2, 'amp_enabled': True, 'clip_grad_norm': 1.0, 'log_interval': 20, 'optimizer': 'AdamW', 'optimizer_params': {'betas': (0.9, 0.999), 'eps': 1e-08}, 'weight_decay': 0.05, 'lr_head_frozen_phase': 5e-05, 'lr_backbone_unfrozen_phase': 1e-05, 'lr_head_unfrozen_phase': 2e-05, 'scheduler': 'WarmupCosine', 'warmup_epochs': 5, 'eta_min_lr': 1e-07, 'loss_label_smoothing': 0.1, 'augmentations_enabled': True, 'evaluate_every_n_epochs': 1, 'early_stopping_patience': 15, 'metric_to_monitor_early_stopping': 'f1_macro', 'tta_enabled_val': False, 'ssl_pretrain_img_size_fallback': (448, 448)}
2025-05-28 15:19:07 - __main__ - INFO - [set_global_seed:69] - Global random seed set to: 42
2025-05-28 15:19:07 - __main__ - INFO - [main_execution_logic:196] - Using device: cuda. GPU: Tesla T4
2025-05-28 15:19:07 - phase4_finetuning.dataset - INFO - [__init__:53] - [DATASET INIT - train] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448), Normalize: False
2025-05-28 15:19:07 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-28 15:19:07 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:105] - [DATASET INIT - train] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:117] - [DATASET INIT - train] Dataset split size: 7309 samples.
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:128] - [DATASET INIT - train] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=True)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
)
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:53] - [DATASET INIT - val] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448), Normalize: False
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:105] - [DATASET INIT - val] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:117] - [DATASET INIT - val] Dataset split size: 1828 samples.
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [__init__:128] - [DATASET INIT - val] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=True)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
)
2025-05-28 15:19:08 - phase4_finetuning.dataset - INFO - [get_class_weights:185] - Computed class weights (inv_freq for loss) for split 'train': [1.029 0.912 1.065 1.014 1.05  0.833 1.172]
2025-05-28 15:19:08 - __main__ - INFO - [main_execution_logic:237] - Using WeightedRandomSampler with 'inv_freq' mode. Per-class weights from dataset: [1.029 0.912 1.065 1.014 1.05  0.833 1.172]
2025-05-28 15:19:08 - __main__ - INFO - [main_execution_logic:254] - WeightedRandomSampler enabled (mode: inv_freq).
2025-05-28 15:19:08 - __main__ - INFO - [main_execution_logic:261] - Dataloaders created. Train batches: 456, Val batches: 115
2025-05-28 15:19:08 - phase2_model.models.hvt - INFO - [create_disease_aware_hvt:602] - Factory: Creating DiseaseAwareHVT for img_size: (448, 448), num_classes: 7
2025-05-28 15:19:11 - phase2_model.models.hvt - INFO - [__init__:325] - HVT: Running RGB stream only. No fusion.
2025-05-28 15:19:14 - phase2_model.models.hvt - INFO - [__init__:359] - DiseaseAwareHVT initialized for image size (448, 448) and 7 classes.
2025-05-28 15:19:14 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:121] - Loading SSL backbone weights from: /teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth
2025-05-28 15:19:16 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:133] - SSL and Finetune img_size match: (448, 448).
2025-05-28 15:19:16 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:159] - SSL Backbone weights loaded: 450 direct, 0 PE interpolated, 2 head layers skipped.
2025-05-28 15:19:16 - __main__.load_and_prepare_hvt_model - WARNING - [load_and_prepare_hvt_model:160] - Missing keys when loading SSL backbone: ['classifier_head.weight', 'classifier_head.bias']
2025-05-28 15:19:16 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:166] - Re-initialized HVT classifier_head for 7 classes (in_features=1536).
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:266] - Model ready. Total params: 273,615,751, Trainable params: 273,615,751
2025-05-28 15:19:17 - phase4_finetuning.utils.augmentations - INFO - [__init__:23] - FinetuneAugmentation initialized with enhanced transforms.
2025-05-28 15:19:17 - phase4_finetuning.utils.augmentations - DEBUG - [__init__:24] - Augmentation pipeline: Compose(
      RandomHorizontalFlip(p=0.5)
      RandomVerticalFlip(p=0.3)
      RandomRotation(degrees=[-30.0, 30.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)
      ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.7, 1.3), hue=(-0.2, 0.2))
      RandomAffine(degrees=[-15.0, 15.0], translate=(0.2, 0.2), scale=(0.8, 1.2), shear=[-5.0, 5.0], interpolation=InterpolationMode.NEAREST, fill=0)
      RandomApply(    GaussianBlur(kernel_size=(3, 7), sigma=[0.1, 2.0]))
      RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)
      RandomSolarize(p=0.1, threshold=0.5)
)
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:280] - Using weighted CrossEntropyLoss. Weights: [1.029 0.912 1.065 1.014 1.05  0.833 1.172]
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:297] - Optimizer initial setup: Backbone frozen. Head LR: 5.00e-05, Backbone LR: 0.00e+00
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:325] - Optimizer: AdamW created with effective defaults: {'lr': 2e-05, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.05, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'differentiable': False, 'fused': None}
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:328] -   Group 'head': Initial LR 5.00e-05, Weight Decay 5.00e-02
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:328] -   Group 'backbone': Initial LR 0.00e+00, Weight Decay 5.00e-02
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:346] - Scheduler: WarmupCosine (per-step). WU Steps: 1140, Total Steps: 13680, Eta Min used by lambda: 1e-07
2025-05-28 15:19:17 - phase4_finetuning.finetune.trainer - INFO - [__init__:44] - Finetuner initialized: device=cuda, accum_steps=2, lr_sched_on_batch=True, AMP=True
2025-05-28 15:19:17 - phase4_finetuning.finetune.trainer - INFO - [__init__:46] - Using training augmentations: FinetuneAugmentation
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:376] - Checkpoints will be saved in: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1
2025-05-28 15:19:17 - __main__ - DEBUG - [main_execution_logic:380] - DEBUG INIT: Opt Group 0 ('head'): Current LR 0.00e+00, Scheduler Base LR 5.00e-05
2025-05-28 15:19:17 - __main__ - DEBUG - [main_execution_logic:380] - DEBUG INIT: Opt Group 1 ('backbone'): Current LR 0.00e+00, Scheduler Base LR 0.00e+00
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:383] - Starting fine-tuning for 60 epochs. Monitor: 'f1_macro'. Backbone frozen for initial 10 epochs.
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:405] - Epoch 1: Starting in Frozen Backbone phase.
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:410] -   Param group 'head': Current optimizer LR at epoch start: 0.00e+00
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:412] -     LambdaLR base_lr for this group: 5.00e-05
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:410] -   Param group 'backbone': Current optimizer LR at epoch start: 0.00e+00
2025-05-28 15:19:17 - __main__ - INFO - [main_execution_logic:412] -     LambdaLR base_lr for this group: 0.00e+00
2025-05-28 15:20:29 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 1 training finished. Avg Loss: 2.0180, Final LR for epoch: 1.00e-05, Opt Steps: 228
2025-05-28 15:20:47 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.9465, accuracy: 0.1822, f1_macro: 0.1310, f1_weighted: 0.1250, precision_macro: 0.1384, precision_weighted: 0.1326, recall_macro: 0.1961, recall_weighted: 0.1822, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.1129, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.5499, f1_Leaf_Hopper_Jassids: 0.2469, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0074
2025-05-28 15:20:49 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:189] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1/best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth
2025-05-28 15:20:49 - __main__ - INFO - [main_execution_logic:465] - E1: New best! Val f1_macro: 0.1310
2025-05-28 15:20:49 - __main__ - INFO - [main_execution_logic:478] - Epoch 1 completed in 91.74s.
2025-05-28 15:20:49 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E1 End: Alloc 1063.4MB, Reserved 1366.0MB
2025-05-28 15:21:57 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 2 training finished. Avg Loss: 1.8633, Final LR for epoch: 2.00e-05, Opt Steps: 228
2025-05-28 15:22:14 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.8099, accuracy: 0.2763, f1_macro: 0.1800, f1_weighted: 0.1654, precision_macro: 0.3023, precision_weighted: 0.2810, recall_macro: 0.3026, recall_weighted: 0.2763, f1_Bacterial_Blight: 0.0335, f1_Curl_Virus: 0.0576, f1_Healthy_Leaf: 0.0070, f1_Herbicide_Growth_Damage: 0.5408, f1_Leaf_Hopper_Jassids: 0.1828, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.4380
2025-05-28 15:22:18 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:189] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1/best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth
2025-05-28 15:22:18 - __main__ - INFO - [main_execution_logic:465] - E2: New best! Val f1_macro: 0.1800
2025-05-28 15:22:18 - __main__ - INFO - [main_execution_logic:478] - Epoch 2 completed in 88.79s.
2025-05-28 15:22:18 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E2 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:23:26 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 3 training finished. Avg Loss: 1.7807, Final LR for epoch: 3.00e-05, Opt Steps: 228
2025-05-28 15:23:43 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.7128, accuracy: 0.3419, f1_macro: 0.2471, f1_weighted: 0.2505, precision_macro: 0.3425, precision_weighted: 0.3549, recall_macro: 0.3530, recall_weighted: 0.3419, f1_Bacterial_Blight: 0.1300, f1_Curl_Virus: 0.0195, f1_Healthy_Leaf: 0.0211, f1_Herbicide_Growth_Damage: 0.5110, f1_Leaf_Hopper_Jassids: 0.1023, f1_Leaf_Redding: 0.5237, f1_Leaf_Variegation: 0.4218
2025-05-28 15:23:46 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:189] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1/best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth
2025-05-28 15:23:46 - __main__ - INFO - [main_execution_logic:465] - E3: New best! Val f1_macro: 0.2471
2025-05-28 15:23:46 - __main__ - INFO - [main_execution_logic:478] - Epoch 3 completed in 88.33s.
2025-05-28 15:23:46 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E3 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:24:55 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 4 training finished. Avg Loss: 1.7268, Final LR for epoch: 4.00e-05, Opt Steps: 228
2025-05-28 15:25:12 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6618, accuracy: 0.3725, f1_macro: 0.2937, f1_weighted: 0.2980, precision_macro: 0.3770, precision_weighted: 0.3836, recall_macro: 0.3704, recall_weighted: 0.3725, f1_Bacterial_Blight: 0.2202, f1_Curl_Virus: 0.0964, f1_Healthy_Leaf: 0.1063, f1_Herbicide_Growth_Damage: 0.5067, f1_Leaf_Hopper_Jassids: 0.1086, f1_Leaf_Redding: 0.5578, f1_Leaf_Variegation: 0.4595
2025-05-28 15:25:15 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:189] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1/best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth
2025-05-28 15:25:15 - __main__ - INFO - [main_execution_logic:465] - E4: New best! Val f1_macro: 0.2937
2025-05-28 15:25:15 - __main__ - INFO - [main_execution_logic:478] - Epoch 4 completed in 88.96s.
2025-05-28 15:25:15 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E4 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:26:24 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 5 training finished. Avg Loss: 1.6885, Final LR for epoch: 5.00e-05, Opt Steps: 228
2025-05-28 15:26:41 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6304, accuracy: 0.3687, f1_macro: 0.2955, f1_weighted: 0.2961, precision_macro: 0.3927, precision_weighted: 0.3907, recall_macro: 0.3607, recall_weighted: 0.3687, f1_Bacterial_Blight: 0.2895, f1_Curl_Virus: 0.0506, f1_Healthy_Leaf: 0.1720, f1_Herbicide_Growth_Damage: 0.5329, f1_Leaf_Hopper_Jassids: 0.1375, f1_Leaf_Redding: 0.4733, f1_Leaf_Variegation: 0.4125
2025-05-28 15:26:45 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:189] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1/best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth
2025-05-28 15:26:45 - __main__ - INFO - [main_execution_logic:465] - E5: New best! Val f1_macro: 0.2955
2025-05-28 15:26:45 - __main__ - INFO - [main_execution_logic:478] - Epoch 5 completed in 89.60s.
2025-05-28 15:26:45 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E5 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:27:51 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 6 training finished. Avg Loss: 1.6587, Final LR for epoch: 5.00e-05, Opt Steps: 228
2025-05-28 15:28:08 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6660, accuracy: 0.3397, f1_macro: 0.2528, f1_weighted: 0.2536, precision_macro: 0.3663, precision_weighted: 0.3615, recall_macro: 0.3281, recall_weighted: 0.3397, f1_Bacterial_Blight: 0.2865, f1_Curl_Virus: 0.0121, f1_Healthy_Leaf: 0.0943, f1_Herbicide_Growth_Damage: 0.5192, f1_Leaf_Hopper_Jassids: 0.0959, f1_Leaf_Redding: 0.4374, f1_Leaf_Variegation: 0.3242
2025-05-28 15:28:08 - __main__ - INFO - [main_execution_logic:469] - E6: Val f1_macro (0.2528) not better than best (0.2955). Patience: 1/15
2025-05-28 15:28:08 - __main__ - INFO - [main_execution_logic:478] - Epoch 6 completed in 83.07s.
2025-05-28 15:28:08 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E6 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:29:15 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 7 training finished. Avg Loss: 1.6537, Final LR for epoch: 4.98e-05, Opt Steps: 228
2025-05-28 15:29:31 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6810, accuracy: 0.3326, f1_macro: 0.2440, f1_weighted: 0.2472, precision_macro: 0.3790, precision_weighted: 0.3752, recall_macro: 0.3191, recall_weighted: 0.3326, f1_Bacterial_Blight: 0.2762, f1_Curl_Virus: 0.0616, f1_Healthy_Leaf: 0.0878, f1_Herbicide_Growth_Damage: 0.5260, f1_Leaf_Hopper_Jassids: 0.0890, f1_Leaf_Redding: 0.4323, f1_Leaf_Variegation: 0.2349
2025-05-28 15:29:31 - __main__ - INFO - [main_execution_logic:469] - E7: Val f1_macro (0.2440) not better than best (0.2955). Patience: 2/15
2025-05-28 15:29:31 - __main__ - INFO - [main_execution_logic:478] - Epoch 7 completed in 83.47s.
2025-05-28 15:29:31 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E7 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:30:39 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 8 training finished. Avg Loss: 1.6493, Final LR for epoch: 4.96e-05, Opt Steps: 228
2025-05-28 15:30:57 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6981, accuracy: 0.3490, f1_macro: 0.2655, f1_weighted: 0.2678, precision_macro: 0.3267, precision_weighted: 0.3229, recall_macro: 0.3381, recall_weighted: 0.3490, f1_Bacterial_Blight: 0.2493, f1_Curl_Virus: 0.1307, f1_Healthy_Leaf: 0.0071, f1_Herbicide_Growth_Damage: 0.5132, f1_Leaf_Hopper_Jassids: 0.1220, f1_Leaf_Redding: 0.4751, f1_Leaf_Variegation: 0.3611
2025-05-28 15:30:57 - __main__ - INFO - [main_execution_logic:469] - E8: Val f1_macro (0.2655) not better than best (0.2955). Patience: 3/15
2025-05-28 15:30:57 - __main__ - INFO - [main_execution_logic:478] - Epoch 8 completed in 85.73s.
2025-05-28 15:30:57 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E8 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:32:08 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 9 training finished. Avg Loss: 1.6365, Final LR for epoch: 4.94e-05, Opt Steps: 228
2025-05-28 15:32:27 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6857, accuracy: 0.3534, f1_macro: 0.2637, f1_weighted: 0.2640, precision_macro: 0.3745, precision_weighted: 0.3721, recall_macro: 0.3435, recall_weighted: 0.3534, f1_Bacterial_Blight: 0.3115, f1_Curl_Virus: 0.0242, f1_Healthy_Leaf: 0.0819, f1_Herbicide_Growth_Damage: 0.5400, f1_Leaf_Hopper_Jassids: 0.0460, f1_Leaf_Redding: 0.4514, f1_Leaf_Variegation: 0.3908
2025-05-28 15:32:27 - __main__ - INFO - [main_execution_logic:469] - E9: Val f1_macro (0.2637) not better than best (0.2955). Patience: 4/15
2025-05-28 15:32:27 - __main__ - INFO - [main_execution_logic:478] - Epoch 9 completed in 89.46s.
2025-05-28 15:32:27 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E9 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:33:38 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 10 training finished. Avg Loss: 1.6404, Final LR for epoch: 4.90e-05, Opt Steps: 228
2025-05-28 15:33:56 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6676, accuracy: 0.3589, f1_macro: 0.2841, f1_weighted: 0.2863, precision_macro: 0.4066, precision_weighted: 0.4033, recall_macro: 0.3476, recall_weighted: 0.3589, f1_Bacterial_Blight: 0.3294, f1_Curl_Virus: 0.1036, f1_Healthy_Leaf: 0.1067, f1_Herbicide_Growth_Damage: 0.5479, f1_Leaf_Hopper_Jassids: 0.1602, f1_Leaf_Redding: 0.4660, f1_Leaf_Variegation: 0.2749
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:469] - E10: Val f1_macro (0.2841) not better than best (0.2955). Patience: 5/15
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:478] - Epoch 10 completed in 89.83s.
2025-05-28 15:33:56 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E10 End: Alloc 1063.4MB, Reserved 2384.0MB
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:415] - Epoch 11: Backbone UNPROZEN. Updating LRs to unfrozen phase values.
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:427] -   Updating head group optimizer LR from 4.90e-05 to 2.00e-05
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:432] -     Updating LambdaLR's base_lr for group 'head' (idx 0) from 5.00e-05 to 2.00e-05
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:427] -   Updating backbone group optimizer LR from 0.00e+00 to 1.00e-05
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:432] -     Updating LambdaLR's base_lr for group 'backbone' (idx 1) from 0.00e+00 to 1.00e-05
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:436] -   Effective Base LRs for scheduler (after unfreezing update):
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:443] -     Opt Group 0 ('head'): Current LR 2.000e-05 (Scheduler base: 2.000e-05)
2025-05-28 15:33:56 - __main__ - INFO - [main_execution_logic:443] -     Opt Group 1 ('backbone'): Current LR 1.000e-05 (Scheduler base: 1.000e-05)
2025-05-28 15:37:36 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:114] - Epoch 11 training finished. Avg Loss: 1.6038, Final LR for epoch: 1.94e-05, Opt Steps: 228
2025-05-28 15:37:54 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:182] - Validation finished. Avg Loss: 1.6791, accuracy: 0.3786, f1_macro: 0.3121, f1_weighted: 0.3141, precision_macro: 0.4345, precision_weighted: 0.4338, recall_macro: 0.3687, recall_weighted: 0.3786, f1_Bacterial_Blight: 0.3379, f1_Curl_Virus: 0.1542, f1_Healthy_Leaf: 0.1200, f1_Herbicide_Growth_Damage: 0.5430, f1_Leaf_Hopper_Jassids: 0.1731, f1_Leaf_Redding: 0.4959, f1_Leaf_Variegation: 0.3602
2025-05-28 15:37:58 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:189] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_ssl_nonorm_lowlr_v1/checkpoints_ssl_nonorm_lowlr_v1/best_finetuned_hvt_ssl_nonorm_lowlr_v1.pth
2025-05-28 15:37:58 - __main__ - INFO - [main_execution_logic:465] - E11: New best! Val f1_macro: 0.3121
2025-05-28 15:37:58 - __main__ - INFO - [main_execution_logic:478] - Epoch 11 completed in 241.60s.
2025-05-28 15:37:58 - __main__ - DEBUG - [main_execution_logic:479] - CUDA Mem E11 End: Alloc 3161.3MB, Reserved 6628.0MB
