2025-05-28 14:29:25 - root - INFO - [setup_logging:75] - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/finetune_hvt_xl_optimized_v1_20250528_142925.log. Logger 'root' Effective Level: DEBUG
2025-05-28 14:29:25 - __main__ - INFO - [main_execution_logic:193] - ======== Starting Phase 4: HVT Fine-tuning (Run ID: 20250528_142925) ========
2025-05-28 14:29:25 - __main__ - INFO - [main_execution_logic:194] - Full run configuration: {'seed': 42, 'device': 'cuda', 'PACKAGE_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25/phase4_finetuning', 'PROJECT_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25', 'log_dir': 'logs_finetune_optimized_v1', 'log_file_finetune': 'finetune_hvt_xl_optimized_v1.log', 'best_model_filename': 'best_finetuned_hvt_xl_optimized_v1.pth', 'final_model_filename': 'final_finetuned_hvt_xl_optimized_v1.pth', 'checkpoint_save_dir_name': 'checkpoints_optimized_v1', 'data_root': '/teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection', 'original_dataset_name': 'Original Dataset', 'augmented_dataset_name': 'Augmented Dataset', 'img_size': (448, 448), 'num_classes': 7, 'train_split_ratio': 0.8, 'normalize_data': True, 'use_weighted_sampler': True, 'weighted_sampler_mode': 'sqrt_inv_count', 'use_weighted_loss': True, 'num_workers': 4, 'prefetch_factor': 2, 'model_architecture_name': 'DiseaseAwareHVT_SSL_OptimizedFinetune', 'pretrained_checkpoint_path': '/teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth', 'load_pretrained_backbone': True, 'hvt_params_for_model_init': {'patch_size': 14, 'embed_dim_rgb': 192, 'embed_dim_spectral': 192, 'spectral_channels': 0, 'depths': [3, 6, 24, 3], 'num_heads': [6, 12, 24, 48], 'mlp_ratio': 4.0, 'qkv_bias': True, 'model_drop_rate': 0.1, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.2, 'norm_layer_name': 'LayerNorm', 'use_dfca': False, 'use_gradient_checkpointing': True, 'ssl_enable_mae': False, 'ssl_enable_contrastive': False, 'enable_consistency_loss_heads': False, 'dfca_embed_dim_match_rgb': True, 'dfca_num_heads': 32, 'dfca_drop_rate': 0.1, 'dfca_use_disease_mask': True, 'ssl_mae_mask_ratio': 0.75, 'ssl_mae_decoder_dim': 64, 'ssl_mae_norm_pix_loss': True, 'ssl_contrastive_projector_dim': 128, 'ssl_contrastive_projector_depth': 2}, 'enable_torch_compile': False, 'torch_compile_mode': 'reduce-overhead', 'matmul_precision': 'high', 'cudnn_benchmark': True, 'freeze_backbone_epochs': 5, 'epochs': 120, 'batch_size': 32, 'accumulation_steps': 1, 'amp_enabled': True, 'clip_grad_norm': 0.5, 'log_interval': 20, 'optimizer': 'AdamW', 'optimizer_params': {'betas': (0.9, 0.999), 'eps': 1e-08}, 'weight_decay': 0.01, 'lr_head_frozen_phase': 0.001, 'lr_backbone_unfrozen_phase': 5e-05, 'lr_head_unfrozen_phase': 0.0001, 'scheduler': 'WarmupCosine', 'warmup_epochs': 10, 'eta_min_lr': 1e-06, 'loss_label_smoothing': 0.05, 'augmentations_enabled': True, 'evaluate_every_n_epochs': 1, 'early_stopping_patience': 15, 'metric_to_monitor_early_stopping': 'f1_macro', 'tta_enabled_val': True}
2025-05-28 14:29:25 - __main__ - INFO - [set_global_seed:71] - Global random seed set to: 42
2025-05-28 14:29:25 - __main__ - INFO - [main_execution_logic:198] - Using device: cuda. GPU: Tesla T4
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:54] - [DATASET INIT - train] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448)
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:98] - [DATASET INIT - train] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:111] - [DATASET INIT - train] Dataset split size: 7309 samples.
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:123] - [DATASET INIT - train] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=False)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
)
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:54] - [DATASET INIT - val] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448)
2025-05-28 14:29:25 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-28 14:29:26 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-28 14:29:26 - phase4_finetuning.dataset - INFO - [__init__:98] - [DATASET INIT - val] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-28 14:29:26 - phase4_finetuning.dataset - INFO - [__init__:111] - [DATASET INIT - val] Dataset split size: 1828 samples.
2025-05-28 14:29:26 - phase4_finetuning.dataset - INFO - [__init__:123] - [DATASET INIT - val] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=False)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
)
2025-05-28 14:29:26 - __main__ - INFO - [main_execution_logic:238] - Using WeightedRandomSampler with 'sqrt_inv_count' mode. Per-class weights: [0.031 0.03  0.032 0.031 0.032 0.028 0.034]
2025-05-28 14:29:26 - __main__ - INFO - [main_execution_logic:258] - WeightedRandomSampler enabled (mode: sqrt_inv_count).
2025-05-28 14:29:26 - __main__ - INFO - [main_execution_logic:265] - Dataloaders created. Train batches: 228, Val batches: 58
2025-05-28 14:29:26 - phase2_model.models.hvt - INFO - [create_disease_aware_hvt:602] - Factory: Creating DiseaseAwareHVT for img_size: (448, 448), num_classes: 7
2025-05-28 14:29:29 - phase2_model.models.hvt - INFO - [__init__:325] - HVT: Running RGB stream only. No fusion.
2025-05-28 14:29:31 - phase2_model.models.hvt - INFO - [__init__:359] - DiseaseAwareHVT initialized for image size (448, 448) and 7 classes.
2025-05-28 14:29:31 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:123] - Loading SSL backbone weights from: /teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth
2025-05-28 14:29:34 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:135] - SSL and Finetune img_size match: (448, 448).
2025-05-28 14:29:34 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:161] - SSL Backbone weights loaded: 450 direct, 0 PE interpolated, 2 head layers skipped.
2025-05-28 14:29:34 - __main__.load_and_prepare_hvt_model - WARNING - [load_and_prepare_hvt_model:162] - Missing keys when loading SSL backbone: ['classifier_head.weight', 'classifier_head.bias']
2025-05-28 14:29:34 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:168] - Re-initialized HVT classifier_head for 7 classes (in_features=1536).
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:270] - Model ready. Total params: 273,615,751, Trainable params: 273,615,751
2025-05-28 14:29:35 - phase4_finetuning.utils.augmentations - INFO - [__init__:24] - FinetuneAugmentation initialized with enhanced transforms.
2025-05-28 14:29:35 - phase4_finetuning.utils.augmentations - DEBUG - [__init__:25] - Augmentation pipeline: Compose(
      RandomHorizontalFlip(p=0.5)
      RandomVerticalFlip(p=0.3)
      RandomRotation(degrees=[-30.0, 30.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)
      ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.7, 1.3), hue=(-0.2, 0.2))
      RandomAffine(degrees=[-15.0, 15.0], translate=(0.2, 0.2), scale=(0.8, 1.2), shear=[-5.0, 5.0], interpolation=InterpolationMode.NEAREST, fill=0)
      RandomApply(    GaussianBlur(kernel_size=(3, 7), sigma=[0.1, 2.0]))
      RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=[0.0], inplace=False)
      RandomSolarize(p=0.1, threshold=0.5)
)
2025-05-28 14:29:35 - phase4_finetuning.dataset - INFO - [get_class_weights:180] - Computed class weights for split 'train': [1.029 0.912 1.065 1.014 1.05  0.833 1.172]
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:286] - Using weighted CrossEntropyLoss. Weights: [1.029 0.912 1.065 1.014 1.05  0.833 1.172]
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:305] - Optimizer initial setup: Backbone frozen. Head LR: 1.00e-03, Backbone LR: 0.00e+00
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:338] - Optimizer: AdamW created with parameters: {'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'differentiable': False, 'fused': None}
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:341] -   Group 'head': Initial LR 1.00e-03, Weight Decay 1.00e-02
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:341] -   Group 'backbone': Initial LR 0.00e+00, Weight Decay 1.00e-02
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:365] - Scheduler: WarmupCosine (per-step). WU Steps: 2280, Total Steps: 27360, Eta Min: 1e-06
2025-05-28 14:29:35 - phase4_finetuning.finetune.trainer - INFO - [__init__:44] - Finetuner initialized: device=cuda, accum_steps=1, lr_sched_on_batch=True, AMP=True
2025-05-28 14:29:35 - phase4_finetuning.finetune.trainer - INFO - [__init__:46] - Using training augmentations: FinetuneAugmentation
2025-05-28 14:29:35 - phase4_finetuning.finetune.trainer - INFO - [__init__:48] - Test-Time Augmentation (TTA) enabled for validation.
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:386] - Checkpoints will be saved in: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/checkpoints_optimized_v1
2025-05-28 14:29:35 - __main__ - DEBUG - [main_execution_logic:391] - DEBUG INIT: Opt Group 0 ('head'): Current LR 0.00e+00, Scheduler Base LR 1.00e-03
2025-05-28 14:29:35 - __main__ - DEBUG - [main_execution_logic:391] - DEBUG INIT: Opt Group 1 ('backbone'): Current LR 0.00e+00, Scheduler Base LR 0.00e+00
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:397] - Starting fine-tuning for 120 epochs. Monitor: 'f1_macro'. Backbone frozen for initial 5 epochs.
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:419] - Epoch 1: Starting in Frozen Backbone phase.
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:424] -   Param group 'head': Current optimizer LR at epoch start: 0.00e+00
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:426] -     LambdaLR base_lr for this group: 1.00e-03
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:424] -   Param group 'backbone': Current optimizer LR at epoch start: 0.00e+00
2025-05-28 14:29:35 - __main__ - INFO - [main_execution_logic:426] -     LambdaLR base_lr for this group: 0.00e+00
2025-05-28 14:30:52 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 1 training finished. Avg Loss: 1.9680, Final LR for epoch: 1.00e-04, Opt Steps: 228
2025-05-28 14:31:24 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.0616, accuracy: 0.0651, f1_macro: 0.0314, f1_weighted: 0.0326, precision_macro: 0.0226, precision_weighted: 0.0231, recall_macro: 0.0621, recall_weighted: 0.0651, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.1377, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0608, f1_Leaf_Hopper_Jassids: 0.0214, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 14:31:26 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:194] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/checkpoints_optimized_v1/best_finetuned_hvt_xl_optimized_v1.pth
2025-05-28 14:31:26 - __main__ - INFO - [main_execution_logic:482] - E1: New best! Val f1_macro: 0.0314
2025-05-28 14:31:26 - __main__ - INFO - [main_execution_logic:495] - Epoch 1 completed in 111.12s.
2025-05-28 14:31:26 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E1 End: Alloc 1063.4MB, Reserved 1386.0MB
2025-05-28 14:32:31 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 2 training finished. Avg Loss: 1.9380, Final LR for epoch: 2.00e-04, Opt Steps: 228
2025-05-28 14:33:03 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.0555, accuracy: 0.0498, f1_macro: 0.0276, f1_weighted: 0.0251, precision_macro: 0.0193, precision_weighted: 0.0174, recall_macro: 0.0543, recall_weighted: 0.0498, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0576, f1_Leaf_Hopper_Jassids: 0.1359, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 14:33:03 - __main__ - INFO - [main_execution_logic:486] - E2: Val f1_macro (0.0276) not better than best (0.0314). Patience: 1/15
2025-05-28 14:33:03 - __main__ - INFO - [main_execution_logic:495] - Epoch 2 completed in 97.22s.
2025-05-28 14:33:03 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E2 End: Alloc 1063.4MB, Reserved 3660.0MB
2025-05-28 14:34:14 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 3 training finished. Avg Loss: 1.9369, Final LR for epoch: 3.00e-04, Opt Steps: 228
2025-05-28 14:34:46 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.0305, accuracy: 0.0930, f1_macro: 0.0719, f1_weighted: 0.0736, precision_macro: 0.0601, precision_weighted: 0.0619, recall_macro: 0.0918, recall_weighted: 0.0930, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.3182, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0399, f1_Leaf_Hopper_Jassids: 0.1450, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 14:34:50 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:194] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/checkpoints_optimized_v1/best_finetuned_hvt_xl_optimized_v1.pth
2025-05-28 14:34:50 - __main__ - INFO - [main_execution_logic:482] - E3: New best! Val f1_macro: 0.0719
2025-05-28 14:34:50 - __main__ - INFO - [main_execution_logic:495] - Epoch 3 completed in 106.49s.
2025-05-28 14:34:50 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E3 End: Alloc 1063.4MB, Reserved 3660.0MB
2025-05-28 14:35:54 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 4 training finished. Avg Loss: 1.9495, Final LR for epoch: 4.00e-04, Opt Steps: 228
2025-05-28 14:36:26 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.0450, accuracy: 0.0996, f1_macro: 0.0689, f1_weighted: 0.0770, precision_macro: 0.1276, precision_weighted: 0.1390, recall_macro: 0.0897, recall_weighted: 0.0996, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.3717, f1_Healthy_Leaf: 0.0072, f1_Herbicide_Growth_Damage: 0.0150, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0887, f1_Leaf_Variegation: 0.0000
2025-05-28 14:36:26 - __main__ - INFO - [main_execution_logic:486] - E4: Val f1_macro (0.0689) not better than best (0.0719). Patience: 1/15
2025-05-28 14:36:26 - __main__ - INFO - [main_execution_logic:495] - Epoch 4 completed in 96.78s.
2025-05-28 14:36:26 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E4 End: Alloc 1063.4MB, Reserved 3660.0MB
2025-05-28 14:37:40 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 5 training finished. Avg Loss: 1.9594, Final LR for epoch: 5.00e-04, Opt Steps: 228
2025-05-28 14:38:12 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.1315, accuracy: 0.1712, f1_macro: 0.0478, f1_weighted: 0.0593, precision_macro: 0.0289, precision_weighted: 0.0359, recall_macro: 0.1380, recall_weighted: 0.1712, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.3348, f1_Leaf_Variegation: 0.0000
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:486] - E5: Val f1_macro (0.0478) not better than best (0.0719). Patience: 2/15
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:495] - Epoch 5 completed in 106.04s.
2025-05-28 14:38:12 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E5 End: Alloc 1063.4MB, Reserved 3660.0MB
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:429] - Epoch 6: Backbone UNPROZEN. Updating LRs to unfrozen phase values.
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:443] -   Updating head group optimizer LR from 5.00e-04 to 1.00e-04
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:448] -     Updating LambdaLR's base_lr for group 'head' (idx 0) from 1.00e-03 to 1.00e-04
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:443] -   Updating backbone group optimizer LR from 0.00e+00 to 5.00e-05
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:448] -     Updating LambdaLR's base_lr for group 'backbone' (idx 1) from 0.00e+00 to 5.00e-05
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:452] -   Effective Base LRs for scheduler (after unfreezing update):
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:459] -     Opt Group 0 ('head'): Current LR 1.000e-04 (Scheduler base: 1.000e-04)
2025-05-28 14:38:12 - __main__ - INFO - [main_execution_logic:459] -     Opt Group 1 ('backbone'): Current LR 5.000e-05 (Scheduler base: 5.000e-05)
2025-05-28 14:41:34 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 6 training finished. Avg Loss: 1.9282, Final LR for epoch: 6.00e-05, Opt Steps: 228
2025-05-28 14:42:06 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 1.9366, accuracy: 0.2243, f1_macro: 0.1171, f1_weighted: 0.1304, precision_macro: 0.1230, precision_weighted: 0.1295, recall_macro: 0.1903, recall_weighted: 0.2243, f1_Bacterial_Blight: 0.1818, f1_Curl_Virus: 0.2904, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.3476, f1_Leaf_Variegation: 0.0000
2025-05-28 14:42:09 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:194] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/checkpoints_optimized_v1/best_finetuned_hvt_xl_optimized_v1.pth
2025-05-28 14:42:09 - __main__ - INFO - [main_execution_logic:482] - E6: New best! Val f1_macro: 0.1171
2025-05-28 14:42:09 - __main__ - INFO - [main_execution_logic:495] - Epoch 6 completed in 236.62s.
2025-05-28 14:42:09 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E6 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 14:45:30 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 7 training finished. Avg Loss: 1.9110, Final LR for epoch: 7.00e-05, Opt Steps: 228
2025-05-28 14:46:02 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 1.9451, accuracy: 0.2336, f1_macro: 0.1269, f1_weighted: 0.1387, precision_macro: 0.1240, precision_weighted: 0.1330, recall_macro: 0.2028, recall_weighted: 0.2336, f1_Bacterial_Blight: 0.2677, f1_Curl_Virus: 0.2752, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.3452, f1_Leaf_Variegation: 0.0000
2025-05-28 14:46:06 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:194] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/checkpoints_optimized_v1/best_finetuned_hvt_xl_optimized_v1.pth
2025-05-28 14:46:06 - __main__ - INFO - [main_execution_logic:482] - E7: New best! Val f1_macro: 0.1269
2025-05-28 14:46:06 - __main__ - INFO - [main_execution_logic:495] - Epoch 7 completed in 236.76s.
2025-05-28 14:46:06 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E7 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 14:49:27 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 8 training finished. Avg Loss: 1.9154, Final LR for epoch: 8.00e-05, Opt Steps: 228
2025-05-28 14:49:58 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 1.9706, accuracy: 0.1865, f1_macro: 0.1004, f1_weighted: 0.1114, precision_macro: 0.0889, precision_weighted: 0.0960, recall_macro: 0.1674, recall_weighted: 0.1865, f1_Bacterial_Blight: 0.1279, f1_Curl_Virus: 0.3373, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2379, f1_Leaf_Variegation: 0.0000
2025-05-28 14:49:58 - __main__ - INFO - [main_execution_logic:486] - E8: Val f1_macro (0.1004) not better than best (0.1269). Patience: 1/15
2025-05-28 14:49:58 - __main__ - INFO - [main_execution_logic:495] - Epoch 8 completed in 232.24s.
2025-05-28 14:49:58 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E8 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 14:53:18 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 9 training finished. Avg Loss: 1.9001, Final LR for epoch: 9.00e-05, Opt Steps: 228
2025-05-28 14:53:50 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 1.8758, accuracy: 0.2013, f1_macro: 0.1113, f1_weighted: 0.1254, precision_macro: 0.1245, precision_weighted: 0.1316, recall_macro: 0.1714, recall_weighted: 0.2013, f1_Bacterial_Blight: 0.0420, f1_Curl_Virus: 0.2667, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.1270, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.3437, f1_Leaf_Variegation: 0.0000
2025-05-28 14:53:50 - __main__ - INFO - [main_execution_logic:486] - E9: Val f1_macro (0.1113) not better than best (0.1269). Patience: 2/15
2025-05-28 14:53:50 - __main__ - INFO - [main_execution_logic:495] - Epoch 9 completed in 231.73s.
2025-05-28 14:53:50 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E9 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 14:57:10 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 10 training finished. Avg Loss: 1.8922, Final LR for epoch: 1.00e-04, Opt Steps: 228
2025-05-28 14:57:42 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.1930, accuracy: 0.1647, f1_macro: 0.1102, f1_weighted: 0.1131, precision_macro: 0.0963, precision_weighted: 0.1001, recall_macro: 0.1595, recall_weighted: 0.1647, f1_Bacterial_Blight: 0.2890, f1_Curl_Virus: 0.2865, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0903, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.1057, f1_Leaf_Variegation: 0.0000
2025-05-28 14:57:42 - __main__ - INFO - [main_execution_logic:486] - E10: Val f1_macro (0.1102) not better than best (0.1269). Patience: 3/15
2025-05-28 14:57:42 - __main__ - INFO - [main_execution_logic:495] - Epoch 10 completed in 232.19s.
2025-05-28 14:57:42 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E10 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 15:01:03 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 11 training finished. Avg Loss: 1.8803, Final LR for epoch: 1.00e-04, Opt Steps: 228
2025-05-28 15:01:34 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.5775, accuracy: 0.1767, f1_macro: 0.0966, f1_weighted: 0.1023, precision_macro: 0.2078, precision_weighted: 0.2195, recall_macro: 0.1779, recall_weighted: 0.1767, f1_Bacterial_Blight: 0.0866, f1_Curl_Virus: 0.1226, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.2665, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2005, f1_Leaf_Variegation: 0.0000
2025-05-28 15:01:34 - __main__ - INFO - [main_execution_logic:486] - E11: Val f1_macro (0.0966) not better than best (0.1269). Patience: 4/15
2025-05-28 15:01:34 - __main__ - INFO - [main_execution_logic:495] - Epoch 11 completed in 232.10s.
2025-05-28 15:01:34 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E11 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 15:04:54 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 12 training finished. Avg Loss: 1.8827, Final LR for epoch: 9.99e-05, Opt Steps: 228
2025-05-28 15:05:26 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.8189, accuracy: 0.1198, f1_macro: 0.0372, f1_weighted: 0.0367, precision_macro: 0.0403, precision_weighted: 0.0418, recall_macro: 0.1245, recall_weighted: 0.1198, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.0528, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.2078, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 15:05:26 - __main__ - INFO - [main_execution_logic:486] - E12: Val f1_macro (0.0372) not better than best (0.1269). Patience: 5/15
2025-05-28 15:05:26 - __main__ - INFO - [main_execution_logic:495] - Epoch 12 completed in 231.62s.
2025-05-28 15:05:26 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E12 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 15:08:46 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 13 training finished. Avg Loss: 1.8830, Final LR for epoch: 9.98e-05, Opt Steps: 228
2025-05-28 15:09:18 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.9041, accuracy: 0.1362, f1_macro: 0.0369, f1_weighted: 0.0357, precision_macro: 0.0669, precision_weighted: 0.0706, recall_macro: 0.1421, recall_weighted: 0.1362, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.0203, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.2378, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 15:09:18 - __main__ - INFO - [main_execution_logic:486] - E13: Val f1_macro (0.0369) not better than best (0.1269). Patience: 6/15
2025-05-28 15:09:18 - __main__ - INFO - [main_execution_logic:495] - Epoch 13 completed in 231.91s.
2025-05-28 15:09:18 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E13 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 15:12:38 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 14 training finished. Avg Loss: 1.8848, Final LR for epoch: 9.97e-05, Opt Steps: 228
2025-05-28 15:13:10 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.6295, accuracy: 0.1379, f1_macro: 0.0442, f1_weighted: 0.0450, precision_macro: 0.1659, precision_weighted: 0.1980, recall_macro: 0.1426, recall_weighted: 0.1379, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.0132, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.2362, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0597, f1_Leaf_Variegation: 0.0000
2025-05-28 15:13:10 - __main__ - INFO - [main_execution_logic:486] - E14: Val f1_macro (0.0442) not better than best (0.1269). Patience: 7/15
2025-05-28 15:13:10 - __main__ - INFO - [main_execution_logic:495] - Epoch 14 completed in 232.31s.
2025-05-28 15:13:10 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E14 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 15:16:31 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:113] - Epoch 15 training finished. Avg Loss: 1.8653, Final LR for epoch: 9.95e-05, Opt Steps: 228
2025-05-28 15:17:02 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:187] - Validation finished. Avg Loss: 2.5057, accuracy: 0.1597, f1_macro: 0.1033, f1_weighted: 0.1143, precision_macro: 0.1406, precision_weighted: 0.1528, recall_macro: 0.1533, recall_weighted: 0.1597, f1_Bacterial_Blight: 0.0243, f1_Curl_Virus: 0.2343, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.1923, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.2720, f1_Leaf_Variegation: 0.0000
2025-05-28 15:17:02 - __main__ - INFO - [main_execution_logic:486] - E15: Val f1_macro (0.1033) not better than best (0.1269). Patience: 8/15
2025-05-28 15:17:02 - __main__ - INFO - [main_execution_logic:495] - Epoch 15 completed in 232.60s.
2025-05-28 15:17:02 - __main__ - DEBUG - [main_execution_logic:496] - CUDA Mem E15 End: Alloc 3165.2MB, Reserved 8920.0MB
2025-05-28 15:18:58 - __main__ - WARNING - [main_execution_logic:499] - Fine-tuning interrupted by user. Last completed epoch: 15.
2025-05-28 15:18:58 - __main__ - INFO - [main_execution_logic:504] - Fine-tuning process ended. Last successfully completed epoch: 15.
2025-05-28 15:19:00 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:194] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_v1/checkpoints_optimized_v1/final_finetuned_hvt_xl_optimized_v1.pth
2025-05-28 15:19:00 - __main__ - INFO - [main_execution_logic:507] - Fine-tuning summary: Best validation 'f1_macro': 0.1269 (achieved during training).
