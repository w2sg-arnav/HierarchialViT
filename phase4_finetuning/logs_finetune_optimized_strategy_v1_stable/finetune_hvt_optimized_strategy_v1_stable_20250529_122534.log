2025-05-29 12:25:34 - root - INFO - [setup_logging:75] - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/finetune_hvt_optimized_strategy_v1_stable_20250529_122534.log. Logger 'root' Effective Level: DEBUG
2025-05-29 12:25:34 - __main__ - INFO - [main_execution_logic:243] - ======== Starting Phase 4: HVT Fine-tuning (Run ID: 20250529_122534) ========
2025-05-29 12:25:34 - __main__ - INFO - [main_execution_logic:244] - Full run configuration: {'seed': 42, 'device': 'cuda', 'PACKAGE_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25/phase4_finetuning', 'PROJECT_ROOT_PATH': '/teamspace/studios/this_studio/cvpr25', 'log_dir': 'logs_finetune_optimized_strategy_v1_stable', 'log_file_finetune': 'finetune_hvt_optimized_strategy_v1_stable.log', 'best_model_filename': 'best_finetuned_hvt_optimized_strategy_v1_stable.pth', 'final_model_filename': 'final_finetuned_hvt_optimized_strategy_v1_stable.pth', 'checkpoint_save_dir_name': 'checkpoints_optimized_strategy_v1_stable', 'data_root': '/teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection', 'original_dataset_name': 'Original Dataset', 'augmented_dataset_name': 'Augmented Dataset', 'img_size': (448, 448), 'num_classes': 7, 'train_split_ratio': 0.85, 'normalize_data': True, 'use_weighted_sampler': True, 'weighted_sampler_mode': 'sqrt_inv_count', 'use_weighted_loss': True, 'num_workers': 4, 'prefetch_factor': 2, 'model_architecture_name': 'DiseaseAwareHVT_Optimized_Strategy_Finetune_v1_Stable', 'pretrained_checkpoint_path': '/teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth', 'load_pretrained_backbone': True, 'hvt_params_for_model_init': {'patch_size': 14, 'embed_dim_rgb': 192, 'embed_dim_spectral': 192, 'spectral_channels': 0, 'depths': [3, 6, 24, 3], 'num_heads': [6, 12, 24, 48], 'mlp_ratio': 4.0, 'qkv_bias': True, 'model_drop_rate': 0.1, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.05, 'norm_layer_name': 'LayerNorm', 'use_dfca': False, 'use_gradient_checkpointing': True, 'ssl_enable_mae': False, 'ssl_enable_contrastive': False, 'enable_consistency_loss_heads': False, 'dfca_embed_dim_match_rgb': True, 'dfca_num_heads': 32, 'dfca_drop_rate': 0.1, 'dfca_use_disease_mask': True, 'ssl_mae_mask_ratio': 0.75, 'ssl_mae_decoder_dim': 64, 'ssl_mae_norm_pix_loss': True, 'ssl_contrastive_projector_dim': 128, 'ssl_contrastive_projector_depth': 2}, 'enable_torch_compile': False, 'torch_compile_mode': 'reduce-overhead', 'matmul_precision': 'high', 'cudnn_benchmark': True, 'freeze_backbone_epochs': 5, 'epochs': 150, 'batch_size': 8, 'accumulation_steps': 6, 'amp_enabled': False, 'clip_grad_norm': 0.5, 'optimizer': 'AdamW', 'optimizer_params': {'betas': (0.9, 0.999), 'eps': 1e-07}, 'weight_decay': 0.05, 'lr_head_frozen_phase': 0.0001, 'lr_backbone_unfrozen_phase': 1e-05, 'lr_head_unfrozen_phase': 0.0001, 'scheduler': 'WarmupCosine', 'warmup_epochs': 15, 'eta_min_lr': 1e-07, 'loss_label_smoothing': 0.1, 'augmentations_enabled': True, 'augmentation_strategy': 'stable_enhanced', 'augmentation_severity': 'mild', 'evaluate_every_n_epochs': 1, 'early_stopping_patience': 25, 'metric_to_monitor_early_stopping': 'f1_macro', 'tta_enabled_val': True, 'ssl_pretrain_img_size_fallback': (448, 448), 'debug_nan_detection': True, 'stop_on_nan_threshold': 5, 'monitor_gradients': True, 'gradient_log_interval': 50, 'save_checkpoint_every_n_epochs': 10}
2025-05-29 12:25:34 - __main__ - INFO - [set_global_seed:66] - Global random seed set to: 42
2025-05-29 12:25:34 - __main__ - INFO - [main_execution_logic:248] - Using device: cuda. GPU: Tesla T4
2025-05-29 12:25:34 - phase4_finetuning.dataset - INFO - [__init__:54] - [DATASET INIT - train] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448), Normalize: True
2025-05-29 12:25:34 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-29 12:25:34 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-29 12:25:35 - phase4_finetuning.dataset - INFO - [__init__:105] - [DATASET INIT - train] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-29 12:25:35 - phase4_finetuning.dataset - INFO - [__init__:117] - [DATASET INIT - train] Dataset split size: 7766 samples.
2025-05-29 12:25:35 - phase4_finetuning.dataset - INFO - [__init__:128] - [DATASET INIT - train] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=True)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
)
2025-05-29 12:25:35 - phase4_finetuning.dataset - INFO - [__init__:54] - [DATASET INIT - val] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448), Normalize: True
2025-05-29 12:25:35 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-29 12:25:35 - phase4_finetuning.dataset - INFO - [__init__:74] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-29 12:25:37 - phase4_finetuning.dataset - INFO - [__init__:105] - [DATASET INIT - val] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-29 12:25:37 - phase4_finetuning.dataset - INFO - [__init__:117] - [DATASET INIT - val] Dataset split size: 1371 samples.
2025-05-29 12:25:37 - phase4_finetuning.dataset - INFO - [__init__:128] - [DATASET INIT - val] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=True)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
)
2025-05-29 12:25:37 - __main__ - INFO - [main_execution_logic:276] - Using WeightedRandomSampler with 'sqrt_inv_count' mode. Per-class weights: [0.031 0.029 0.031 0.03  0.031 0.027 0.032]
2025-05-29 12:25:37 - __main__ - INFO - [main_execution_logic:287] - WeightedRandomSampler enabled (mode: sqrt_inv_count).
2025-05-29 12:25:37 - __main__ - INFO - [main_execution_logic:293] - Dataloaders created. Train batches: 970, Val batches: 172
2025-05-29 12:25:37 - phase2_model.models.hvt - INFO - [create_disease_aware_hvt:602] - Factory: Creating DiseaseAwareHVT for img_size: (448, 448), num_classes: 7
2025-05-29 12:25:40 - phase2_model.models.hvt - INFO - [__init__:325] - HVT: Running RGB stream only. No fusion.
2025-05-29 12:25:42 - phase2_model.models.hvt - INFO - [__init__:359] - DiseaseAwareHVT initialized for image size (448, 448) and 7 classes.
2025-05-29 12:25:42 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:136] - Loading SSL backbone weights from: /teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth
2025-05-29 12:25:45 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:149] - SSL and Finetune img_size match: (448, 448).
2025-05-29 12:25:45 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:186] - PE rgb_pos_embed: Shape matches. Loading directly.
2025-05-29 12:25:45 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:197] - SSL Backbone weights loaded: 450 direct, 0 PE interpolated, 2 head layers skipped.
2025-05-29 12:25:45 - __main__.load_and_prepare_hvt_model - WARNING - [load_and_prepare_hvt_model:198] - Missing keys when loading SSL backbone: ['classifier_head.weight', 'classifier_head.bias']
2025-05-29 12:25:45 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:218] - Re-initialized HVT classifier_head for 7 classes (in_features=1536).
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:298] - Model ready. Total params: 273,615,751, Trainable params: 273,615,751
2025-05-29 12:25:46 - phase4_finetuning.utils.augmentations - INFO - [create_augmentation:228] - Creating augmentation strategy: 'stable_enhanced' with img_size: (448, 448), kwargs: {'severity': 'mild'}
2025-05-29 12:25:46 - phase4_finetuning.utils.augmentations - INFO - [__init__:104] - StableEnhancedFinetuneAugmentation initialized with 'mild' severity for stability.
2025-05-29 12:25:46 - phase4_finetuning.utils.augmentations - DEBUG - [__init__:105] - Augmentation pipeline: Compose(
      RandomHorizontalFlip(p=0.5)
      RandomVerticalFlip(p=0.3)
      RandomRotation(degrees=[-10.0, 10.0], interpolation=InterpolationMode.BILINEAR, expand=False, fill=0.0)
      StableColorJitter()
      RandomAffine(degrees=[-5.0, 5.0], translate=(0.05, 0.05), scale=(0.95, 1.05), shear=[-5.0, 5.0], interpolation=InterpolationMode.BILINEAR, fill=0.0)
      RandomPerspective(p=0.15, distortion_scale=0.1, interpolation=InterpolationMode.BILINEAR, fill=0.0)
      RandomApply(    GaussianBlur(kernel_size=(3, 3), sigma=[0.1, 0.5]))
      StableRandomErasing()
)
2025-05-29 12:25:46 - phase4_finetuning.dataset - INFO - [get_class_weights:196] - Computed class weights (inv_freq for loss) for split 'train': [1.034 0.905 1.061 1.02  1.065 0.829 1.164]
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:318] - Using weighted CrossEntropyLoss. Weights: [1.034 0.905 1.061 1.02  1.065 0.829 1.164]
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:329] - Optimizer initial setup: Backbone frozen. Head LR: 1.00e-04, Backbone LR: 0.00e+00
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:347] - Optimizer: AdamW created with overall defaults: {'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-07, 'weight_decay': 0.05, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'differentiable': False, 'fused': None}
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:349] -   Group 'head': Configured LR 1.00e-04, WD 5.00e-02
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:349] -   Group 'backbone': Configured LR 0.00e+00, WD 5.00e-02
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:367] - Scheduler: WarmupCosine (per-step). WU Steps: 2415, Total Steps: 24150
2025-05-29 12:25:46 - phase4_finetuning.finetune.trainer - INFO - [__init__:54] - Finetuner initialized: device=cuda, accum_steps=6, AMP=False
2025-05-29 12:25:46 - phase4_finetuning.finetune.trainer - INFO - [__init__:55] - Using training augmentations: StableEnhancedFinetuneAugmentation
2025-05-29 12:25:46 - phase4_finetuning.finetune.trainer - INFO - [__init__:56] - Test-Time Augmentation (TTA) enabled for validation.
2025-05-29 12:25:46 - phase4_finetuning.finetune.trainer - INFO - [__init__:57] - NaN detection enabled. Stop threshold: 5 NaNs/epoch.
2025-05-29 12:25:46 - phase4_finetuning.finetune.trainer - INFO - [__init__:58] - Gradient monitoring enabled. Log interval: 50 optimizer steps.
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:401] - Checkpoints will be saved in: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:404] - LRs after scheduler initialization:
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:409] -   Opt Group 0 ('head'): Current LR in optimizer 0.00e+00, Scheduler Base LR 1.00e-04
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:409] -   Opt Group 1 ('backbone'): Current LR in optimizer 0.00e+00, Scheduler Base LR 0.00e+00
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:412] - Starting fine-tuning for 150 epochs. Monitor: 'f1_macro'. Backbone frozen for initial 5 epochs.
2025-05-29 12:25:46 - __main__ - INFO - [main_execution_logic:434] - Epoch 1: Starting in Frozen Backbone phase.
2025-05-29 12:26:30 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E1 OptStep 50: Grad Norm: 10.4876
2025-05-29 12:27:10 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E1 OptStep 100: Grad Norm: 7.4451
2025-05-29 12:27:51 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E1 OptStep 150: Grad Norm: 5.9138
2025-05-29 12:28:00 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 1 training finished. Avg Loss: 2.0754, Final LR: 6.67e-06, Opt Steps: 161, NaN count: 0
2025-05-29 12:29:02 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 2.0073, accuracy: 0.1889, f1_macro: 0.0840, f1_weighted: 0.0812, precision_macro: 0.0655, precision_weighted: 0.0642, recall_macro: 0.1953, recall_weighted: 0.1889, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.0177, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.3660, f1_Leaf_Hopper_Jassids: 0.2041, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-29 12:29:04 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 12:29:04 - __main__ - INFO - [main_execution_logic:479] - E1: New best! Val f1_macro: 0.0840
2025-05-29 12:29:04 - __main__ - INFO - [main_execution_logic:496] - Epoch 1 completed in 197.71s.
2025-05-29 12:29:04 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E1 End: Alloc 1063.5MB, Reserved 1388.0MB
2025-05-29 12:29:45 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E2 OptStep 50: Grad Norm: 5.1011
2025-05-29 12:30:25 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E2 OptStep 100: Grad Norm: 5.2977
2025-05-29 12:31:06 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E2 OptStep 150: Grad Norm: 6.0707
2025-05-29 12:31:15 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 2 training finished. Avg Loss: 1.9199, Final LR: 1.33e-05, Opt Steps: 161, NaN count: 0
2025-05-29 12:32:17 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.8970, accuracy: 0.2553, f1_macro: 0.2193, f1_weighted: 0.2259, precision_macro: 0.2262, precision_weighted: 0.2312, recall_macro: 0.2487, recall_weighted: 0.2553, f1_Bacterial_Blight: 0.1945, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.0980, f1_Herbicide_Growth_Damage: 0.2836, f1_Leaf_Hopper_Jassids: 0.1721, f1_Leaf_Redding: 0.5247, f1_Leaf_Variegation: 0.2625
2025-05-29 12:32:20 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 12:32:20 - __main__ - INFO - [main_execution_logic:479] - E2: New best! Val f1_macro: 0.2193
2025-05-29 12:32:20 - __main__ - INFO - [main_execution_logic:496] - Epoch 2 completed in 196.53s.
2025-05-29 12:32:20 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E2 End: Alloc 1063.5MB, Reserved 1774.0MB
2025-05-29 12:33:01 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E3 OptStep 50: Grad Norm: 3.0100
2025-05-29 12:33:42 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E3 OptStep 100: Grad Norm: 3.0865
2025-05-29 12:34:22 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E3 OptStep 150: Grad Norm: 4.2261
2025-05-29 12:34:32 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 3 training finished. Avg Loss: 1.8286, Final LR: 2.00e-05, Opt Steps: 161, NaN count: 0
2025-05-29 12:35:34 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.8281, accuracy: 0.3107, f1_macro: 0.2567, f1_weighted: 0.2660, precision_macro: 0.3307, precision_weighted: 0.3293, recall_macro: 0.2959, recall_weighted: 0.3107, f1_Bacterial_Blight: 0.2469, f1_Curl_Virus: 0.0000, f1_Healthy_Leaf: 0.3006, f1_Herbicide_Growth_Damage: 0.3323, f1_Leaf_Hopper_Jassids: 0.1000, f1_Leaf_Redding: 0.5502, f1_Leaf_Variegation: 0.2667
2025-05-29 12:35:37 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 12:35:37 - __main__ - INFO - [main_execution_logic:479] - E3: New best! Val f1_macro: 0.2567
2025-05-29 12:35:37 - __main__ - INFO - [main_execution_logic:496] - Epoch 3 completed in 196.90s.
2025-05-29 12:35:37 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E3 End: Alloc 1063.5MB, Reserved 1774.0MB
2025-05-29 12:36:18 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E4 OptStep 50: Grad Norm: 4.3155
2025-05-29 12:36:59 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E4 OptStep 100: Grad Norm: 5.9793
2025-05-29 12:37:39 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E4 OptStep 150: Grad Norm: 3.9461
2025-05-29 12:37:48 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 4 training finished. Avg Loss: 1.7608, Final LR: 2.67e-05, Opt Steps: 161, NaN count: 0
2025-05-29 12:38:50 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.7617, accuracy: 0.3392, f1_macro: 0.2755, f1_weighted: 0.2836, precision_macro: 0.3079, precision_weighted: 0.3080, recall_macro: 0.3255, recall_weighted: 0.3392, f1_Bacterial_Blight: 0.2387, f1_Curl_Virus: 0.0170, f1_Healthy_Leaf: 0.3447, f1_Herbicide_Growth_Damage: 0.3780, f1_Leaf_Hopper_Jassids: 0.0208, f1_Leaf_Redding: 0.5505, f1_Leaf_Variegation: 0.3791
2025-05-29 12:38:55 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 12:38:55 - __main__ - INFO - [main_execution_logic:479] - E4: New best! Val f1_macro: 0.2755
2025-05-29 12:38:55 - __main__ - INFO - [main_execution_logic:496] - Epoch 4 completed in 197.32s.
2025-05-29 12:38:55 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E4 End: Alloc 1063.5MB, Reserved 1774.0MB
2025-05-29 12:39:36 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E5 OptStep 50: Grad Norm: 4.6034
2025-05-29 12:40:16 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E5 OptStep 100: Grad Norm: 3.2151
2025-05-29 12:40:56 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E5 OptStep 150: Grad Norm: 5.2377
2025-05-29 12:41:06 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 5 training finished. Avg Loss: 1.7026, Final LR: 3.33e-05, Opt Steps: 161, NaN count: 0
2025-05-29 12:42:08 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.7094, accuracy: 0.3654, f1_macro: 0.3072, f1_weighted: 0.3133, precision_macro: 0.3618, precision_weighted: 0.3583, recall_macro: 0.3529, recall_weighted: 0.3654, f1_Bacterial_Blight: 0.2520, f1_Curl_Virus: 0.0252, f1_Healthy_Leaf: 0.3862, f1_Herbicide_Growth_Damage: 0.4054, f1_Leaf_Hopper_Jassids: 0.0882, f1_Leaf_Redding: 0.5511, f1_Leaf_Variegation: 0.4421
2025-05-29 12:42:11 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:479] - E5: New best! Val f1_macro: 0.3072
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:496] - Epoch 5 completed in 196.40s.
2025-05-29 12:42:11 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E5 End: Alloc 1063.5MB, Reserved 1774.0MB
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:437] - Epoch 6: Backbone UNPROZEN. Updating LRs.
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:446] -   Updating head group optimizer LR to 1.00e-04
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:446] -   Updating backbone group optimizer LR to 1.00e-05
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:450] -     Updating Scheduler's base_lr for group 'backbone' to 1.00e-05
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:453] -   Effective LRs for scheduler after unfreezing update:
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:454] -     Opt Group 0 ('head'): LR 1.000e-04, Scheduler base 1.000e-04
2025-05-29 12:42:11 - __main__ - INFO - [main_execution_logic:454] -     Opt Group 1 ('backbone'): LR 1.000e-05, Scheduler base 1.000e-05
2025-05-29 12:44:42 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E6 OptStep 50: Grad Norm: 3.4508
2025-05-29 12:47:12 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E6 OptStep 100: Grad Norm: 5.1939
2025-05-29 12:49:43 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E6 OptStep 150: Grad Norm: 5.1568
2025-05-29 12:50:18 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 6 training finished. Avg Loss: 1.6323, Final LR: 4.00e-05, Opt Steps: 161, NaN count: 0
2025-05-29 12:51:20 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.5833, accuracy: 0.4245, f1_macro: 0.3628, f1_weighted: 0.3692, precision_macro: 0.4369, precision_weighted: 0.4326, recall_macro: 0.4122, recall_weighted: 0.4245, f1_Bacterial_Blight: 0.3026, f1_Curl_Virus: 0.1060, f1_Healthy_Leaf: 0.4497, f1_Herbicide_Growth_Damage: 0.5346, f1_Leaf_Hopper_Jassids: 0.0718, f1_Leaf_Redding: 0.5851, f1_Leaf_Variegation: 0.4895
2025-05-29 12:51:24 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 12:51:24 - __main__ - INFO - [main_execution_logic:479] - E6: New best! Val f1_macro: 0.3628
2025-05-29 12:51:24 - __main__ - INFO - [main_execution_logic:496] - Epoch 6 completed in 552.80s.
2025-05-29 12:51:24 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E6 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 12:53:55 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E7 OptStep 50: Grad Norm: 2.8626
2025-05-29 12:56:26 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E7 OptStep 100: Grad Norm: 4.6691
2025-05-29 12:58:56 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E7 OptStep 150: Grad Norm: 4.5146
2025-05-29 12:59:31 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 7 training finished. Avg Loss: 1.5424, Final LR: 4.67e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:00:33 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.4907, accuracy: 0.4588, f1_macro: 0.3886, f1_weighted: 0.3946, precision_macro: 0.4218, precision_weighted: 0.4240, recall_macro: 0.4499, recall_weighted: 0.4588, f1_Bacterial_Blight: 0.0755, f1_Curl_Virus: 0.1061, f1_Healthy_Leaf: 0.4511, f1_Herbicide_Growth_Damage: 0.6208, f1_Leaf_Hopper_Jassids: 0.2302, f1_Leaf_Redding: 0.6204, f1_Leaf_Variegation: 0.6163
2025-05-29 13:00:37 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 13:00:37 - __main__ - INFO - [main_execution_logic:479] - E7: New best! Val f1_macro: 0.3886
2025-05-29 13:00:37 - __main__ - INFO - [main_execution_logic:496] - Epoch 7 completed in 552.90s.
2025-05-29 13:00:37 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E7 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:03:08 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E8 OptStep 50: Grad Norm: 4.0781
2025-05-29 13:05:39 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E8 OptStep 100: Grad Norm: 6.4445
2025-05-29 13:08:10 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E8 OptStep 150: Grad Norm: 3.2179
2025-05-29 13:08:45 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 8 training finished. Avg Loss: 1.4817, Final LR: 5.33e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:09:47 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.4502, accuracy: 0.5004, f1_macro: 0.4652, f1_weighted: 0.4675, precision_macro: 0.4829, precision_weighted: 0.4829, recall_macro: 0.4962, recall_weighted: 0.5004, f1_Bacterial_Blight: 0.3077, f1_Curl_Virus: 0.2177, f1_Healthy_Leaf: 0.5000, f1_Herbicide_Growth_Damage: 0.6565, f1_Leaf_Hopper_Jassids: 0.2867, f1_Leaf_Redding: 0.6230, f1_Leaf_Variegation: 0.6647
2025-05-29 13:09:50 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 13:09:50 - __main__ - INFO - [main_execution_logic:479] - E8: New best! Val f1_macro: 0.4652
2025-05-29 13:09:50 - __main__ - INFO - [main_execution_logic:496] - Epoch 8 completed in 553.28s.
2025-05-29 13:09:50 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E8 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:12:21 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E9 OptStep 50: Grad Norm: 3.7256
2025-05-29 13:14:52 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E9 OptStep 100: Grad Norm: 4.9311
2025-05-29 13:17:23 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E9 OptStep 150: Grad Norm: 3.7982
2025-05-29 13:17:58 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 9 training finished. Avg Loss: 1.4435, Final LR: 6.00e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:19:00 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.4231, accuracy: 0.5084, f1_macro: 0.4473, f1_weighted: 0.4549, precision_macro: 0.5261, precision_weighted: 0.5296, recall_macro: 0.5008, recall_weighted: 0.5084, f1_Bacterial_Blight: 0.0729, f1_Curl_Virus: 0.3475, f1_Healthy_Leaf: 0.4871, f1_Herbicide_Growth_Damage: 0.7343, f1_Leaf_Hopper_Jassids: 0.1732, f1_Leaf_Redding: 0.6425, f1_Leaf_Variegation: 0.6738
2025-05-29 13:19:00 - __main__ - INFO - [main_execution_logic:482] - E9: Val f1_macro (0.4473) not better. Patience: 1/25
2025-05-29 13:19:00 - __main__ - INFO - [main_execution_logic:496] - Epoch 9 completed in 549.98s.
2025-05-29 13:19:00 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E9 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:21:31 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E10 OptStep 50: Grad Norm: 5.3538
2025-05-29 13:24:02 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E10 OptStep 100: Grad Norm: 5.2769
2025-05-29 13:26:33 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E10 OptStep 150: Grad Norm: 3.2215
2025-05-29 13:27:08 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 10 training finished. Avg Loss: 1.4213, Final LR: 6.67e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:28:10 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.4097, accuracy: 0.5150, f1_macro: 0.4427, f1_weighted: 0.4490, precision_macro: 0.5261, precision_weighted: 0.5264, recall_macro: 0.5064, recall_weighted: 0.5150, f1_Bacterial_Blight: 0.1268, f1_Curl_Virus: 0.2721, f1_Healthy_Leaf: 0.4993, f1_Herbicide_Growth_Damage: 0.7220, f1_Leaf_Hopper_Jassids: 0.1143, f1_Leaf_Redding: 0.6506, f1_Leaf_Variegation: 0.7135
2025-05-29 13:28:10 - __main__ - INFO - [main_execution_logic:482] - E10: Val f1_macro (0.4427) not better. Patience: 2/25
2025-05-29 13:28:12 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/checkpoint_epoch_10.pth
2025-05-29 13:28:12 - __main__ - INFO - [main_execution_logic:496] - Epoch 10 completed in 551.78s.
2025-05-29 13:28:12 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E10 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:30:43 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E11 OptStep 50: Grad Norm: 3.0696
2025-05-29 13:33:14 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E11 OptStep 100: Grad Norm: 3.8036
2025-05-29 13:35:45 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E11 OptStep 150: Grad Norm: 5.8745
2025-05-29 13:36:20 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 11 training finished. Avg Loss: 1.3912, Final LR: 7.33e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:37:22 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.3632, accuracy: 0.5281, f1_macro: 0.4644, f1_weighted: 0.4703, precision_macro: 0.5582, precision_weighted: 0.5604, recall_macro: 0.5225, recall_weighted: 0.5281, f1_Bacterial_Blight: 0.1569, f1_Curl_Virus: 0.2748, f1_Healthy_Leaf: 0.5136, f1_Herbicide_Growth_Damage: 0.7380, f1_Leaf_Hopper_Jassids: 0.1992, f1_Leaf_Redding: 0.6638, f1_Leaf_Variegation: 0.7044
2025-05-29 13:37:22 - __main__ - INFO - [main_execution_logic:482] - E11: Val f1_macro (0.4644) not better. Patience: 3/25
2025-05-29 13:37:22 - __main__ - INFO - [main_execution_logic:496] - Epoch 11 completed in 549.87s.
2025-05-29 13:37:22 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E11 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:39:53 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E12 OptStep 50: Grad Norm: 4.3740
2025-05-29 13:42:24 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E12 OptStep 100: Grad Norm: 3.5084
2025-05-29 13:44:54 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E12 OptStep 150: Grad Norm: 3.5673
2025-05-29 13:45:29 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 12 training finished. Avg Loss: 1.3640, Final LR: 8.00e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:46:31 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.3413, accuracy: 0.5587, f1_macro: 0.5092, f1_weighted: 0.5103, precision_macro: 0.5592, precision_weighted: 0.5605, recall_macro: 0.5593, recall_weighted: 0.5587, f1_Bacterial_Blight: 0.4955, f1_Curl_Virus: 0.2727, f1_Healthy_Leaf: 0.5490, f1_Herbicide_Growth_Damage: 0.7269, f1_Leaf_Hopper_Jassids: 0.1395, f1_Leaf_Redding: 0.6488, f1_Leaf_Variegation: 0.7323
2025-05-29 13:46:34 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 13:46:34 - __main__ - INFO - [main_execution_logic:479] - E12: New best! Val f1_macro: 0.5092
2025-05-29 13:46:34 - __main__ - INFO - [main_execution_logic:496] - Epoch 12 completed in 552.88s.
2025-05-29 13:46:34 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E12 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:49:06 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E13 OptStep 50: Grad Norm: 4.1284
2025-05-29 13:51:36 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E13 OptStep 100: Grad Norm: 4.4284
2025-05-29 13:54:07 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E13 OptStep 150: Grad Norm: 4.6806
2025-05-29 13:54:42 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 13 training finished. Avg Loss: 1.3341, Final LR: 8.67e-05, Opt Steps: 161, NaN count: 0
2025-05-29 13:55:44 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.2974, accuracy: 0.5864, f1_macro: 0.5557, f1_weighted: 0.5564, precision_macro: 0.5916, precision_weighted: 0.5981, recall_macro: 0.5913, recall_weighted: 0.5864, f1_Bacterial_Blight: 0.5269, f1_Curl_Virus: 0.3723, f1_Healthy_Leaf: 0.5969, f1_Herbicide_Growth_Damage: 0.7393, f1_Leaf_Hopper_Jassids: 0.2595, f1_Leaf_Redding: 0.6560, f1_Leaf_Variegation: 0.7392
2025-05-29 13:55:47 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 13:55:47 - __main__ - INFO - [main_execution_logic:479] - E13: New best! Val f1_macro: 0.5557
2025-05-29 13:55:47 - __main__ - INFO - [main_execution_logic:496] - Epoch 13 completed in 552.97s.
2025-05-29 13:55:47 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E13 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 13:58:19 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E14 OptStep 50: Grad Norm: 4.3136
2025-05-29 14:00:50 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E14 OptStep 100: Grad Norm: 4.1974
2025-05-29 14:03:20 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E14 OptStep 150: Grad Norm: 5.6294
2025-05-29 14:03:55 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 14 training finished. Avg Loss: 1.3064, Final LR: 9.33e-05, Opt Steps: 161, NaN count: 0
2025-05-29 14:04:57 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.2777, accuracy: 0.5959, f1_macro: 0.5781, f1_weighted: 0.5771, precision_macro: 0.6042, precision_weighted: 0.6076, recall_macro: 0.6019, recall_weighted: 0.5959, f1_Bacterial_Blight: 0.5333, f1_Curl_Virus: 0.3662, f1_Healthy_Leaf: 0.5812, f1_Herbicide_Growth_Damage: 0.7720, f1_Leaf_Hopper_Jassids: 0.3586, f1_Leaf_Redding: 0.6652, f1_Leaf_Variegation: 0.7701
2025-05-29 14:05:01 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 14:05:01 - __main__ - INFO - [main_execution_logic:479] - E14: New best! Val f1_macro: 0.5781
2025-05-29 14:05:01 - __main__ - INFO - [main_execution_logic:496] - Epoch 14 completed in 553.21s.
2025-05-29 14:05:01 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E14 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 14:07:32 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E15 OptStep 50: Grad Norm: 3.9173
2025-05-29 14:10:03 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E15 OptStep 100: Grad Norm: 5.3750
2025-05-29 14:12:33 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E15 OptStep 150: Grad Norm: 3.3027
2025-05-29 14:13:08 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 15 training finished. Avg Loss: 1.3014, Final LR: 1.00e-04, Opt Steps: 161, NaN count: 0
2025-05-29 14:14:10 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.2674, accuracy: 0.5974, f1_macro: 0.5804, f1_weighted: 0.5787, precision_macro: 0.6178, precision_weighted: 0.6208, recall_macro: 0.6044, recall_weighted: 0.5974, f1_Bacterial_Blight: 0.5276, f1_Curl_Virus: 0.3564, f1_Healthy_Leaf: 0.5829, f1_Herbicide_Growth_Damage: 0.7642, f1_Leaf_Hopper_Jassids: 0.3864, f1_Leaf_Redding: 0.6610, f1_Leaf_Variegation: 0.7847
2025-05-29 14:14:14 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 14:14:14 - __main__ - INFO - [main_execution_logic:479] - E15: New best! Val f1_macro: 0.5804
2025-05-29 14:14:14 - __main__ - INFO - [main_execution_logic:496] - Epoch 15 completed in 553.58s.
2025-05-29 14:14:14 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E15 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 14:16:45 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E16 OptStep 50: Grad Norm: 2.5446
2025-05-29 14:19:17 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E16 OptStep 100: Grad Norm: 3.8515
2025-05-29 14:21:48 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E16 OptStep 150: Grad Norm: 6.1229
2025-05-29 14:22:23 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 16 training finished. Avg Loss: 1.2806, Final LR: 1.00e-04, Opt Steps: 161, NaN count: 0
2025-05-29 14:23:25 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.2184, accuracy: 0.6404, f1_macro: 0.6279, f1_weighted: 0.6271, precision_macro: 0.6523, precision_weighted: 0.6544, recall_macro: 0.6437, recall_weighted: 0.6404, f1_Bacterial_Blight: 0.5561, f1_Curl_Virus: 0.4906, f1_Healthy_Leaf: 0.6455, f1_Herbicide_Growth_Damage: 0.8145, f1_Leaf_Hopper_Jassids: 0.4057, f1_Leaf_Redding: 0.6773, f1_Leaf_Variegation: 0.8058
2025-05-29 14:23:28 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 14:23:28 - __main__ - INFO - [main_execution_logic:479] - E16: New best! Val f1_macro: 0.6279
2025-05-29 14:23:28 - __main__ - INFO - [main_execution_logic:496] - Epoch 16 completed in 554.21s.
2025-05-29 14:23:28 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E16 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 14:26:00 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E17 OptStep 50: Grad Norm: 5.5725
2025-05-29 14:28:31 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E17 OptStep 100: Grad Norm: 5.1697
2025-05-29 14:31:02 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E17 OptStep 150: Grad Norm: 3.1763
2025-05-29 14:31:37 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 17 training finished. Avg Loss: 1.2565, Final LR: 9.99e-05, Opt Steps: 161, NaN count: 0
2025-05-29 14:32:39 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.2023, accuracy: 0.6448, f1_macro: 0.6263, f1_weighted: 0.6243, precision_macro: 0.6570, precision_weighted: 0.6589, recall_macro: 0.6497, recall_weighted: 0.6448, f1_Bacterial_Blight: 0.5626, f1_Curl_Virus: 0.3927, f1_Healthy_Leaf: 0.6803, f1_Herbicide_Growth_Damage: 0.7982, f1_Leaf_Hopper_Jassids: 0.4371, f1_Leaf_Redding: 0.6809, f1_Leaf_Variegation: 0.8319
2025-05-29 14:32:39 - __main__ - INFO - [main_execution_logic:482] - E17: Val f1_macro (0.6263) not better. Patience: 1/25
2025-05-29 14:32:39 - __main__ - INFO - [main_execution_logic:496] - Epoch 17 completed in 550.06s.
2025-05-29 14:32:39 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E17 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 14:35:10 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E18 OptStep 50: Grad Norm: 4.4494
2025-05-29 14:37:41 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E18 OptStep 100: Grad Norm: 5.0939
2025-05-29 14:40:12 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E18 OptStep 150: Grad Norm: 4.5287
2025-05-29 14:40:47 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 18 training finished. Avg Loss: 1.2453, Final LR: 9.99e-05, Opt Steps: 161, NaN count: 0
2025-05-29 14:41:49 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.2004, accuracy: 0.6448, f1_macro: 0.6353, f1_weighted: 0.6338, precision_macro: 0.6575, precision_weighted: 0.6595, recall_macro: 0.6489, recall_weighted: 0.6448, f1_Bacterial_Blight: 0.5547, f1_Curl_Virus: 0.4863, f1_Healthy_Leaf: 0.6510, f1_Herbicide_Growth_Damage: 0.8112, f1_Leaf_Hopper_Jassids: 0.4483, f1_Leaf_Redding: 0.6776, f1_Leaf_Variegation: 0.8179
2025-05-29 14:41:52 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 14:41:52 - __main__ - INFO - [main_execution_logic:479] - E18: New best! Val f1_macro: 0.6353
2025-05-29 14:41:52 - __main__ - INFO - [main_execution_logic:496] - Epoch 18 completed in 553.95s.
2025-05-29 14:41:52 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E18 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 14:44:24 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E19 OptStep 50: Grad Norm: 3.4653
2025-05-29 14:46:55 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E19 OptStep 100: Grad Norm: 3.7981
2025-05-29 14:49:26 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E19 OptStep 150: Grad Norm: 4.2579
2025-05-29 14:50:01 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 19 training finished. Avg Loss: 1.2286, Final LR: 9.98e-05, Opt Steps: 161, NaN count: 0
2025-05-29 14:51:03 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.1700, accuracy: 0.6601, f1_macro: 0.6516, f1_weighted: 0.6500, precision_macro: 0.6773, precision_weighted: 0.6823, recall_macro: 0.6679, recall_weighted: 0.6601, f1_Bacterial_Blight: 0.5647, f1_Curl_Virus: 0.5188, f1_Healthy_Leaf: 0.6904, f1_Herbicide_Growth_Damage: 0.8085, f1_Leaf_Hopper_Jassids: 0.4558, f1_Leaf_Redding: 0.6796, f1_Leaf_Variegation: 0.8433
2025-05-29 14:51:07 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 14:51:07 - __main__ - INFO - [main_execution_logic:479] - E19: New best! Val f1_macro: 0.6516
2025-05-29 14:51:07 - __main__ - INFO - [main_execution_logic:496] - Epoch 19 completed in 554.40s.
2025-05-29 14:51:07 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E19 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 14:53:39 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E20 OptStep 50: Grad Norm: 3.2412
2025-05-29 14:56:10 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E20 OptStep 100: Grad Norm: 4.1479
2025-05-29 14:58:41 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E20 OptStep 150: Grad Norm: 4.6487
2025-05-29 14:59:16 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 20 training finished. Avg Loss: 1.2333, Final LR: 9.97e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:00:18 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.1475, accuracy: 0.6667, f1_macro: 0.6528, f1_weighted: 0.6519, precision_macro: 0.6726, precision_weighted: 0.6751, recall_macro: 0.6717, recall_weighted: 0.6667, f1_Bacterial_Blight: 0.5882, f1_Curl_Virus: 0.4805, f1_Healthy_Leaf: 0.6996, f1_Herbicide_Growth_Damage: 0.8074, f1_Leaf_Hopper_Jassids: 0.4742, f1_Leaf_Redding: 0.7000, f1_Leaf_Variegation: 0.8199
2025-05-29 15:00:22 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 15:00:22 - __main__ - INFO - [main_execution_logic:479] - E20: New best! Val f1_macro: 0.6528
2025-05-29 15:00:24 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/checkpoint_epoch_20.pth
2025-05-29 15:00:24 - __main__ - INFO - [main_execution_logic:496] - Epoch 20 completed in 556.65s.
2025-05-29 15:00:24 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E20 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:02:55 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E21 OptStep 50: Grad Norm: 3.0022
2025-05-29 15:05:26 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E21 OptStep 100: Grad Norm: 4.6595
2025-05-29 15:07:57 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E21 OptStep 150: Grad Norm: 4.4888
2025-05-29 15:08:33 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 21 training finished. Avg Loss: 1.1984, Final LR: 9.95e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:09:35 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.1398, accuracy: 0.6776, f1_macro: 0.6700, f1_weighted: 0.6680, precision_macro: 0.6875, precision_weighted: 0.6910, recall_macro: 0.6844, recall_weighted: 0.6776, f1_Bacterial_Blight: 0.5990, f1_Curl_Virus: 0.5493, f1_Healthy_Leaf: 0.7078, f1_Herbicide_Growth_Damage: 0.8111, f1_Leaf_Hopper_Jassids: 0.5157, f1_Leaf_Redding: 0.6766, f1_Leaf_Variegation: 0.8305
2025-05-29 15:09:38 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 15:09:38 - __main__ - INFO - [main_execution_logic:479] - E21: New best! Val f1_macro: 0.6700
2025-05-29 15:09:38 - __main__ - INFO - [main_execution_logic:496] - Epoch 21 completed in 554.52s.
2025-05-29 15:09:38 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E21 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:12:10 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E22 OptStep 50: Grad Norm: 4.8670
2025-05-29 15:14:41 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E22 OptStep 100: Grad Norm: 5.2243
2025-05-29 15:17:12 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E22 OptStep 150: Grad Norm: 4.6022
2025-05-29 15:17:47 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 22 training finished. Avg Loss: 1.1924, Final LR: 9.93e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:18:49 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.1231, accuracy: 0.6740, f1_macro: 0.6621, f1_weighted: 0.6612, precision_macro: 0.6890, precision_weighted: 0.6934, recall_macro: 0.6815, recall_weighted: 0.6740, f1_Bacterial_Blight: 0.5859, f1_Curl_Virus: 0.5178, f1_Healthy_Leaf: 0.6914, f1_Herbicide_Growth_Damage: 0.8146, f1_Leaf_Hopper_Jassids: 0.4948, f1_Leaf_Redding: 0.7067, f1_Leaf_Variegation: 0.8235
2025-05-29 15:18:49 - __main__ - INFO - [main_execution_logic:482] - E22: Val f1_macro (0.6621) not better. Patience: 1/25
2025-05-29 15:18:49 - __main__ - INFO - [main_execution_logic:496] - Epoch 22 completed in 550.63s.
2025-05-29 15:18:49 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E22 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:21:20 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E23 OptStep 50: Grad Norm: 3.0741
2025-05-29 15:23:51 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E23 OptStep 100: Grad Norm: 4.1149
2025-05-29 15:26:22 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E23 OptStep 150: Grad Norm: 2.3563
2025-05-29 15:26:57 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 23 training finished. Avg Loss: 1.1754, Final LR: 9.91e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:27:59 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.1314, accuracy: 0.6783, f1_macro: 0.6718, f1_weighted: 0.6695, precision_macro: 0.6956, precision_weighted: 0.6980, recall_macro: 0.6843, recall_weighted: 0.6783, f1_Bacterial_Blight: 0.5877, f1_Curl_Virus: 0.4933, f1_Healthy_Leaf: 0.6892, f1_Herbicide_Growth_Damage: 0.8168, f1_Leaf_Hopper_Jassids: 0.5515, f1_Leaf_Redding: 0.7091, f1_Leaf_Variegation: 0.8547
2025-05-29 15:28:03 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 15:28:03 - __main__ - INFO - [main_execution_logic:479] - E23: New best! Val f1_macro: 0.6718
2025-05-29 15:28:03 - __main__ - INFO - [main_execution_logic:496] - Epoch 23 completed in 554.15s.
2025-05-29 15:28:03 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E23 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:30:34 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E24 OptStep 50: Grad Norm: 3.7022
2025-05-29 15:33:05 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E24 OptStep 100: Grad Norm: 2.4786
2025-05-29 15:35:36 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E24 OptStep 150: Grad Norm: 4.5021
2025-05-29 15:36:11 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 24 training finished. Avg Loss: 1.1612, Final LR: 9.89e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:37:14 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.1081, accuracy: 0.6988, f1_macro: 0.6920, f1_weighted: 0.6900, precision_macro: 0.7079, precision_weighted: 0.7122, recall_macro: 0.7056, recall_weighted: 0.6988, f1_Bacterial_Blight: 0.6138, f1_Curl_Virus: 0.5460, f1_Healthy_Leaf: 0.7189, f1_Herbicide_Growth_Damage: 0.8454, f1_Leaf_Hopper_Jassids: 0.5549, f1_Leaf_Redding: 0.7109, f1_Leaf_Variegation: 0.8539
2025-05-29 15:37:17 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 15:37:17 - __main__ - INFO - [main_execution_logic:479] - E24: New best! Val f1_macro: 0.6920
2025-05-29 15:37:17 - __main__ - INFO - [main_execution_logic:496] - Epoch 24 completed in 554.12s.
2025-05-29 15:37:17 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E24 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:39:48 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E25 OptStep 50: Grad Norm: 4.6416
2025-05-29 15:42:19 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E25 OptStep 100: Grad Norm: 3.8440
2025-05-29 15:44:50 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E25 OptStep 150: Grad Norm: 4.1767
2025-05-29 15:45:25 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 25 training finished. Avg Loss: 1.1581, Final LR: 9.87e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:46:27 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0942, accuracy: 0.6980, f1_macro: 0.6901, f1_weighted: 0.6883, precision_macro: 0.7088, precision_weighted: 0.7107, recall_macro: 0.7024, recall_weighted: 0.6980, f1_Bacterial_Blight: 0.6138, f1_Curl_Virus: 0.5421, f1_Healthy_Leaf: 0.7099, f1_Herbicide_Growth_Damage: 0.8544, f1_Leaf_Hopper_Jassids: 0.5414, f1_Leaf_Redding: 0.7172, f1_Leaf_Variegation: 0.8522
2025-05-29 15:46:27 - __main__ - INFO - [main_execution_logic:482] - E25: Val f1_macro (0.6901) not better. Patience: 1/25
2025-05-29 15:46:27 - __main__ - INFO - [main_execution_logic:496] - Epoch 25 completed in 550.30s.
2025-05-29 15:46:27 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E25 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:48:58 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E26 OptStep 50: Grad Norm: 16.6045
2025-05-29 15:51:29 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E26 OptStep 100: Grad Norm: 3.9986
2025-05-29 15:54:01 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E26 OptStep 150: Grad Norm: 3.8520
2025-05-29 15:54:36 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 26 training finished. Avg Loss: 1.1442, Final LR: 9.84e-05, Opt Steps: 161, NaN count: 0
2025-05-29 15:55:38 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0695, accuracy: 0.7024, f1_macro: 0.6978, f1_weighted: 0.6963, precision_macro: 0.7140, precision_weighted: 0.7155, recall_macro: 0.7075, recall_weighted: 0.7024, f1_Bacterial_Blight: 0.5973, f1_Curl_Virus: 0.5488, f1_Healthy_Leaf: 0.7317, f1_Herbicide_Growth_Damage: 0.8447, f1_Leaf_Hopper_Jassids: 0.5788, f1_Leaf_Redding: 0.7249, f1_Leaf_Variegation: 0.8588
2025-05-29 15:55:41 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 15:55:41 - __main__ - INFO - [main_execution_logic:479] - E26: New best! Val f1_macro: 0.6978
2025-05-29 15:55:41 - __main__ - INFO - [main_execution_logic:496] - Epoch 26 completed in 554.09s.
2025-05-29 15:55:41 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E26 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 15:58:13 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E27 OptStep 50: Grad Norm: 3.3213
2025-05-29 16:00:44 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E27 OptStep 100: Grad Norm: 4.2743
2025-05-29 16:03:15 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E27 OptStep 150: Grad Norm: 2.5264
2025-05-29 16:03:50 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 27 training finished. Avg Loss: 1.1484, Final LR: 9.81e-05, Opt Steps: 161, NaN count: 0
2025-05-29 16:04:52 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0664, accuracy: 0.7112, f1_macro: 0.7025, f1_weighted: 0.7004, precision_macro: 0.7223, precision_weighted: 0.7224, recall_macro: 0.7144, recall_weighted: 0.7112, f1_Bacterial_Blight: 0.6146, f1_Curl_Virus: 0.5263, f1_Healthy_Leaf: 0.7291, f1_Herbicide_Growth_Damage: 0.8310, f1_Leaf_Hopper_Jassids: 0.6224, f1_Leaf_Redding: 0.7323, f1_Leaf_Variegation: 0.8622
2025-05-29 16:04:55 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 16:04:55 - __main__ - INFO - [main_execution_logic:479] - E27: New best! Val f1_macro: 0.7025
2025-05-29 16:04:55 - __main__ - INFO - [main_execution_logic:496] - Epoch 27 completed in 553.95s.
2025-05-29 16:04:55 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E27 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 16:07:27 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E28 OptStep 50: Grad Norm: 3.7135
2025-05-29 16:09:58 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E28 OptStep 100: Grad Norm: 5.3658
2025-05-29 16:12:29 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E28 OptStep 150: Grad Norm: 6.5530
2025-05-29 16:13:05 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 28 training finished. Avg Loss: 1.1426, Final LR: 9.77e-05, Opt Steps: 161, NaN count: 0
2025-05-29 16:14:07 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0412, accuracy: 0.7163, f1_macro: 0.7140, f1_weighted: 0.7122, precision_macro: 0.7235, precision_weighted: 0.7252, recall_macro: 0.7210, recall_weighted: 0.7163, f1_Bacterial_Blight: 0.6216, f1_Curl_Virus: 0.5801, f1_Healthy_Leaf: 0.7346, f1_Herbicide_Growth_Damage: 0.8437, f1_Leaf_Hopper_Jassids: 0.6106, f1_Leaf_Redding: 0.7366, f1_Leaf_Variegation: 0.8709
2025-05-29 16:14:10 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 16:14:10 - __main__ - INFO - [main_execution_logic:479] - E28: New best! Val f1_macro: 0.7140
2025-05-29 16:14:10 - __main__ - INFO - [main_execution_logic:496] - Epoch 28 completed in 554.46s.
2025-05-29 16:14:10 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E28 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 16:16:41 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E29 OptStep 50: Grad Norm: 3.0449
2025-05-29 16:19:12 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E29 OptStep 100: Grad Norm: 5.5478
2025-05-29 16:21:43 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E29 OptStep 150: Grad Norm: 4.0953
2025-05-29 16:22:19 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 29 training finished. Avg Loss: 1.1312, Final LR: 9.74e-05, Opt Steps: 161, NaN count: 0
2025-05-29 16:23:20 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0565, accuracy: 0.7148, f1_macro: 0.7085, f1_weighted: 0.7067, precision_macro: 0.7356, precision_weighted: 0.7381, recall_macro: 0.7214, recall_weighted: 0.7148, f1_Bacterial_Blight: 0.6313, f1_Curl_Virus: 0.5793, f1_Healthy_Leaf: 0.7418, f1_Herbicide_Growth_Damage: 0.8341, f1_Leaf_Hopper_Jassids: 0.6021, f1_Leaf_Redding: 0.7206, f1_Leaf_Variegation: 0.8500
2025-05-29 16:23:20 - __main__ - INFO - [main_execution_logic:482] - E29: Val f1_macro (0.7085) not better. Patience: 1/25
2025-05-29 16:23:20 - __main__ - INFO - [main_execution_logic:496] - Epoch 29 completed in 550.63s.
2025-05-29 16:23:20 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E29 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 16:25:52 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E30 OptStep 50: Grad Norm: 3.1347
2025-05-29 16:28:23 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E30 OptStep 100: Grad Norm: 3.7023
2025-05-29 16:30:54 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E30 OptStep 150: Grad Norm: 5.6899
2025-05-29 16:31:29 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 30 training finished. Avg Loss: 1.1157, Final LR: 9.70e-05, Opt Steps: 161, NaN count: 0
2025-05-29 16:32:31 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0444, accuracy: 0.7228, f1_macro: 0.7176, f1_weighted: 0.7161, precision_macro: 0.7349, precision_weighted: 0.7376, recall_macro: 0.7280, recall_weighted: 0.7228, f1_Bacterial_Blight: 0.6247, f1_Curl_Virus: 0.5952, f1_Healthy_Leaf: 0.7302, f1_Herbicide_Growth_Damage: 0.8621, f1_Leaf_Hopper_Jassids: 0.6149, f1_Leaf_Redding: 0.7390, f1_Leaf_Variegation: 0.8571
2025-05-29 16:32:34 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 16:32:34 - __main__ - INFO - [main_execution_logic:479] - E30: New best! Val f1_macro: 0.7176
2025-05-29 16:32:36 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/checkpoint_epoch_30.pth
2025-05-29 16:32:36 - __main__ - INFO - [main_execution_logic:496] - Epoch 30 completed in 555.38s.
2025-05-29 16:32:36 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E30 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 16:35:07 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E31 OptStep 50: Grad Norm: 3.0664
2025-05-29 16:37:39 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E31 OptStep 100: Grad Norm: 4.7072
2025-05-29 16:40:10 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E31 OptStep 150: Grad Norm: 4.0901
2025-05-29 16:40:45 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 31 training finished. Avg Loss: 1.1058, Final LR: 9.66e-05, Opt Steps: 161, NaN count: 0
2025-05-29 16:41:47 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0323, accuracy: 0.7272, f1_macro: 0.7211, f1_weighted: 0.7185, precision_macro: 0.7426, precision_weighted: 0.7415, recall_macro: 0.7313, recall_weighted: 0.7272, f1_Bacterial_Blight: 0.6456, f1_Curl_Virus: 0.5615, f1_Healthy_Leaf: 0.7443, f1_Herbicide_Growth_Damage: 0.8482, f1_Leaf_Hopper_Jassids: 0.6250, f1_Leaf_Redding: 0.7384, f1_Leaf_Variegation: 0.8850
2025-05-29 16:41:51 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 16:41:51 - __main__ - INFO - [main_execution_logic:479] - E31: New best! Val f1_macro: 0.7211
2025-05-29 16:41:51 - __main__ - INFO - [main_execution_logic:496] - Epoch 31 completed in 554.74s.
2025-05-29 16:41:51 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E31 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 16:44:22 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E32 OptStep 50: Grad Norm: 3.1556
2025-05-29 16:46:53 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E32 OptStep 100: Grad Norm: 3.9218
2025-05-29 16:49:24 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E32 OptStep 150: Grad Norm: 3.8990
2025-05-29 16:49:59 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 32 training finished. Avg Loss: 1.1023, Final LR: 9.61e-05, Opt Steps: 161, NaN count: 0
2025-05-29 16:51:01 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0262, accuracy: 0.7192, f1_macro: 0.7152, f1_weighted: 0.7122, precision_macro: 0.7353, precision_weighted: 0.7379, recall_macro: 0.7266, recall_weighted: 0.7192, f1_Bacterial_Blight: 0.6207, f1_Curl_Virus: 0.5769, f1_Healthy_Leaf: 0.7302, f1_Herbicide_Growth_Damage: 0.8398, f1_Leaf_Hopper_Jassids: 0.6313, f1_Leaf_Redding: 0.7193, f1_Leaf_Variegation: 0.8883
2025-05-29 16:51:01 - __main__ - INFO - [main_execution_logic:482] - E32: Val f1_macro (0.7152) not better. Patience: 1/25
2025-05-29 16:51:01 - __main__ - INFO - [main_execution_logic:496] - Epoch 32 completed in 550.13s.
2025-05-29 16:51:01 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E32 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 16:53:32 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E33 OptStep 50: Grad Norm: 3.8740
2025-05-29 16:56:04 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E33 OptStep 100: Grad Norm: 3.7238
2025-05-29 16:58:35 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E33 OptStep 150: Grad Norm: 3.7673
2025-05-29 16:59:10 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 33 training finished. Avg Loss: 1.1021, Final LR: 9.57e-05, Opt Steps: 161, NaN count: 0
2025-05-29 17:00:12 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0156, accuracy: 0.7352, f1_macro: 0.7290, f1_weighted: 0.7261, precision_macro: 0.7469, precision_weighted: 0.7493, recall_macro: 0.7426, recall_weighted: 0.7352, f1_Bacterial_Blight: 0.6600, f1_Curl_Virus: 0.5732, f1_Healthy_Leaf: 0.7598, f1_Herbicide_Growth_Damage: 0.8469, f1_Leaf_Hopper_Jassids: 0.6463, f1_Leaf_Redding: 0.7323, f1_Leaf_Variegation: 0.8845
2025-05-29 17:00:15 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 17:00:15 - __main__ - INFO - [main_execution_logic:479] - E33: New best! Val f1_macro: 0.7290
2025-05-29 17:00:15 - __main__ - INFO - [main_execution_logic:496] - Epoch 33 completed in 554.79s.
2025-05-29 17:00:15 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E33 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 17:02:47 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E34 OptStep 50: Grad Norm: 3.7894
2025-05-29 17:05:18 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E34 OptStep 100: Grad Norm: 5.3888
2025-05-29 17:07:50 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E34 OptStep 150: Grad Norm: 3.3899
2025-05-29 17:08:25 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 34 training finished. Avg Loss: 1.0861, Final LR: 9.52e-05, Opt Steps: 161, NaN count: 0
2025-05-29 17:09:27 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 1.0047, accuracy: 0.7345, f1_macro: 0.7317, f1_weighted: 0.7298, precision_macro: 0.7466, precision_weighted: 0.7507, recall_macro: 0.7414, recall_weighted: 0.7345, f1_Bacterial_Blight: 0.6455, f1_Curl_Virus: 0.6182, f1_Healthy_Leaf: 0.7490, f1_Herbicide_Growth_Damage: 0.8450, f1_Leaf_Hopper_Jassids: 0.6372, f1_Leaf_Redding: 0.7465, f1_Leaf_Variegation: 0.8807
2025-05-29 17:09:31 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 17:09:31 - __main__ - INFO - [main_execution_logic:479] - E34: New best! Val f1_macro: 0.7317
2025-05-29 17:09:31 - __main__ - INFO - [main_execution_logic:496] - Epoch 34 completed in 555.20s.
2025-05-29 17:09:31 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E34 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 17:12:02 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E35 OptStep 50: Grad Norm: 3.7686
2025-05-29 17:14:33 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E35 OptStep 100: Grad Norm: 4.8886
2025-05-29 17:17:05 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E35 OptStep 150: Grad Norm: 3.6706
2025-05-29 17:17:40 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 35 training finished. Avg Loss: 1.0738, Final LR: 9.47e-05, Opt Steps: 161, NaN count: 0
2025-05-29 17:18:42 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 0.9892, accuracy: 0.7367, f1_macro: 0.7329, f1_weighted: 0.7310, precision_macro: 0.7425, precision_weighted: 0.7435, recall_macro: 0.7411, recall_weighted: 0.7367, f1_Bacterial_Blight: 0.6260, f1_Curl_Virus: 0.6084, f1_Healthy_Leaf: 0.7443, f1_Herbicide_Growth_Damage: 0.8529, f1_Leaf_Hopper_Jassids: 0.6627, f1_Leaf_Redding: 0.7511, f1_Leaf_Variegation: 0.8851
2025-05-29 17:18:46 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:229] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_optimized_strategy_v1_stable/checkpoints_optimized_strategy_v1_stable/best_finetuned_hvt_optimized_strategy_v1_stable.pth
2025-05-29 17:18:46 - __main__ - INFO - [main_execution_logic:479] - E35: New best! Val f1_macro: 0.7329
2025-05-29 17:18:46 - __main__ - INFO - [main_execution_logic:496] - Epoch 35 completed in 554.88s.
2025-05-29 17:18:46 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E35 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 17:21:17 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E36 OptStep 50: Grad Norm: 5.4406
2025-05-29 17:23:48 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E36 OptStep 100: Grad Norm: 4.2350
2025-05-29 17:26:19 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E36 OptStep 150: Grad Norm: 3.6767
2025-05-29 17:26:55 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 36 training finished. Avg Loss: 1.0694, Final LR: 9.41e-05, Opt Steps: 161, NaN count: 0
2025-05-29 17:27:57 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:222] - Validation finished. Avg Loss: 0.9998, accuracy: 0.7309, f1_macro: 0.7238, f1_weighted: 0.7218, precision_macro: 0.7453, precision_weighted: 0.7476, recall_macro: 0.7364, recall_weighted: 0.7309, f1_Bacterial_Blight: 0.6390, f1_Curl_Virus: 0.5916, f1_Healthy_Leaf: 0.7480, f1_Herbicide_Growth_Damage: 0.8482, f1_Leaf_Hopper_Jassids: 0.6355, f1_Leaf_Redding: 0.7366, f1_Leaf_Variegation: 0.8674
2025-05-29 17:27:57 - __main__ - INFO - [main_execution_logic:482] - E36: Val f1_macro (0.7238) not better. Patience: 1/25
2025-05-29 17:27:57 - __main__ - INFO - [main_execution_logic:496] - Epoch 36 completed in 551.00s.
2025-05-29 17:27:57 - __main__ - DEBUG - [main_execution_logic:497] - CUDA Mem E36 End: Alloc 4221.1MB, Reserved 6092.0MB
2025-05-29 17:30:28 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E37 OptStep 50: Grad Norm: 3.9243
2025-05-29 17:32:59 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E37 OptStep 100: Grad Norm: 3.4484
2025-05-29 17:35:30 - phase4_finetuning.finetune.trainer - DEBUG - [train_one_epoch:128] - E37 OptStep 150: Grad Norm: 5.2088
2025-05-29 17:36:05 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:154] - Epoch 37 training finished. Avg Loss: 1.0851, Final LR: 9.36e-05, Opt Steps: 161, NaN count: 0
