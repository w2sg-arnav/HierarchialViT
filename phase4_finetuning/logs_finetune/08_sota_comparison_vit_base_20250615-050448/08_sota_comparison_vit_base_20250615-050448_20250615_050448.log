2025-06-15 05:04:48 - root - INFO - [setup_logging:75] - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/08_sota_comparison_vit_base_20250615-050448_20250615_050448.log. Logger 'root' Effective Level: INFO
2025-06-15 05:04:48 - __main__ - INFO - [run:38] - Starting fine-tuning run: 08_sota_comparison_vit_base_20250615-050448
2025-06-15 05:04:48 - __main__ - INFO - [run:39] - Full configuration:
PACKAGE_ROOT_PATH: /teamspace/studios/this_studio/cvpr25/phase4_finetuning
PROJECT_ROOT_PATH: /teamspace/studios/this_studio/cvpr25
augmentations:
  cutmix_prob: 0.2
  mixup_alpha: 0.2
  severity: strong
  strategy: cotton_disease
cudnn_benchmark: true
data:
  augmented_dataset_name: Augmented Dataset
  img_size:
  - 448
  - 448
  num_workers: 4
  original_dataset_name: Original Dataset
  root_dir: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset
    for Cotton Leaf Disease Detection
  train_split_ratio: 0.9
  use_weighted_sampler: true
device: cuda
evaluation:
  early_stopping:
    metric: f1_macro
    min_delta: 0.001
    patience: 20
  ema_decay: 0.9999
  tta_enabled: true
  use_ema: true
model:
  hvt_params:
    depths:
    - 3
    - 6
    - 24
    - 3
    drop_path_rate: 0.2
    embed_dim_rgb: 192
    enable_consistency_loss_heads: false
    mlp_ratio: 4.0
    model_drop_rate: 0.1
    norm_layer_name: LayerNorm
    num_heads:
    - 6
    - 12
    - 24
    - 48
    patch_size: 14
    qkv_bias: true
    spectral_channels: 0
    use_dfca: false
    use_gradient_checkpointing: true
  resume_finetune_path: null
  ssl_pretrained_path: null
model_override:
  name: vit_base_patch16_224.augreg_in21k_ft_in1k
  type: timm
run_name_prefix: 08_sota_comparison_vit_base
seed: 42
torch_compile:
  enable: false
  mode: reduce-overhead
training:
  accumulation_steps: 2
  amp_enabled: true
  batch_size: 16
  clip_grad_norm: 1.0
  epochs: 100
  freeze_backbone_epochs: 10
  loss:
    focal_alpha: 0.5
    focal_gamma: 2.0
    label_smoothing: 0.1
    type: CombinedLoss
    use_class_weights: true
    weights:
      ce: 0.5
      focal: 0.5
  optimizer:
    lr_backbone_unfrozen: 2.0e-05
    lr_head_unfrozen: 0.0002
  scheduler:
    div_factor: 10
    final_div_factor: 1000
    name: onecyclelr
    pct_start: 0.1

2025-06-15 05:04:49 - __main__ - INFO - [run:50] - Setting up datasets and dataloaders...
2025-06-15 05:04:49 - phase4_finetuning.utils.augmentations - INFO - [create_cotton_leaf_augmentation:148] - Creating augmentation strategy: 'cotton_disease' for image size (448, 448)
2025-06-15 05:04:49 - phase4_finetuning.utils.augmentations - INFO - [__init__:134] - CottonLeafDiseaseAugmentation initialized with severity 'strong'.
2025-06-15 05:04:49 - phase4_finetuning.utils.augmentations - INFO - [create_cotton_leaf_augmentation:148] - Creating augmentation strategy: 'minimal' for image size (448, 448)
2025-06-15 05:04:49 - phase4_finetuning.dataset - INFO - [__init__:37] - Initializing Dataset for split 'train'...
2025-06-15 05:04:50 - phase4_finetuning.dataset - INFO - [__init__:53] - Found 9137 total image paths.
2025-06-15 05:04:50 - phase4_finetuning.dataset - INFO - [__init__:64] - Split 'train' size: 8223 samples.
2025-06-15 05:04:50 - phase4_finetuning.dataset - INFO - [__init__:37] - Initializing Dataset for split 'val'...
2025-06-15 05:04:50 - phase4_finetuning.dataset - INFO - [__init__:53] - Found 9137 total image paths.
2025-06-15 05:04:50 - phase4_finetuning.dataset - INFO - [__init__:64] - Split 'val' size: 914 samples.
2025-06-15 05:04:50 - __main__ - INFO - [run:87] - Discovered 7 classes.
2025-06-15 05:04:50 - __main__ - INFO - [run:97] - Using WeightedRandomSampler for training.
2025-06-15 05:04:50 - __main__ - INFO - [run:110] - --- MODEL OVERRIDE IN EFFECT ---
2025-06-15 05:04:50 - __main__ - INFO - [run:111] - Loading baseline model -> Type: timm, Name: vit_base_patch16_224.augreg_in21k_ft_in1k
2025-06-15 05:04:53 - timm.models._builder - INFO - [load_pretrained:204] - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k_ft_in1k)
2025-06-15 05:04:53 - timm.models._hub - INFO - [load_state_dict_from_hf:217] - [timm/vit_base_patch16_224.augreg_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-06-15 05:04:53 - timm.layers.pos_embed - INFO - [resample_abs_pos_embed:55] - Resized position embedding: (14, 14) to (28, 28).
2025-06-15 05:04:53 - timm.models._builder - INFO - [load_pretrained:262] - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
2025-06-15 05:04:53 - __main__ - INFO - [run:138] - Initializing EnhancedFinetuner...
2025-06-15 05:04:53 - phase4_finetuning.utils.ema - INFO - [_create_shadow_copy:49] - Creating EMA shadow model by re-instantiating timm model.
2025-06-15 05:04:53 - phase4_finetuning.utils.ema - INFO - [_create_shadow_copy:64] - Explicitly passing img_size=(448, 448) to timm.create_model for shadow copy.
2025-06-15 05:04:56 - phase4_finetuning.utils.ema - INFO - [__init__:26] - EMA helper initialized with decay=0.9999. Shadow model created.
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [_get_param_groups:304] - Optimizer parameter groups: Head (56,674,567 params) with LR 2.00e-04, Backbone (29,581,056 params) with LR 2.00e-05
2025-06-15 05:04:56 - phase4_finetuning.dataset - INFO - [get_class_weights:96] - Computed class weights for split 'train': [1.04  0.897 1.049 1.03  1.069 0.834 1.156]
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [_create_criterion:344] - Using class weights in loss function.
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [__init__:59] - Trainer initialized. Model has 86,255,623 trainable parameters.
2025-06-15 05:04:56 - __main__ - INFO - [run:149] - Starting the training and validation loop...
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [run:63] - Starting fine-tuning run. Monitoring 'f1_macro' for best model.
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 1/100 ---
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [_set_parameter_groups_for_epoch:335] - Epoch 1: Setting backbone requires_grad to False
2025-06-15 05:04:56 - phase4_finetuning.finetune.trainer - INFO - [_set_parameter_groups_for_epoch:338] - Trainable params updated: 56,674,567
2025-06-15 05:09:30 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 1: Loss=1.9633, Accuracy=0.1411, F1-Macro=0.1076
2025-06-15 05:09:30 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 1: New best metric! f1_macro = 0.1076 (previously -1.0000)
2025-06-15 05:09:30 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:09:32 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 2/100 ---
2025-06-15 05:14:01 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 2: Loss=1.9499, Accuracy=0.1608, F1-Macro=0.1270
2025-06-15 05:14:01 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 2: New best metric! f1_macro = 0.1270 (previously 0.1076)
2025-06-15 05:14:01 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:14:05 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 3/100 ---
2025-06-15 05:18:34 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 3: Loss=1.9324, Accuracy=0.1860, F1-Macro=0.1491
2025-06-15 05:18:34 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 3: New best metric! f1_macro = 0.1491 (previously 0.1270)
2025-06-15 05:18:34 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:18:38 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 4/100 ---
2025-06-15 05:23:08 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 4: Loss=1.9100, Accuracy=0.2309, F1-Macro=0.2024
2025-06-15 05:23:08 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 4: New best metric! f1_macro = 0.2024 (previously 0.1491)
2025-06-15 05:23:08 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:23:11 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 5/100 ---
2025-06-15 05:27:40 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 5: Loss=1.8815, Accuracy=0.2812, F1-Macro=0.2541
2025-06-15 05:27:40 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 5: New best metric! f1_macro = 0.2541 (previously 0.2024)
2025-06-15 05:27:40 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:27:43 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 6/100 ---
2025-06-15 05:32:12 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 6: Loss=1.8448, Accuracy=0.3479, F1-Macro=0.3181
2025-06-15 05:32:12 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 6: New best metric! f1_macro = 0.3181 (previously 0.2541)
2025-06-15 05:32:12 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:32:16 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 7/100 ---
2025-06-15 05:36:44 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 7: Loss=1.8011, Accuracy=0.4398, F1-Macro=0.4022
2025-06-15 05:36:44 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 7: New best metric! f1_macro = 0.4022 (previously 0.3181)
2025-06-15 05:36:44 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:36:47 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 8/100 ---
2025-06-15 05:41:15 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 8: Loss=1.7512, Accuracy=0.5263, F1-Macro=0.4792
2025-06-15 05:41:15 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 8: New best metric! f1_macro = 0.4792 (previously 0.4022)
2025-06-15 05:41:15 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:41:19 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 9/100 ---
2025-06-15 05:45:47 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 9: Loss=1.6972, Accuracy=0.6149, F1-Macro=0.5681
2025-06-15 05:45:47 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 9: New best metric! f1_macro = 0.5681 (previously 0.4792)
2025-06-15 05:45:47 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:45:50 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 10/100 ---
2025-06-15 05:50:19 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 10: Loss=1.6438, Accuracy=0.6926, F1-Macro=0.6560
2025-06-15 05:50:19 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 10: New best metric! f1_macro = 0.6560 (previously 0.5681)
2025-06-15 05:50:19 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:50:22 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:394] - Saving periodic checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/checkpoint_epoch_10.pth
2025-06-15 05:50:24 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 11/100 ---
2025-06-15 05:50:24 - phase4_finetuning.finetune.trainer - INFO - [_set_parameter_groups_for_epoch:335] - Epoch 11: Setting backbone requires_grad to True
2025-06-15 05:50:24 - phase4_finetuning.finetune.trainer - INFO - [_set_parameter_groups_for_epoch:338] - Trainable params updated: 86,255,623
2025-06-15 05:55:28 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 11: Loss=1.5934, Accuracy=0.7527, F1-Macro=0.7251
2025-06-15 05:55:28 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 11: New best metric! f1_macro = 0.7251 (previously 0.6560)
2025-06-15 05:55:28 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 05:55:33 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 12/100 ---
2025-06-15 06:00:37 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 12: Loss=1.5466, Accuracy=0.7954, F1-Macro=0.7768
2025-06-15 06:00:37 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 12: New best metric! f1_macro = 0.7768 (previously 0.7251)
2025-06-15 06:00:37 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 06:00:42 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 13/100 ---
2025-06-15 06:05:46 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 13: Loss=1.5049, Accuracy=0.8425, F1-Macro=0.8316
2025-06-15 06:05:46 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 13: New best metric! f1_macro = 0.8316 (previously 0.7768)
2025-06-15 06:05:46 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 06:05:51 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 14/100 ---
2025-06-15 06:10:55 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 14: Loss=1.4670, Accuracy=0.8764, F1-Macro=0.8709
2025-06-15 06:10:55 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 14: New best metric! f1_macro = 0.8709 (previously 0.8316)
2025-06-15 06:10:55 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 06:11:00 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 15/100 ---
2025-06-15 06:16:03 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 15: Loss=1.4335, Accuracy=0.9147, F1-Macro=0.9130
2025-06-15 06:16:03 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 15: New best metric! f1_macro = 0.9130 (previously 0.8709)
2025-06-15 06:16:03 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 06:16:08 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 16/100 ---
2025-06-15 06:21:12 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 16: Loss=1.4040, Accuracy=0.9409, F1-Macro=0.9404
2025-06-15 06:21:12 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 16: New best metric! f1_macro = 0.9404 (previously 0.9130)
2025-06-15 06:21:12 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 06:21:17 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 17/100 ---
2025-06-15 06:26:20 - phase4_finetuning.finetune.trainer - INFO - [_validate_one_epoch:187] - Validation Epoch 17: Loss=1.3787, Accuracy=0.9519, F1-Macro=0.9518
2025-06-15 06:26:20 - phase4_finetuning.finetune.trainer - INFO - [run:83] - Epoch 17: New best metric! f1_macro = 0.9518 (previously 0.9404)
2025-06-15 06:26:20 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:388] - Saving best model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/best_model.pth
2025-06-15 06:26:25 - phase4_finetuning.finetune.trainer - INFO - [run:72] - --- Starting Epoch 18/100 ---
2025-06-15 06:28:11 - phase4_finetuning.finetune.trainer - WARNING - [run:99] - Training interrupted by user.
2025-06-15 06:28:11 - phase4_finetuning.finetune.trainer - INFO - [run:105] - Training finished. Saving final model state.
2025-06-15 06:28:11 - phase4_finetuning.finetune.trainer - INFO - [_save_checkpoint:391] - Saving final model checkpoint to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune/08_sota_comparison_vit_base_20250615-050448/checkpoints/checkpoint_epoch_18_final.pth
2025-06-15 06:28:12 - __main__ - INFO - [run:151] - Fine-tuning run '08_sota_comparison_vit_base_20250615-050448' finished successfully.
