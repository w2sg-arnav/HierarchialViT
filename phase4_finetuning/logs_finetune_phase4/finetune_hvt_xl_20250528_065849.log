2025-05-28 06:58:49 - root - INFO - [setup_logging:75] - Logging configured. Log file: /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_phase4/finetune_hvt_xl_20250528_065849.log. Logger 'root' Effective Level: DEBUG
2025-05-28 06:58:49 - __main__ - INFO - [main_execution_logic:191] - ======== Starting Phase 4: HVT Fine-tuning (Run ID: 20250528_065849) ========
2025-05-28 06:58:49 - __main__ - INFO - [main_execution_logic:192] - Full run configuration: {'seed': 42, 'device': 'cuda', 'log_dir': 'logs_finetune_phase4', 'log_file_finetune': 'finetune_hvt_xl.log', 'best_model_filename': 'best_finetuned_hvt_xl.pth', 'final_model_filename': 'final_finetuned_hvt_xl.pth', 'checkpoint_save_dir_name': 'checkpoints', 'data_root': '/teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection', 'original_dataset_name': 'Original Dataset', 'augmented_dataset_name': 'Augmented Dataset', 'img_size': (448, 448), 'num_classes': 7, 'train_split_ratio': 0.8, 'normalize_data': True, 'use_weighted_sampler': True, 'num_workers': 4, 'prefetch_factor': 2, 'model_architecture_name': 'DiseaseAwareHVT_SSL_Finetuned', 'pretrained_checkpoint_path': '/teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth', 'load_pretrained_backbone': True, 'freeze_backbone_epochs': 0, 'unfreeze_backbone_lr_factor': 0.1, 'hvt_params_for_model_init': {'patch_size': 14, 'embed_dim_rgb': 192, 'embed_dim_spectral': 192, 'spectral_channels': 0, 'depths': [3, 6, 24, 3], 'num_heads': [6, 12, 24, 48], 'mlp_ratio': 4.0, 'qkv_bias': True, 'model_drop_rate': 0.1, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.1, 'norm_layer_name': 'LayerNorm', 'use_dfca': False, 'use_gradient_checkpointing': False, 'ssl_enable_mae': False, 'ssl_enable_contrastive': False, 'enable_consistency_loss_heads': False, 'dfca_embed_dim_match_rgb': True, 'dfca_num_heads': 32, 'dfca_drop_rate': 0.1, 'dfca_use_disease_mask': True, 'ssl_mae_mask_ratio': 0.75, 'ssl_mae_decoder_dim': 64, 'ssl_mae_norm_pix_loss': True, 'ssl_contrastive_projector_dim': 128, 'ssl_contrastive_projector_depth': 2}, 'enable_torch_compile': False, 'torch_compile_mode': 'reduce-overhead', 'matmul_precision': 'high', 'cudnn_benchmark': True, 'epochs': 30, 'batch_size': 16, 'accumulation_steps': 2, 'amp_enabled': True, 'clip_grad_norm': 1.0, 'log_interval': 10, 'optimizer': 'AdamW', 'learning_rate': 3e-05, 'head_lr_multiplier': 1.0, 'weight_decay': 0.05, 'optimizer_params': {'betas': (0.9, 0.999)}, 'scheduler': 'WarmupCosine', 'warmup_epochs': 3, 'eta_min_lr': 1e-07, 'loss_label_smoothing': 0.1, 'augmentations_enabled': True, 'evaluate_every_n_epochs': 1, 'early_stopping_patience': 10, 'metric_to_monitor_early_stopping': 'f1_macro'}
2025-05-28 06:58:49 - __main__ - INFO - [set_global_seed:85] - Global random seed set to: 42
2025-05-28 06:58:49 - __main__ - INFO - [main_execution_logic:196] - Using device: cuda
2025-05-28 06:58:49 - __main__ - INFO - [main_execution_logic:197] - GPU: Tesla T4; CUDA Ver: 12.1
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:54] - [DATASET INIT - train] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448)
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - train] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:98] - [DATASET INIT - train] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:111] - [DATASET INIT - train] Dataset split size: 7309 samples.
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:123] - [DATASET INIT - train] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=False)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
)
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:54] - [DATASET INIT - val] Root: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection, ImgSize: (448, 448)
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Original Dataset
2025-05-28 06:58:49 - phase4_finetuning.dataset - INFO - [__init__:67] - [DATASET INIT - val] Scanning: /teamspace/studios/this_studio/cvpr25/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Augmented Dataset
2025-05-28 06:58:50 - phase4_finetuning.dataset - INFO - [__init__:98] - [DATASET INIT - val] Total valid image paths collected: 9137 from ~9137 items considered.
2025-05-28 06:58:50 - phase4_finetuning.dataset - INFO - [__init__:111] - [DATASET INIT - val] Dataset split size: 1828 samples.
2025-05-28 06:58:50 - phase4_finetuning.dataset - INFO - [__init__:123] - [DATASET INIT - val] Base RGB Transforms: Compose(
      ToImage()
      ToDtype(scale=False)
      Resize(size=[448, 448], interpolation=InterpolationMode.BICUBIC, antialias=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
)
2025-05-28 06:58:50 - phase4_finetuning.dataset - INFO - [get_class_weights:180] - Computed class weights for split 'train': [1.029 0.912 1.065 1.014 1.05  0.833 1.172]
2025-05-28 06:58:50 - __main__ - INFO - [main_execution_logic:214] - Using WeightedRandomSampler for training.
2025-05-28 06:58:50 - __main__ - INFO - [main_execution_logic:220] - Dataloaders created. Train batches: 456, Val batches: 115
2025-05-28 06:58:50 - phase2_model.models.hvt - INFO - [create_disease_aware_hvt:602] - Factory: Creating DiseaseAwareHVT for img_size: (448, 448), num_classes: 7
2025-05-28 06:58:52 - phase2_model.models.hvt - INFO - [__init__:325] - HVT: Running RGB stream only. No fusion.
2025-05-28 06:58:55 - phase2_model.models.hvt - INFO - [__init__:359] - DiseaseAwareHVT initialized for image size (448, 448) and 7 classes.
2025-05-28 06:58:55 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:130] - Loading SSL backbone weights from: /teamspace/studios/this_studio/cvpr25/phase3_pretraining/pretrain_checkpoints_hvt_xl/hvt_xl_simclr_t4_resumed_best_probe.pth
2025-05-28 06:58:57 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:140] - SSL and Finetune img_size match: (448, 448). No PE interpolation if patch counts same.
2025-05-28 06:58:58 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:158] - SSL Backbone weights loaded: 450 direct, 0 PE interp, 2 head skipped.
2025-05-28 06:58:58 - __main__.load_and_prepare_hvt_model - WARNING - [load_and_prepare_hvt_model:159] - Missing keys in backbone load: ['classifier_head.weight', 'classifier_head.bias']
2025-05-28 06:58:58 - __main__.load_and_prepare_hvt_model - INFO - [load_and_prepare_hvt_model:165] - Re-initialized HVT classifier_head for 7 classes (in_features=1536).
2025-05-28 06:58:59 - __main__ - INFO - [main_execution_logic:226] - Model ready. Total params: 273,615,751, Trainable params: 273,615,751
2025-05-28 06:58:59 - phase4_finetuning.utils.augmentations - INFO - [__init__:24] - FinetuneAugmentation initialized.
2025-05-28 06:58:59 - __main__ - INFO - [main_execution_logic:261] - Optimizer setup: Training all specified parameters. Head LR: 3.00e-05, Backbone LR: 3.00e-05.
2025-05-28 06:58:59 - __main__ - INFO - [main_execution_logic:269] - Optimizer: AdamW.
2025-05-28 06:58:59 - __main__ - INFO - [main_execution_logic:285] - Scheduler: WarmupCosine (per-step). WU Steps: 684, Total Steps: 6840
2025-05-28 06:58:59 - phase4_finetuning.finetune.trainer - INFO - [__init__:44] - Finetuner initialized: device=cuda, accum_steps=2, lr_sched_on_batch=True, AMP=True
2025-05-28 06:58:59 - phase4_finetuning.finetune.trainer - INFO - [__init__:46] - Using augmentations: FinetuneAugmentation
2025-05-28 06:58:59 - __main__ - INFO - [main_execution_logic:310] - Starting fine-tuning: 30 epochs. Monitor: 'f1_macro', Patience: 10.
2025-05-28 07:01:53 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 1 training finished. Avg Loss: 1.9845, Final LR for epoch: 1.00e-05, Opt Steps: 228
2025-05-28 07:02:11 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9814, accuracy: 0.1094, f1_macro: 0.0556, f1_weighted: 0.0549, precision_macro: 0.0780, precision_weighted: 0.0803, recall_macro: 0.1157, recall_weighted: 0.1094, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.1242, f1_Healthy_Leaf: 0.0769, f1_Herbicide_Growth_Damage: 0.0000, f1_Leaf_Hopper_Jassids: 0.1884, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 07:02:13 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:173] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_phase4/checkpoints/best_finetuned_hvt_xl.pth
2025-05-28 07:02:13 - __main__ - INFO - [main_execution_logic:355] - E1: New best! Val f1_macro: 0.0556
2025-05-28 07:02:13 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E1 End: Alloc 3162.6MB
2025-05-28 07:05:07 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 2 training finished. Avg Loss: 1.9347, Final LR for epoch: 2.00e-05, Opt Steps: 228
2025-05-28 07:05:25 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9995, accuracy: 0.1575, f1_macro: 0.0411, f1_weighted: 0.0447, precision_macro: 0.1653, precision_weighted: 0.1614, recall_macro: 0.1440, recall_weighted: 0.1575, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.2719, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0159, f1_Leaf_Hopper_Jassids: 0.0000, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 07:05:25 - __main__ - INFO - [main_execution_logic:357] - E2: Val f1_macro (0.0411) not better than 0.0556. Patience: 1/10
2025-05-28 07:05:25 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E2 End: Alloc 3162.6MB
2025-05-28 07:08:19 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 3 training finished. Avg Loss: 1.9122, Final LR for epoch: 3.00e-05, Opt Steps: 228
2025-05-28 07:08:37 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9333, accuracy: 0.2172, f1_macro: 0.1130, f1_weighted: 0.1138, precision_macro: 0.2203, precision_weighted: 0.2242, recall_macro: 0.2121, recall_weighted: 0.2172, f1_Bacterial_Blight: 0.0000, f1_Curl_Virus: 0.3009, f1_Healthy_Leaf: 0.0353, f1_Herbicide_Growth_Damage: 0.3743, f1_Leaf_Hopper_Jassids: 0.0806, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 07:08:41 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:173] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_phase4/checkpoints/best_finetuned_hvt_xl.pth
2025-05-28 07:08:41 - __main__ - INFO - [main_execution_logic:355] - E3: New best! Val f1_macro: 0.1130
2025-05-28 07:08:41 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E3 End: Alloc 3162.6MB
2025-05-28 07:11:35 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 4 training finished. Avg Loss: 1.8881, Final LR for epoch: 2.99e-05, Opt Steps: 228
2025-05-28 07:11:52 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9938, accuracy: 0.1679, f1_macro: 0.0902, f1_weighted: 0.0923, precision_macro: 0.3139, precision_weighted: 0.2911, recall_macro: 0.1658, recall_weighted: 0.1679, f1_Bacterial_Blight: 0.0726, f1_Curl_Virus: 0.3228, f1_Healthy_Leaf: 0.0137, f1_Herbicide_Growth_Damage: 0.2139, f1_Leaf_Hopper_Jassids: 0.0086, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 07:11:52 - __main__ - INFO - [main_execution_logic:357] - E4: Val f1_macro (0.0902) not better than 0.1130. Patience: 1/10
2025-05-28 07:11:52 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E4 End: Alloc 3162.6MB
2025-05-28 07:14:46 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 5 training finished. Avg Loss: 1.8781, Final LR for epoch: 2.96e-05, Opt Steps: 228
2025-05-28 07:15:04 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9834, accuracy: 0.1767, f1_macro: 0.0929, f1_weighted: 0.0979, precision_macro: 0.2500, precision_weighted: 0.2636, recall_macro: 0.1638, recall_weighted: 0.1767, f1_Bacterial_Blight: 0.0784, f1_Curl_Virus: 0.2870, f1_Healthy_Leaf: 0.0900, f1_Herbicide_Growth_Damage: 0.1111, f1_Leaf_Hopper_Jassids: 0.0147, f1_Leaf_Redding: 0.0688, f1_Leaf_Variegation: 0.0000
2025-05-28 07:15:04 - __main__ - INFO - [main_execution_logic:357] - E5: Val f1_macro (0.0929) not better than 0.1130. Patience: 2/10
2025-05-28 07:15:04 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E5 End: Alloc 3162.6MB
2025-05-28 07:17:58 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 6 training finished. Avg Loss: 1.8667, Final LR for epoch: 2.91e-05, Opt Steps: 228
2025-05-28 07:18:15 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 2.0497, accuracy: 0.1794, f1_macro: 0.0963, f1_weighted: 0.0949, precision_macro: 0.1241, precision_weighted: 0.1178, recall_macro: 0.1711, recall_weighted: 0.1794, f1_Bacterial_Blight: 0.2202, f1_Curl_Virus: 0.2897, f1_Healthy_Leaf: 0.0000, f1_Herbicide_Growth_Damage: 0.0490, f1_Leaf_Hopper_Jassids: 0.1150, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 07:18:15 - __main__ - INFO - [main_execution_logic:357] - E6: Val f1_macro (0.0963) not better than 0.1130. Patience: 3/10
2025-05-28 07:18:15 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E6 End: Alloc 3162.6MB
2025-05-28 07:21:09 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 7 training finished. Avg Loss: 1.8584, Final LR for epoch: 2.84e-05, Opt Steps: 228
2025-05-28 07:21:26 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.8990, accuracy: 0.2243, f1_macro: 0.1588, f1_weighted: 0.1582, precision_macro: 0.2596, precision_weighted: 0.2722, recall_macro: 0.2257, recall_weighted: 0.2243, f1_Bacterial_Blight: 0.2560, f1_Curl_Virus: 0.3071, f1_Healthy_Leaf: 0.0958, f1_Herbicide_Growth_Damage: 0.3333, f1_Leaf_Hopper_Jassids: 0.0559, f1_Leaf_Redding: 0.0414, f1_Leaf_Variegation: 0.0222
2025-05-28 07:21:29 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:173] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_phase4/checkpoints/best_finetuned_hvt_xl.pth
2025-05-28 07:21:29 - __main__ - INFO - [main_execution_logic:355] - E7: New best! Val f1_macro: 0.1588
2025-05-28 07:21:29 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E7 End: Alloc 3162.6MB
2025-05-28 07:24:23 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 8 training finished. Avg Loss: 1.8507, Final LR for epoch: 2.75e-05, Opt Steps: 228
2025-05-28 07:24:40 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9961, accuracy: 0.2139, f1_macro: 0.1365, f1_weighted: 0.1349, precision_macro: 0.2177, precision_weighted: 0.2139, recall_macro: 0.2089, recall_weighted: 0.2139, f1_Bacterial_Blight: 0.1111, f1_Curl_Virus: 0.3023, f1_Healthy_Leaf: 0.0347, f1_Herbicide_Growth_Damage: 0.3810, f1_Leaf_Hopper_Jassids: 0.1265, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0000
2025-05-28 07:24:40 - __main__ - INFO - [main_execution_logic:357] - E8: Val f1_macro (0.1365) not better than 0.1588. Patience: 1/10
2025-05-28 07:24:40 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E8 End: Alloc 3162.6MB
2025-05-28 07:27:34 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 9 training finished. Avg Loss: 1.8417, Final LR for epoch: 2.65e-05, Opt Steps: 228
2025-05-28 07:27:51 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.8373, accuracy: 0.2921, f1_macro: 0.2214, f1_weighted: 0.2375, precision_macro: 0.2472, precision_weighted: 0.2599, recall_macro: 0.2758, recall_weighted: 0.2921, f1_Bacterial_Blight: 0.0084, f1_Curl_Virus: 0.3145, f1_Healthy_Leaf: 0.2375, f1_Herbicide_Growth_Damage: 0.4838, f1_Leaf_Hopper_Jassids: 0.0739, f1_Leaf_Redding: 0.4168, f1_Leaf_Variegation: 0.0152
2025-05-28 07:27:55 - phase4_finetuning.finetune.trainer - INFO - [save_model_checkpoint:173] - Model checkpoint saved to /teamspace/studios/this_studio/cvpr25/phase4_finetuning/logs_finetune_phase4/checkpoints/best_finetuned_hvt_xl.pth
2025-05-28 07:27:55 - __main__ - INFO - [main_execution_logic:355] - E9: New best! Val f1_macro: 0.2214
2025-05-28 07:27:55 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E9 End: Alloc 3162.6MB
2025-05-28 07:30:48 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 10 training finished. Avg Loss: 1.8387, Final LR for epoch: 2.53e-05, Opt Steps: 228
2025-05-28 07:31:07 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9042, accuracy: 0.2626, f1_macro: 0.2203, f1_weighted: 0.2163, precision_macro: 0.2380, precision_weighted: 0.2314, recall_macro: 0.2682, recall_weighted: 0.2626, f1_Bacterial_Blight: 0.3182, f1_Curl_Virus: 0.3369, f1_Healthy_Leaf: 0.2573, f1_Herbicide_Growth_Damage: 0.4467, f1_Leaf_Hopper_Jassids: 0.0162, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.1671
2025-05-28 07:31:07 - __main__ - INFO - [main_execution_logic:357] - E10: Val f1_macro (0.2203) not better than 0.2214. Patience: 1/10
2025-05-28 07:31:07 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E10 End: Alloc 3162.6MB
2025-05-28 07:34:00 - phase4_finetuning.finetune.trainer - INFO - [train_one_epoch:115] - Epoch 11 training finished. Avg Loss: 1.8314, Final LR for epoch: 2.40e-05, Opt Steps: 228
2025-05-28 07:34:18 - phase4_finetuning.finetune.trainer - INFO - [validate_one_epoch:165] - Validation finished. Avg Loss: 1.9112, accuracy: 0.2495, f1_macro: 0.1959, f1_weighted: 0.1953, precision_macro: 0.2027, precision_weighted: 0.1974, recall_macro: 0.2453, recall_weighted: 0.2495, f1_Bacterial_Blight: 0.2529, f1_Curl_Virus: 0.3188, f1_Healthy_Leaf: 0.2971, f1_Herbicide_Growth_Damage: 0.4383, f1_Leaf_Hopper_Jassids: 0.0082, f1_Leaf_Redding: 0.0000, f1_Leaf_Variegation: 0.0558
2025-05-28 07:34:18 - __main__ - INFO - [main_execution_logic:357] - E11: Val f1_macro (0.1959) not better than 0.2214. Patience: 2/10
2025-05-28 07:34:18 - __main__ - DEBUG - [main_execution_logic:360] - CUDA Mem E11 End: Alloc 3162.6MB
